+ . /data/sls/scratch/share-201907/slstoolchainrc
./run_icbhi.sh: line 15: /data/sls/scratch/share-201907/slstoolchainrc: No such file or directory
+ source ../../../venvssast/bin/activate
++ deactivate nondestructive
++ '[' -n '' ']'
++ '[' -n '' ']'
++ '[' -n /bin/bash -o -n '' ']'
++ hash -r
++ '[' -n '' ']'
++ unset VIRTUAL_ENV
++ '[' '!' nondestructive = nondestructive ']'
++ VIRTUAL_ENV=/workspace/pj_resp/ssast/venvssast
++ export VIRTUAL_ENV
++ _OLD_VIRTUAL_PATH=/workspace/pj_resp/ssast/venvssast/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/workspace/pj_resp/ssast/venvssast/bin:/workspace/pj_resp/ssast/venvssast/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export PATH
++ '[' -n '' ']'
++ '[' -z '' ']'
++ _OLD_VIRTUAL_PS1=
++ '[' 'x(venvssast) ' '!=' x ']'
++ PS1='(venvssast) '
++ export PS1
++ '[' -n /bin/bash -o -n '' ']'
++ hash -r
+ export TORCH_HOME=../../pretrained_models
+ TORCH_HOME=../../pretrained_models
+ mkdir -p ./exp
+ '[' -e SSAST-Base-Patch-400.pth ']'
+ echo 'pretrained model already downloaded.'
pretrained model already downloaded.
+ pretrain_exp=
+ pretrain_model=SSAST-Base-Patch-400
+ pretrain_path=.//SSAST-Base-Patch-400.pth
+ dataset=icbhi
+ dataset_mean=-4.2677393
+ dataset_std=4.5689974
+ target_length=1024
+ noise=False
+ task=ft_avgtok
+ model_size=base
+ head_lr=1
+ warmup=True
+ bal=none
+ lr=5e-5
+ epoch=25
+ tr_data=./data/icbhi_train.json
+ te_data=./data/icbhi_eval.json
+ freqm=48
+ timem=192
+ mixup=0.5
+ fstride=10
+ tstride=10
+ fshape=16
+ tshape=16
+ batch_size=8
+ filename=230806_1
+ exp_dir=./exp/230806_1-icbhi-f10-16-t10-16-b8-lr5e-5-ft_avgtok-base--SSAST-Base-Patch-400-1x-noiseFalse-3
+ CUDA_CACHE_DISABLE=1
+ python -W ignore ../../run.py --dataset icbhi --data-train ./data/icbhi_train.json --data-val ./data/icbhi_eval.json --exp-dir ./exp/230806_1-icbhi-f10-16-t10-16-b8-lr5e-5-ft_avgtok-base--SSAST-Base-Patch-400-1x-noiseFalse-3 --label-csv ./data/icbhi_class_labels_indices.csv --n_class 4 --lr 5e-5 --n-epochs 25 --batch-size 8 --save_model False --freqm 48 --timem 192 --mixup 0.5 --bal none --tstride 10 --fstride 10 --fshape 16 --tshape 16 --warmup False --task ft_avgtok --model_size base --adaptschedule False --pretrained_mdl_path .//SSAST-Base-Patch-400.pth --dataset_mean -4.2677393 --dataset_std 4.5689974 --target_length 1024 --num_mel_bins 128 --head_lr 1 --noise False --lrscheduler_start 10 --lrscheduler_step 5 --lrscheduler_decay 0.5 --wa True --wa_start 6 --wa_end 25 --loss BCE --metrics mAP
I am process 241, running on 05ea1d3ab41c: starting (Mon Aug  7 12:40:51 2023)
balanced sampler is not used
---------------the train dataloader---------------
now using following mask: 48 freq, 192 time
now using mix-up with rate 0.500000
now process icbhi
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 4
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process icbhi
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 4
Now train with icbhi with 4142 training samples, evaluate with 2756 samples
now load a SSL pretrained models from .//SSAST-Base-Patch-400.pth
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=10, time=10
fine-tuning number of patches=1212

Creating experiment directory: ./exp/230806_1-icbhi-f10-16-t10-16-b8-lr5e-5-ft_avgtok-base--SSAST-Base-Patch-400-1x-noiseFalse-3
Now starting fine-tuning for 25 epochs
running on cuda
Total parameter number is : 87.730 million
Total trainable parameter number is : 87.730 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 87.725 million
now training with icbhi, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fd14c8f9490>
The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-08-07 12:41:48.298332
current #epochs=1, #steps=0
Epoch: [1][100/517]	Per Sample Total Time 0.18486	Per Sample Data Time 0.00271	Per Sample DNN Time 0.18216	Train Loss 0.4980	
Epoch: [1][200/517]	Per Sample Total Time 0.12911	Per Sample Data Time 0.00156	Per Sample DNN Time 0.12755	Train Loss 0.4966	
Epoch: [1][300/517]	Per Sample Total Time 0.11053	Per Sample Data Time 0.00117	Per Sample DNN Time 0.10936	Train Loss 0.4942	
Epoch: [1][400/517]	Per Sample Total Time 0.10124	Per Sample Data Time 0.00098	Per Sample DNN Time 0.10026	Train Loss 0.4955	
Epoch: [1][500/517]	Per Sample Total Time 0.09565	Per Sample Data Time 0.00086	Per Sample DNN Time 0.09479	Train Loss 0.4951	
start validation
mAP: 0.265894
AUC: 0.545613
Avg Precision: 0.267070
Avg Recall: 0.675223
d_prime: 0.162050
train_loss: 0.494866
valid_loss: 0.733939
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-1 lr: 5e-05
Epoch-1 lr: 5e-05
epoch 1 training time: 463.146
---------------
2023-08-07 12:49:31.444436
current #epochs=2, #steps=517
Epoch: [2][83/517]	Per Sample Total Time 0.07711	Per Sample Data Time 0.00436	Per Sample DNN Time 0.07275	Train Loss 0.5057	
Epoch: [2][183/517]	Per Sample Total Time 0.07500	Per Sample Data Time 0.00221	Per Sample DNN Time 0.07279	Train Loss 0.4944	
Epoch: [2][283/517]	Per Sample Total Time 0.07439	Per Sample Data Time 0.00159	Per Sample DNN Time 0.07281	Train Loss 0.4908	
Epoch: [2][383/517]	Per Sample Total Time 0.07411	Per Sample Data Time 0.00132	Per Sample DNN Time 0.07280	Train Loss 0.4912	
Epoch: [2][483/517]	Per Sample Total Time 0.07393	Per Sample Data Time 0.00115	Per Sample DNN Time 0.07278	Train Loss 0.4922	
start validation
mAP: 0.259322
AUC: 0.526728
Avg Precision: 0.258116
Avg Recall: 0.659521
d_prime: 0.094818
train_loss: 0.492187
valid_loss: 0.734084
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-2 lr: 5e-05
Epoch-2 lr: 5e-05
epoch 2 training time: 374.668
---------------
2023-08-07 12:55:46.112077
current #epochs=3, #steps=1034
Epoch: [3][66/517]	Per Sample Total Time 0.07834	Per Sample Data Time 0.00582	Per Sample DNN Time 0.07252	Train Loss 0.4930	
Epoch: [3][166/517]	Per Sample Total Time 0.07530	Per Sample Data Time 0.00266	Per Sample DNN Time 0.07263	Train Loss 0.4890	
Epoch: [3][266/517]	Per Sample Total Time 0.07455	Per Sample Data Time 0.00187	Per Sample DNN Time 0.07267	Train Loss 0.4925	
Epoch: [3][366/517]	Per Sample Total Time 0.07421	Per Sample Data Time 0.00151	Per Sample DNN Time 0.07270	Train Loss 0.4923	
Epoch: [3][466/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00130	Per Sample DNN Time 0.07272	Train Loss 0.4918	
start validation
mAP: 0.248662
AUC: 0.496282
Avg Precision: 0.244084
Avg Recall: 0.626701
d_prime: -0.013179
train_loss: 0.491591
valid_loss: 0.733100
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-3 lr: 5e-05
Epoch-3 lr: 5e-05
epoch 3 training time: 376.693
---------------
2023-08-07 13:02:02.805484
current #epochs=4, #steps=1551
Epoch: [4][49/517]	Per Sample Total Time 0.07979	Per Sample Data Time 0.00721	Per Sample DNN Time 0.07258	Train Loss 0.4963	
Epoch: [4][149/517]	Per Sample Total Time 0.07545	Per Sample Data Time 0.00277	Per Sample DNN Time 0.07268	Train Loss 0.4855	
Epoch: [4][249/517]	Per Sample Total Time 0.07461	Per Sample Data Time 0.00189	Per Sample DNN Time 0.07272	Train Loss 0.4958	
Epoch: [4][349/517]	Per Sample Total Time 0.07423	Per Sample Data Time 0.00150	Per Sample DNN Time 0.07273	Train Loss 0.4948	
Epoch: [4][449/517]	Per Sample Total Time 0.07403	Per Sample Data Time 0.00129	Per Sample DNN Time 0.07274	Train Loss 0.4934	
start validation
mAP: 0.260810
AUC: 0.512044
Avg Precision: 0.251079
Avg Recall: 0.637136
d_prime: 0.042700
train_loss: 0.492395
valid_loss: 0.735532
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-4 lr: 5e-05
Epoch-4 lr: 5e-05
epoch 4 training time: 374.733
---------------
2023-08-07 13:08:17.538176
current #epochs=5, #steps=2068
Epoch: [5][32/517]	Per Sample Total Time 0.08827	Per Sample Data Time 0.01578	Per Sample DNN Time 0.07248	Train Loss 0.4954	
Epoch: [5][132/517]	Per Sample Total Time 0.07696	Per Sample Data Time 0.00435	Per Sample DNN Time 0.07261	Train Loss 0.4907	
Epoch: [5][232/517]	Per Sample Total Time 0.07543	Per Sample Data Time 0.00273	Per Sample DNN Time 0.07270	Train Loss 0.4922	
Epoch: [5][332/517]	Per Sample Total Time 0.07481	Per Sample Data Time 0.00208	Per Sample DNN Time 0.07273	Train Loss 0.4911	
Epoch: [5][432/517]	Per Sample Total Time 0.07447	Per Sample Data Time 0.00173	Per Sample DNN Time 0.07274	Train Loss 0.4902	
start validation
mAP: 0.275100
AUC: 0.556706
Avg Precision: 0.264086
Avg Recall: 0.702787
d_prime: 0.201698
train_loss: 0.489264
valid_loss: 0.737910
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-5 lr: 5e-05
Epoch-5 lr: 5e-05
epoch 5 training time: 379.067
---------------
2023-08-07 13:14:36.604966
current #epochs=6, #steps=2585
Epoch: [6][15/517]	Per Sample Total Time 0.09591	Per Sample Data Time 0.02363	Per Sample DNN Time 0.07228	Train Loss 0.5023	
Epoch: [6][115/517]	Per Sample Total Time 0.07625	Per Sample Data Time 0.00370	Per Sample DNN Time 0.07255	Train Loss 0.4988	
Epoch: [6][215/517]	Per Sample Total Time 0.07488	Per Sample Data Time 0.00223	Per Sample DNN Time 0.07265	Train Loss 0.4921	
Epoch: [6][315/517]	Per Sample Total Time 0.07440	Per Sample Data Time 0.00168	Per Sample DNN Time 0.07271	Train Loss 0.4915	
Epoch: [6][415/517]	Per Sample Total Time 0.07414	Per Sample Data Time 0.00141	Per Sample DNN Time 0.07273	Train Loss 0.4913	
Epoch: [6][515/517]	Per Sample Total Time 0.07397	Per Sample Data Time 0.00124	Per Sample DNN Time 0.07273	Train Loss 0.4897	
start validation
mAP: 0.245529
AUC: 0.493678
Avg Precision: 0.250900
Avg Recall: 0.656314
d_prime: -0.022412
train_loss: 0.489706
valid_loss: 0.734728
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-6 lr: 5e-05
Epoch-6 lr: 5e-05
epoch 6 training time: 374.481
---------------
2023-08-07 13:20:51.085702
current #epochs=7, #steps=3102
Epoch: [7][98/517]	Per Sample Total Time 0.07666	Per Sample Data Time 0.00406	Per Sample DNN Time 0.07259	Train Loss 0.4785	
Epoch: [7][198/517]	Per Sample Total Time 0.07499	Per Sample Data Time 0.00230	Per Sample DNN Time 0.07269	Train Loss 0.4905	
Epoch: [7][298/517]	Per Sample Total Time 0.07442	Per Sample Data Time 0.00171	Per Sample DNN Time 0.07271	Train Loss 0.4888	
Epoch: [7][398/517]	Per Sample Total Time 0.07413	Per Sample Data Time 0.00142	Per Sample DNN Time 0.07271	Train Loss 0.4882	
Epoch: [7][498/517]	Per Sample Total Time 0.07395	Per Sample Data Time 0.00124	Per Sample DNN Time 0.07271	Train Loss 0.4878	
start validation
mAP: 0.258429
AUC: 0.536362
Avg Precision: 0.262167
Avg Recall: 0.695270
d_prime: 0.129079
train_loss: 0.487174
valid_loss: 0.729010
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-7 lr: 5e-05
Epoch-7 lr: 5e-05
epoch 7 training time: 374.238
---------------
2023-08-07 13:27:05.323637
current #epochs=8, #steps=3619
Epoch: [8][81/517]	Per Sample Total Time 0.07794	Per Sample Data Time 0.00538	Per Sample DNN Time 0.07256	Train Loss 0.4913	
Epoch: [8][181/517]	Per Sample Total Time 0.07537	Per Sample Data Time 0.00271	Per Sample DNN Time 0.07266	Train Loss 0.4894	
Epoch: [8][281/517]	Per Sample Total Time 0.07464	Per Sample Data Time 0.00194	Per Sample DNN Time 0.07270	Train Loss 0.4857	
Epoch: [8][381/517]	Per Sample Total Time 0.07432	Per Sample Data Time 0.00158	Per Sample DNN Time 0.07273	Train Loss 0.4859	
Epoch: [8][481/517]	Per Sample Total Time 0.07412	Per Sample Data Time 0.00137	Per Sample DNN Time 0.07275	Train Loss 0.4892	
start validation
mAP: 0.261247
AUC: 0.513755
Avg Precision: 0.250517
Avg Recall: 0.640946
d_prime: 0.048770
train_loss: 0.489261
valid_loss: 0.737610
S_p: 99.74667511082332, S_e: 0.16992353440950128, Score: 49.95829932261641
validation finished
normal learning rate scheduler step
Epoch-8 lr: 5e-05
Epoch-8 lr: 5e-05
epoch 8 training time: 375.304
---------------
2023-08-07 13:33:20.627980
current #epochs=9, #steps=4136
Epoch: [9][64/517]	Per Sample Total Time 0.07912	Per Sample Data Time 0.00650	Per Sample DNN Time 0.07262	Train Loss 0.5011	
Epoch: [9][164/517]	Per Sample Total Time 0.07556	Per Sample Data Time 0.00283	Per Sample DNN Time 0.07273	Train Loss 0.4905	
Epoch: [9][264/517]	Per Sample Total Time 0.07472	Per Sample Data Time 0.00194	Per Sample DNN Time 0.07277	Train Loss 0.4881	
Epoch: [9][364/517]	Per Sample Total Time 0.07432	Per Sample Data Time 0.00154	Per Sample DNN Time 0.07279	Train Loss 0.4848	
Epoch: [9][464/517]	Per Sample Total Time 0.07409	Per Sample Data Time 0.00130	Per Sample DNN Time 0.07279	Train Loss 0.4830	
start validation
mAP: 0.242168
AUC: 0.482514
Avg Precision: 0.235788
Avg Recall: 0.613090
d_prime: -0.062007
train_loss: 0.483357
valid_loss: 0.735588
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-9 lr: 5e-05
Epoch-9 lr: 5e-05
epoch 9 training time: 374.441
---------------
2023-08-07 13:39:35.068599
current #epochs=10, #steps=4653
Epoch: [10][47/517]	Per Sample Total Time 0.08158	Per Sample Data Time 0.00900	Per Sample DNN Time 0.07258	Train Loss 0.4905	
Epoch: [10][147/517]	Per Sample Total Time 0.07595	Per Sample Data Time 0.00328	Per Sample DNN Time 0.07267	Train Loss 0.4831	
Epoch: [10][247/517]	Per Sample Total Time 0.07489	Per Sample Data Time 0.00217	Per Sample DNN Time 0.07272	Train Loss 0.4869	
Epoch: [10][347/517]	Per Sample Total Time 0.07442	Per Sample Data Time 0.00168	Per Sample DNN Time 0.07274	Train Loss 0.4858	
Epoch: [10][447/517]	Per Sample Total Time 0.07415	Per Sample Data Time 0.00141	Per Sample DNN Time 0.07275	Train Loss 0.4826	
start validation
mAP: 0.265186
AUC: 0.533845
Avg Precision: 0.260922
Avg Recall: 0.672694
d_prime: 0.120120
train_loss: 0.484252
valid_loss: 0.735074
S_p: 83.09056364787314, S_e: 5.862361937127794, Score: 44.47646279250047
validation finished
normal learning rate scheduler step
Epoch-10 lr: 2.5e-05
Epoch-10 lr: 2.5e-05
epoch 10 training time: 375.413
---------------
2023-08-07 13:45:50.481985
current #epochs=11, #steps=5170
Epoch: [11][30/517]	Per Sample Total Time 0.08499	Per Sample Data Time 0.01250	Per Sample DNN Time 0.07248	Train Loss 0.4906	
Epoch: [11][130/517]	Per Sample Total Time 0.07597	Per Sample Data Time 0.00335	Per Sample DNN Time 0.07262	Train Loss 0.4880	
Epoch: [11][230/517]	Per Sample Total Time 0.07482	Per Sample Data Time 0.00212	Per Sample DNN Time 0.07270	Train Loss 0.4853	
Epoch: [11][330/517]	Per Sample Total Time 0.07436	Per Sample Data Time 0.00164	Per Sample DNN Time 0.07272	Train Loss 0.4787	
Epoch: [11][430/517]	Per Sample Total Time 0.07411	Per Sample Data Time 0.00138	Per Sample DNN Time 0.07273	Train Loss 0.4815	
start validation
mAP: 0.246650
AUC: 0.498468
Avg Precision: 0.245094
Avg Recall: 0.626046
d_prime: -0.005429
train_loss: 0.481841
valid_loss: 0.732463
S_p: 99.3666877770678, S_e: 0.08496176720475064, Score: 49.72582477213627
validation finished
normal learning rate scheduler step
Epoch-11 lr: 2.5e-05
Epoch-11 lr: 2.5e-05
epoch 11 training time: 374.943
---------------
2023-08-07 13:52:05.424889
current #epochs=12, #steps=5687
Epoch: [12][13/517]	Per Sample Total Time 0.10108	Per Sample Data Time 0.02857	Per Sample DNN Time 0.07251	Train Loss 0.5295	
Epoch: [12][113/517]	Per Sample Total Time 0.07660	Per Sample Data Time 0.00396	Per Sample DNN Time 0.07264	Train Loss 0.4880	
Epoch: [12][213/517]	Per Sample Total Time 0.07505	Per Sample Data Time 0.00234	Per Sample DNN Time 0.07270	Train Loss 0.4833	
Epoch: [12][313/517]	Per Sample Total Time 0.07449	Per Sample Data Time 0.00176	Per Sample DNN Time 0.07273	Train Loss 0.4812	
Epoch: [12][413/517]	Per Sample Total Time 0.07419	Per Sample Data Time 0.00145	Per Sample DNN Time 0.07274	Train Loss 0.4778	
Epoch: [12][513/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00126	Per Sample DNN Time 0.07274	Train Loss 0.4763	
start validation
mAP: 0.246882
AUC: 0.502012
Avg Precision: 0.247368
Avg Recall: 0.645973
d_prime: 0.007132
train_loss: 0.476140
valid_loss: 0.736433
S_p: 88.09373020898745, S_e: 3.1435853865757735, Score: 45.618657797781616
validation finished
normal learning rate scheduler step
Epoch-12 lr: 2.5e-05
Epoch-12 lr: 2.5e-05
epoch 12 training time: 375.136
---------------
2023-08-07 13:58:20.561202
current #epochs=13, #steps=6204
Epoch: [13][96/517]	Per Sample Total Time 0.07719	Per Sample Data Time 0.00457	Per Sample DNN Time 0.07262	Train Loss 0.4747	
Epoch: [13][196/517]	Per Sample Total Time 0.07520	Per Sample Data Time 0.00251	Per Sample DNN Time 0.07270	Train Loss 0.4721	
Epoch: [13][296/517]	Per Sample Total Time 0.07457	Per Sample Data Time 0.00183	Per Sample DNN Time 0.07274	Train Loss 0.4735	
Epoch: [13][396/517]	Per Sample Total Time 0.07424	Per Sample Data Time 0.00149	Per Sample DNN Time 0.07276	Train Loss 0.4753	
Epoch: [13][496/517]	Per Sample Total Time 0.07405	Per Sample Data Time 0.00129	Per Sample DNN Time 0.07276	Train Loss 0.4755	
start validation
mAP: 0.244582
AUC: 0.503245
Avg Precision: 0.246046
Avg Recall: 0.653551
d_prime: 0.011503
train_loss: 0.475206
valid_loss: 0.731726
S_p: 97.0867637745347, S_e: 1.444350042480761, Score: 49.26555690850773
validation finished
normal learning rate scheduler step
Epoch-13 lr: 2.5e-05
Epoch-13 lr: 2.5e-05
epoch 13 training time: 374.808
---------------
2023-08-07 14:04:35.368991
current #epochs=14, #steps=6721
Epoch: [14][79/517]	Per Sample Total Time 0.07729	Per Sample Data Time 0.00468	Per Sample DNN Time 0.07261	Train Loss 0.4678	
Epoch: [14][179/517]	Per Sample Total Time 0.07506	Per Sample Data Time 0.00236	Per Sample DNN Time 0.07270	Train Loss 0.4634	
Epoch: [14][279/517]	Per Sample Total Time 0.07442	Per Sample Data Time 0.00169	Per Sample DNN Time 0.07273	Train Loss 0.4672	
Epoch: [14][379/517]	Per Sample Total Time 0.07412	Per Sample Data Time 0.00137	Per Sample DNN Time 0.07275	Train Loss 0.4693	
Epoch: [14][479/517]	Per Sample Total Time 0.07395	Per Sample Data Time 0.00119	Per Sample DNN Time 0.07276	Train Loss 0.4705	
start validation
mAP: 0.240884
AUC: 0.492293
Avg Precision: 0.241974
Avg Recall: 0.632343
d_prime: -0.027323
train_loss: 0.472037
valid_loss: 0.735057
S_p: 95.6934768840978, S_e: 1.2744265080712596, Score: 48.48395169608453
validation finished
normal learning rate scheduler step
Epoch-14 lr: 2.5e-05
Epoch-14 lr: 2.5e-05
epoch 14 training time: 374.862
---------------
2023-08-07 14:10:50.231311
current #epochs=15, #steps=7238
Epoch: [15][62/517]	Per Sample Total Time 0.07927	Per Sample Data Time 0.00667	Per Sample DNN Time 0.07260	Train Loss 0.4669	
Epoch: [15][162/517]	Per Sample Total Time 0.07557	Per Sample Data Time 0.00288	Per Sample DNN Time 0.07269	Train Loss 0.4687	
Epoch: [15][262/517]	Per Sample Total Time 0.07472	Per Sample Data Time 0.00197	Per Sample DNN Time 0.07274	Train Loss 0.4673	
Epoch: [15][362/517]	Per Sample Total Time 0.07433	Per Sample Data Time 0.00157	Per Sample DNN Time 0.07276	Train Loss 0.4625	
Epoch: [15][462/517]	Per Sample Total Time 0.07410	Per Sample Data Time 0.00133	Per Sample DNN Time 0.07277	Train Loss 0.4627	
start validation
mAP: 0.255164
AUC: 0.521226
Avg Precision: 0.254420
Avg Recall: 0.663526
d_prime: 0.075278
train_loss: 0.463541
valid_loss: 0.742227
S_p: 71.3109563014521, S_e: 14.44350042480761, Score: 42.87722836312985
validation finished
normal learning rate scheduler step
Epoch-15 lr: 1.25e-05
Epoch-15 lr: 1.25e-05
epoch 15 training time: 374.814
---------------
2023-08-07 14:17:05.044942
current #epochs=16, #steps=7755
Epoch: [16][45/517]	Per Sample Total Time 0.08148	Per Sample Data Time 0.00891	Per Sample DNN Time 0.07258	Train Loss 0.4514	
Epoch: [16][145/517]	Per Sample Total Time 0.07576	Per Sample Data Time 0.00310	Per Sample DNN Time 0.07266	Train Loss 0.4595	
Epoch: [16][245/517]	Per Sample Total Time 0.07473	Per Sample Data Time 0.00201	Per Sample DNN Time 0.07271	Train Loss 0.4552	
Epoch: [16][345/517]	Per Sample Total Time 0.07428	Per Sample Data Time 0.00155	Per Sample DNN Time 0.07274	Train Loss 0.4552	
Epoch: [16][445/517]	Per Sample Total Time 0.07404	Per Sample Data Time 0.00129	Per Sample DNN Time 0.07275	Train Loss 0.4553	
start validation
mAP: 0.241549
AUC: 0.492863
Avg Precision: 0.244187
Avg Recall: 0.636093
d_prime: -0.025300
train_loss: 0.454554
valid_loss: 0.735180
S_p: 80.36732108929193, S_e: 10.450297366184328, Score: 45.40880922773813
validation finished
normal learning rate scheduler step
Epoch-16 lr: 1.25e-05
Epoch-16 lr: 1.25e-05
epoch 16 training time: 374.184
---------------
2023-08-07 14:23:19.228698
current #epochs=17, #steps=8272
Epoch: [17][28/517]	Per Sample Total Time 0.08638	Per Sample Data Time 0.01381	Per Sample DNN Time 0.07257	Train Loss 0.4354	
Epoch: [17][128/517]	Per Sample Total Time 0.07613	Per Sample Data Time 0.00343	Per Sample DNN Time 0.07270	Train Loss 0.4297	
Epoch: [17][228/517]	Per Sample Total Time 0.07488	Per Sample Data Time 0.00211	Per Sample DNN Time 0.07277	Train Loss 0.4351	
Epoch: [17][328/517]	Per Sample Total Time 0.07439	Per Sample Data Time 0.00159	Per Sample DNN Time 0.07280	Train Loss 0.4398	
Epoch: [17][428/517]	Per Sample Total Time 0.07413	Per Sample Data Time 0.00132	Per Sample DNN Time 0.07281	Train Loss 0.4406	
start validation
mAP: 0.246618
AUC: 0.504714
Avg Precision: 0.247106
Avg Recall: 0.635680
d_prime: 0.016712
train_loss: 0.441436
valid_loss: 0.746375
S_p: 60.86130462317537, S_e: 16.99235344095013, Score: 38.92682903206275
validation finished
normal learning rate scheduler step
Epoch-17 lr: 1.25e-05
Epoch-17 lr: 1.25e-05
epoch 17 training time: 374.532
---------------
2023-08-07 14:29:33.761173
current #epochs=18, #steps=8789
Epoch: [18][11/517]	Per Sample Total Time 0.10130	Per Sample Data Time 0.02874	Per Sample DNN Time 0.07256	Train Loss 0.4476	
Epoch: [18][111/517]	Per Sample Total Time 0.07609	Per Sample Data Time 0.00341	Per Sample DNN Time 0.07268	Train Loss 0.4321	
Epoch: [18][211/517]	Per Sample Total Time 0.07474	Per Sample Data Time 0.00200	Per Sample DNN Time 0.07274	Train Loss 0.4311	
Epoch: [18][311/517]	Per Sample Total Time 0.07425	Per Sample Data Time 0.00148	Per Sample DNN Time 0.07277	Train Loss 0.4322	
Epoch: [18][411/517]	Per Sample Total Time 0.07400	Per Sample Data Time 0.00122	Per Sample DNN Time 0.07278	Train Loss 0.4316	
Epoch: [18][511/517]	Per Sample Total Time 0.07384	Per Sample Data Time 0.00106	Per Sample DNN Time 0.07278	Train Loss 0.4290	
start validation
mAP: 0.240407
AUC: 0.483562
Avg Precision: 0.239530
Avg Recall: 0.611348
d_prime: -0.058289
train_loss: 0.429397
valid_loss: 0.737991
S_p: 72.2609246358409, S_e: 14.188615123193356, Score: 43.224769879517126
validation finished
normal learning rate scheduler step
Epoch-18 lr: 1.25e-05
Epoch-18 lr: 1.25e-05
epoch 18 training time: 373.512
---------------
2023-08-07 14:35:47.273090
current #epochs=19, #steps=9306
Epoch: [19][94/517]	Per Sample Total Time 0.07712	Per Sample Data Time 0.00448	Per Sample DNN Time 0.07264	Train Loss 0.4245	
Epoch: [19][194/517]	Per Sample Total Time 0.07519	Per Sample Data Time 0.00249	Per Sample DNN Time 0.07269	Train Loss 0.4190	
Epoch: [19][294/517]	Per Sample Total Time 0.07456	Per Sample Data Time 0.00185	Per Sample DNN Time 0.07271	Train Loss 0.4227	
Epoch: [19][394/517]	Per Sample Total Time 0.07424	Per Sample Data Time 0.00153	Per Sample DNN Time 0.07270	Train Loss 0.4218	
Epoch: [19][494/517]	Per Sample Total Time 0.07404	Per Sample Data Time 0.00135	Per Sample DNN Time 0.07269	Train Loss 0.4239	
start validation
mAP: 0.243329
AUC: 0.486680
Avg Precision: 0.241827
Avg Recall: 0.616111
d_prime: -0.047227
train_loss: 0.424142
valid_loss: 0.744327
S_p: 60.86130462317537, S_e: 17.67204757858813, Score: 39.26667610088175
validation finished
normal learning rate scheduler step
Epoch-19 lr: 1.25e-05
Epoch-19 lr: 1.25e-05
epoch 19 training time: 375.285
---------------
2023-08-07 14:42:02.558073
current #epochs=20, #steps=9823
Epoch: [20][77/517]	Per Sample Total Time 0.07855	Per Sample Data Time 0.00599	Per Sample DNN Time 0.07256	Train Loss 0.4133	
Epoch: [20][177/517]	Per Sample Total Time 0.07560	Per Sample Data Time 0.00294	Per Sample DNN Time 0.07266	Train Loss 0.4126	
Epoch: [20][277/517]	Per Sample Total Time 0.07479	Per Sample Data Time 0.00208	Per Sample DNN Time 0.07271	Train Loss 0.4140	
Epoch: [20][377/517]	Per Sample Total Time 0.07440	Per Sample Data Time 0.00167	Per Sample DNN Time 0.07273	Train Loss 0.4119	
Epoch: [20][477/517]	Per Sample Total Time 0.07418	Per Sample Data Time 0.00144	Per Sample DNN Time 0.07274	Train Loss 0.4075	
start validation
mAP: 0.243560
AUC: 0.488356
Avg Precision: 0.239096
Avg Recall: 0.615515
d_prime: -0.041282
train_loss: 0.407804
valid_loss: 0.748542
S_p: 54.40151994933158, S_e: 18.946474086659393, Score: 36.67399701799549
validation finished
normal learning rate scheduler step
Epoch-20 lr: 6.25e-06
Epoch-20 lr: 6.25e-06
epoch 20 training time: 375.536
---------------
2023-08-07 14:48:18.093814
current #epochs=21, #steps=10340
Epoch: [21][60/517]	Per Sample Total Time 0.07918	Per Sample Data Time 0.00657	Per Sample DNN Time 0.07261	Train Loss 0.3992	
Epoch: [21][160/517]	Per Sample Total Time 0.07550	Per Sample Data Time 0.00281	Per Sample DNN Time 0.07269	Train Loss 0.4001	
Epoch: [21][260/517]	Per Sample Total Time 0.07465	Per Sample Data Time 0.00193	Per Sample DNN Time 0.07272	Train Loss 0.3988	
Epoch: [21][360/517]	Per Sample Total Time 0.07427	Per Sample Data Time 0.00153	Per Sample DNN Time 0.07274	Train Loss 0.3986	
Epoch: [21][460/517]	Per Sample Total Time 0.07405	Per Sample Data Time 0.00131	Per Sample DNN Time 0.07274	Train Loss 0.3958	
start validation
mAP: 0.242551
AUC: 0.486176
Avg Precision: 0.240162
Avg Recall: 0.608796
d_prime: -0.049014
train_loss: 0.395695
valid_loss: 0.749524
S_p: 54.338188727039, S_e: 17.41716227697388, Score: 35.87767550200644
validation finished
normal learning rate scheduler step
Epoch-21 lr: 6.25e-06
Epoch-21 lr: 6.25e-06
epoch 21 training time: 374.430
---------------
2023-08-07 14:54:32.523932
current #epochs=22, #steps=10857
Epoch: [22][43/517]	Per Sample Total Time 0.08079	Per Sample Data Time 0.00818	Per Sample DNN Time 0.07261	Train Loss 0.3937	
Epoch: [22][143/517]	Per Sample Total Time 0.07555	Per Sample Data Time 0.00285	Per Sample DNN Time 0.07270	Train Loss 0.3688	
Epoch: [22][243/517]	Per Sample Total Time 0.07462	Per Sample Data Time 0.00189	Per Sample DNN Time 0.07273	Train Loss 0.3696	
Epoch: [22][343/517]	Per Sample Total Time 0.07423	Per Sample Data Time 0.00148	Per Sample DNN Time 0.07275	Train Loss 0.3748	
Epoch: [22][443/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00126	Per Sample DNN Time 0.07275	Train Loss 0.3791	
start validation
mAP: 0.240451
AUC: 0.479594
Avg Precision: 0.237893
Avg Recall: 0.607833
d_prime: -0.072369
train_loss: 0.382711
valid_loss: 0.752604
S_p: 51.17162761240968, S_e: 17.587085811383382, Score: 34.379356711896534
validation finished
normal learning rate scheduler step
Epoch-22 lr: 6.25e-06
Epoch-22 lr: 6.25e-06
epoch 22 training time: 374.854
---------------
2023-08-07 15:00:47.377719
current #epochs=23, #steps=11374
Epoch: [23][26/517]	Per Sample Total Time 0.08684	Per Sample Data Time 0.01431	Per Sample DNN Time 0.07253	Train Loss 0.3873	
Epoch: [23][126/517]	Per Sample Total Time 0.07610	Per Sample Data Time 0.00346	Per Sample DNN Time 0.07263	Train Loss 0.3804	
Epoch: [23][226/517]	Per Sample Total Time 0.07486	Per Sample Data Time 0.00217	Per Sample DNN Time 0.07269	Train Loss 0.3815	
Epoch: [23][326/517]	Per Sample Total Time 0.07438	Per Sample Data Time 0.00166	Per Sample DNN Time 0.07272	Train Loss 0.3821	
Epoch: [23][426/517]	Per Sample Total Time 0.07412	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07273	Train Loss 0.3787	
start validation
mAP: 0.243201
AUC: 0.486615
Avg Precision: 0.240883
Avg Recall: 0.609387
d_prime: -0.047457
train_loss: 0.377471
valid_loss: 0.746945
S_p: 56.04813172893882, S_e: 19.031435853864142, Score: 37.53978379140148
validation finished
normal learning rate scheduler step
Epoch-23 lr: 6.25e-06
Epoch-23 lr: 6.25e-06
epoch 23 training time: 374.911
---------------
2023-08-07 15:07:02.289203
current #epochs=24, #steps=11891
Epoch: [24][9/517]	Per Sample Total Time 0.10745	Per Sample Data Time 0.03497	Per Sample DNN Time 0.07248	Train Loss 0.4185	
Epoch: [24][109/517]	Per Sample Total Time 0.07623	Per Sample Data Time 0.00360	Per Sample DNN Time 0.07263	Train Loss 0.3799	
Epoch: [24][209/517]	Per Sample Total Time 0.07482	Per Sample Data Time 0.00212	Per Sample DNN Time 0.07270	Train Loss 0.3790	
Epoch: [24][309/517]	Per Sample Total Time 0.07434	Per Sample Data Time 0.00161	Per Sample DNN Time 0.07273	Train Loss 0.3723	
Epoch: [24][409/517]	Per Sample Total Time 0.07408	Per Sample Data Time 0.00134	Per Sample DNN Time 0.07275	Train Loss 0.3739	
Epoch: [24][509/517]	Per Sample Total Time 0.07392	Per Sample Data Time 0.00117	Per Sample DNN Time 0.07275	Train Loss 0.3715	
start validation
mAP: 0.241545
AUC: 0.478198
Avg Precision: 0.240116
Avg Recall: 0.619122
d_prime: -0.077326
train_loss: 0.370671
valid_loss: 0.745435
S_p: 59.40468651044589, S_e: 14.528462192012359, Score: 36.96657435122913
validation finished
normal learning rate scheduler step
Epoch-24 lr: 6.25e-06
Epoch-24 lr: 6.25e-06
epoch 24 training time: 374.531
---------------
2023-08-07 15:13:16.820070
current #epochs=25, #steps=12408
Epoch: [25][92/517]	Per Sample Total Time 0.07723	Per Sample Data Time 0.00460	Per Sample DNN Time 0.07263	Train Loss 0.3678	
Epoch: [25][192/517]	Per Sample Total Time 0.07517	Per Sample Data Time 0.00247	Per Sample DNN Time 0.07271	Train Loss 0.3592	
Epoch: [25][292/517]	Per Sample Total Time 0.07455	Per Sample Data Time 0.00180	Per Sample DNN Time 0.07274	Train Loss 0.3611	
Epoch: [25][392/517]	Per Sample Total Time 0.07423	Per Sample Data Time 0.00148	Per Sample DNN Time 0.07276	Train Loss 0.3604	
Epoch: [25][492/517]	Per Sample Total Time 0.07404	Per Sample Data Time 0.00128	Per Sample DNN Time 0.07276	Train Loss 0.3637	
start validation
mAP: 0.244890
AUC: 0.491288
Avg Precision: 0.244265
Avg Recall: 0.621330
d_prime: -0.030885
train_loss: 0.364201
valid_loss: 0.749890
S_p: 52.62824572513915, S_e: 19.11639762106889, Score: 35.872321673104025
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.125e-06
Epoch-25 lr: 3.125e-06
epoch 25 training time: 374.697
---------------Training Finished---------------
weighted averaged models results
mAP: 0.234769
AUC: 0.479722
Avg Precision: 0.235523
Avg Recall: 0.618614
d_prime: -0.071913
train_loss: 0.000000
valid_loss: 0.749890
S_p: 76.94743508549227, S_e: 7.98640611724656, Score: 42.46692060136942
