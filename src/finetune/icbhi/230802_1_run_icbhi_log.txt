pretrained model already downloaded.
I am process 156, running on d36e1a424534: starting (Wed Aug  2 06:48:09 2023)
balanced sampler is not used
---------------the train dataloader---------------
now using following mask: 48 freq, 192 time
now using mix-up with rate 0.500000
now process icbhi
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 4
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process icbhi
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 4
Now train with icbhi with 4142 training samples, evaluate with 2756 samples
now load a SSL pretrained models from .//SSAST-Base-Patch-400.pth
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=10, time=10
fine-tuning number of patches=1212

Creating experiment directory: ./exp/test01-icbhi-f10-16-t10-16-b8-lr5e-5-ft_avgtok-base--SSAST-Base-Patch-400-1x-noiseFalse-3
Now starting fine-tuning for 25 epochs
running on cuda
Total parameter number is : 87.730 million
Total trainable parameter number is : 87.730 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 87.725 million
now training with icbhi, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f24bafcb400>
The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-08-02 06:48:30.666309
current #epochs=1, #steps=0
Epoch: [1][100/517]	Per Sample Total Time 0.09360	Per Sample Data Time 0.00268	Per Sample DNN Time 0.09092	Train Loss 0.5000	
Epoch: [1][200/517]	Per Sample Total Time 0.08449	Per Sample Data Time 0.00163	Per Sample DNN Time 0.08286	Train Loss 0.4973	
Epoch: [1][300/517]	Per Sample Total Time 0.08153	Per Sample Data Time 0.00127	Per Sample DNN Time 0.08026	Train Loss 0.4949	
Epoch: [1][400/517]	Per Sample Total Time 0.08007	Per Sample Data Time 0.00110	Per Sample DNN Time 0.07898	Train Loss 0.4948	
Epoch: [1][500/517]	Per Sample Total Time 0.07920	Per Sample Data Time 0.00099	Per Sample DNN Time 0.07821	Train Loss 0.4958	
start validation
mAP: 0.269884
AUC: 0.544106
Avg Precision: 0.259478
Avg Recall: 0.678275
d_prime: 0.156671
train_loss: 0.496172
valid_loss: 0.736338
validation finished
normal learning rate scheduler step
Epoch-1 lr: 5e-05
Epoch-1 lr: 5e-05
epoch 1 training time: 399.153
---------------
2023-08-02 06:55:09.820084
current #epochs=2, #steps=517
Epoch: [2][83/517]	Per Sample Total Time 0.07783	Per Sample Data Time 0.00305	Per Sample DNN Time 0.07477	Train Loss 0.4969	
Epoch: [2][183/517]	Per Sample Total Time 0.07663	Per Sample Data Time 0.00171	Per Sample DNN Time 0.07493	Train Loss 0.4962	
Epoch: [2][283/517]	Per Sample Total Time 0.07633	Per Sample Data Time 0.00131	Per Sample DNN Time 0.07502	Train Loss 0.4959	
Epoch: [2][383/517]	Per Sample Total Time 0.07617	Per Sample Data Time 0.00112	Per Sample DNN Time 0.07505	Train Loss 0.4955	
Epoch: [2][483/517]	Per Sample Total Time 0.07606	Per Sample Data Time 0.00101	Per Sample DNN Time 0.07505	Train Loss 0.4948	
start validation
mAP: 0.252818
AUC: 0.511989
Avg Precision: 0.252662
Avg Recall: 0.627345
d_prime: 0.042507
train_loss: 0.494776
valid_loss: 0.733179
validation finished
normal learning rate scheduler step
Epoch-2 lr: 5e-05
Epoch-2 lr: 5e-05
epoch 2 training time: 384.469
---------------
2023-08-02 07:01:34.289672
current #epochs=3, #steps=1034
Epoch: [3][66/517]	Per Sample Total Time 0.07916	Per Sample Data Time 0.00420	Per Sample DNN Time 0.07496	Train Loss 0.5026	
Epoch: [3][166/517]	Per Sample Total Time 0.07695	Per Sample Data Time 0.00201	Per Sample DNN Time 0.07494	Train Loss 0.4953	
Epoch: [3][266/517]	Per Sample Total Time 0.07642	Per Sample Data Time 0.00146	Per Sample DNN Time 0.07496	Train Loss 0.4935	
Epoch: [3][366/517]	Per Sample Total Time 0.07615	Per Sample Data Time 0.00122	Per Sample DNN Time 0.07493	Train Loss 0.4922	
Epoch: [3][466/517]	Per Sample Total Time 0.07595	Per Sample Data Time 0.00107	Per Sample DNN Time 0.07487	Train Loss 0.4917	
start validation
mAP: 0.241711
AUC: 0.478759
Avg Precision: 0.246455
Avg Recall: 0.621122
d_prime: -0.075332
train_loss: 0.492129
valid_loss: 0.734909
validation finished
normal learning rate scheduler step
Epoch-3 lr: 5e-05
Epoch-3 lr: 5e-05
epoch 3 training time: 383.323
---------------
2023-08-02 07:07:57.612919
current #epochs=4, #steps=1551
Epoch: [4][49/517]	Per Sample Total Time 0.07982	Per Sample Data Time 0.00524	Per Sample DNN Time 0.07459	Train Loss 0.4807	
Epoch: [4][149/517]	Per Sample Total Time 0.07652	Per Sample Data Time 0.00210	Per Sample DNN Time 0.07442	Train Loss 0.4956	
Epoch: [4][249/517]	Per Sample Total Time 0.07601	Per Sample Data Time 0.00148	Per Sample DNN Time 0.07453	Train Loss 0.4923	
Epoch: [4][349/517]	Per Sample Total Time 0.07576	Per Sample Data Time 0.00121	Per Sample DNN Time 0.07455	Train Loss 0.4911	
Epoch: [4][449/517]	Per Sample Total Time 0.07558	Per Sample Data Time 0.00106	Per Sample DNN Time 0.07452	Train Loss 0.4920	
start validation
mAP: 0.248944
AUC: 0.504988
Avg Precision: 0.245326
Avg Recall: 0.617181
d_prime: 0.017684
train_loss: 0.491201
valid_loss: 0.733470
validation finished
normal learning rate scheduler step
Epoch-4 lr: 5e-05
Epoch-4 lr: 5e-05
epoch 4 training time: 381.837
---------------
2023-08-02 07:14:19.448910
current #epochs=5, #steps=2068
Epoch: [5][32/517]	Per Sample Total Time 0.08181	Per Sample Data Time 0.00711	Per Sample DNN Time 0.07470	Train Loss 0.5042	
Epoch: [5][132/517]	Per Sample Total Time 0.07674	Per Sample Data Time 0.00220	Per Sample DNN Time 0.07454	Train Loss 0.4923	
Epoch: [5][232/517]	Per Sample Total Time 0.07616	Per Sample Data Time 0.00151	Per Sample DNN Time 0.07465	Train Loss 0.4954	
Epoch: [5][332/517]	Per Sample Total Time 0.07596	Per Sample Data Time 0.00122	Per Sample DNN Time 0.07474	Train Loss 0.4902	
Epoch: [5][432/517]	Per Sample Total Time 0.07585	Per Sample Data Time 0.00107	Per Sample DNN Time 0.07478	Train Loss 0.4889	
start validation
mAP: 0.262240
AUC: 0.526836
Avg Precision: 0.261774
Avg Recall: 0.671537
d_prime: 0.095205
train_loss: 0.489503
valid_loss: 0.730715
validation finished
normal learning rate scheduler step
Epoch-5 lr: 5e-05
Epoch-5 lr: 5e-05
epoch 5 training time: 383.240
---------------
2023-08-02 07:20:42.689078
current #epochs=6, #steps=2585
Epoch: [6][15/517]	Per Sample Total Time 0.08888	Per Sample Data Time 0.01453	Per Sample DNN Time 0.07435	Train Loss 0.4945	
Epoch: [6][115/517]	Per Sample Total Time 0.07736	Per Sample Data Time 0.00249	Per Sample DNN Time 0.07487	Train Loss 0.4955	
Epoch: [6][215/517]	Per Sample Total Time 0.07654	Per Sample Data Time 0.00160	Per Sample DNN Time 0.07495	Train Loss 0.4907	
Epoch: [6][315/517]	Per Sample Total Time 0.07622	Per Sample Data Time 0.00127	Per Sample DNN Time 0.07495	Train Loss 0.4937	
Epoch: [6][415/517]	Per Sample Total Time 0.07603	Per Sample Data Time 0.00110	Per Sample DNN Time 0.07493	Train Loss 0.4927	
Epoch: [6][515/517]	Per Sample Total Time 0.07591	Per Sample Data Time 0.00099	Per Sample DNN Time 0.07492	Train Loss 0.4897	
start validation
mAP: 0.256046
AUC: 0.503381
Avg Precision: 0.245489
Avg Recall: 0.647463
d_prime: 0.011987
train_loss: 0.489596
valid_loss: 0.740970
validation finished
normal learning rate scheduler step
Epoch-6 lr: 5e-05
Epoch-6 lr: 5e-05
epoch 6 training time: 383.891
---------------
2023-08-02 07:27:06.580784
current #epochs=7, #steps=3102
Epoch: [7][98/517]	Per Sample Total Time 0.07753	Per Sample Data Time 0.00289	Per Sample DNN Time 0.07464	Train Loss 0.4904	
Epoch: [7][198/517]	Per Sample Total Time 0.07528	Per Sample Data Time 0.00171	Per Sample DNN Time 0.07357	Train Loss 0.4858	
Epoch: [7][298/517]	Per Sample Total Time 0.07471	Per Sample Data Time 0.00131	Per Sample DNN Time 0.07341	Train Loss 0.4887	
Epoch: [7][398/517]	Per Sample Total Time 0.07430	Per Sample Data Time 0.00111	Per Sample DNN Time 0.07319	Train Loss 0.4890	
Epoch: [7][498/517]	Per Sample Total Time 0.07405	Per Sample Data Time 0.00100	Per Sample DNN Time 0.07305	Train Loss 0.4894	
start validation
mAP: 0.247040
AUC: 0.500055
Avg Precision: 0.252611
Avg Recall: 0.669894
d_prime: 0.000194
train_loss: 0.489277
valid_loss: 0.734103
validation finished
normal learning rate scheduler step
Epoch-7 lr: 5e-05
Epoch-7 lr: 5e-05
epoch 7 training time: 373.652
---------------
2023-08-02 07:33:20.232141
current #epochs=8, #steps=3619
Epoch: [8][81/517]	Per Sample Total Time 0.07599	Per Sample Data Time 0.00361	Per Sample DNN Time 0.07238	Train Loss 0.4833	
Epoch: [8][181/517]	Per Sample Total Time 0.07437	Per Sample Data Time 0.00194	Per Sample DNN Time 0.07243	Train Loss 0.4833	
Epoch: [8][281/517]	Per Sample Total Time 0.07391	Per Sample Data Time 0.00146	Per Sample DNN Time 0.07245	Train Loss 0.4844	
Epoch: [8][381/517]	Per Sample Total Time 0.07369	Per Sample Data Time 0.00122	Per Sample DNN Time 0.07247	Train Loss 0.4845	
Epoch: [8][481/517]	Per Sample Total Time 0.07356	Per Sample Data Time 0.00108	Per Sample DNN Time 0.07248	Train Loss 0.4838	
start validation
mAP: 0.248125
AUC: 0.501510
Avg Precision: 0.246151
Avg Recall: 0.643648
d_prime: 0.005354
train_loss: 0.484390
valid_loss: 0.736218
validation finished
normal learning rate scheduler step
Epoch-8 lr: 5e-05
Epoch-8 lr: 5e-05
epoch 8 training time: 371.466
---------------
2023-08-02 07:39:31.697847
current #epochs=9, #steps=4136
Epoch: [9][64/517]	Per Sample Total Time 0.07696	Per Sample Data Time 0.00459	Per Sample DNN Time 0.07237	Train Loss 0.4917	
Epoch: [9][164/517]	Per Sample Total Time 0.07458	Per Sample Data Time 0.00213	Per Sample DNN Time 0.07245	Train Loss 0.4860	
Epoch: [9][264/517]	Per Sample Total Time 0.07400	Per Sample Data Time 0.00152	Per Sample DNN Time 0.07248	Train Loss 0.4891	
Epoch: [9][364/517]	Per Sample Total Time 0.07373	Per Sample Data Time 0.00124	Per Sample DNN Time 0.07249	Train Loss 0.4866	
Epoch: [9][464/517]	Per Sample Total Time 0.07358	Per Sample Data Time 0.00109	Per Sample DNN Time 0.07249	Train Loss 0.4851	
start validation
mAP: 0.244256
AUC: 0.490283
Avg Precision: 0.246374
Avg Recall: 0.642551
d_prime: -0.034448
train_loss: 0.484717
valid_loss: 0.745086
validation finished
normal learning rate scheduler step
Epoch-9 lr: 5e-05
Epoch-9 lr: 5e-05
epoch 9 training time: 371.314
---------------
2023-08-02 07:45:43.012313
current #epochs=10, #steps=4653
Epoch: [10][47/517]	Per Sample Total Time 0.07757	Per Sample Data Time 0.00519	Per Sample DNN Time 0.07238	Train Loss 0.4607	
Epoch: [10][147/517]	Per Sample Total Time 0.07449	Per Sample Data Time 0.00206	Per Sample DNN Time 0.07243	Train Loss 0.4742	
Epoch: [10][247/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00144	Per Sample DNN Time 0.07246	Train Loss 0.4830	
Epoch: [10][347/517]	Per Sample Total Time 0.07365	Per Sample Data Time 0.00118	Per Sample DNN Time 0.07247	Train Loss 0.4802	
Epoch: [10][447/517]	Per Sample Total Time 0.07351	Per Sample Data Time 0.00104	Per Sample DNN Time 0.07247	Train Loss 0.4815	
start validation
mAP: 0.255835
AUC: 0.514153
Avg Precision: 0.247046
Avg Recall: 0.667672
d_prime: 0.050182
train_loss: 0.483105
valid_loss: 0.747240
validation finished
normal learning rate scheduler step
Epoch-10 lr: 2.5e-05
Epoch-10 lr: 2.5e-05
epoch 10 training time: 370.966
---------------
2023-08-02 07:51:53.977582
current #epochs=11, #steps=5170
Epoch: [11][30/517]	Per Sample Total Time 0.08025	Per Sample Data Time 0.00789	Per Sample DNN Time 0.07236	Train Loss 0.4790	
Epoch: [11][130/517]	Per Sample Total Time 0.07467	Per Sample Data Time 0.00225	Per Sample DNN Time 0.07242	Train Loss 0.4824	
Epoch: [11][230/517]	Per Sample Total Time 0.07421	Per Sample Data Time 0.00151	Per Sample DNN Time 0.07270	Train Loss 0.4813	
Epoch: [11][330/517]	Per Sample Total Time 0.07395	Per Sample Data Time 0.00122	Per Sample DNN Time 0.07273	Train Loss 0.4777	
Epoch: [11][430/517]	Per Sample Total Time 0.07382	Per Sample Data Time 0.00106	Per Sample DNN Time 0.07275	Train Loss 0.4746	
start validation
mAP: 0.235604
AUC: 0.475115
Avg Precision: 0.232460
Avg Recall: 0.618197
d_prime: -0.088271
train_loss: 0.473966
valid_loss: 0.741985
validation finished
normal learning rate scheduler step
Epoch-11 lr: 2.5e-05
Epoch-11 lr: 2.5e-05
epoch 11 training time: 372.905
---------------
2023-08-02 07:58:06.882984
current #epochs=12, #steps=5687
Epoch: [12][13/517]	Per Sample Total Time 0.08948	Per Sample Data Time 0.01680	Per Sample DNN Time 0.07268	Train Loss 0.4525	
Epoch: [12][113/517]	Per Sample Total Time 0.07526	Per Sample Data Time 0.00251	Per Sample DNN Time 0.07275	Train Loss 0.4729	
Epoch: [12][213/517]	Per Sample Total Time 0.07439	Per Sample Data Time 0.00159	Per Sample DNN Time 0.07280	Train Loss 0.4730	
Epoch: [12][313/517]	Per Sample Total Time 0.07407	Per Sample Data Time 0.00125	Per Sample DNN Time 0.07282	Train Loss 0.4753	
Epoch: [12][413/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00108	Per Sample DNN Time 0.07282	Train Loss 0.4742	
Epoch: [12][513/517]	Per Sample Total Time 0.07379	Per Sample Data Time 0.00098	Per Sample DNN Time 0.07282	Train Loss 0.4725	
start validation
mAP: 0.258695
AUC: 0.523788
Avg Precision: 0.255948
Avg Recall: 0.678356
d_prime: 0.084376
train_loss: 0.472793
valid_loss: 0.744325
validation finished
normal learning rate scheduler step
Epoch-12 lr: 2.5e-05
Epoch-12 lr: 2.5e-05
epoch 12 training time: 373.015
---------------
2023-08-02 08:04:19.899154
current #epochs=13, #steps=6204
Epoch: [13][96/517]	Per Sample Total Time 0.07611	Per Sample Data Time 0.00344	Per Sample DNN Time 0.07267	Train Loss 0.4710	
Epoch: [13][196/517]	Per Sample Total Time 0.07469	Per Sample Data Time 0.00197	Per Sample DNN Time 0.07271	Train Loss 0.4706	
Epoch: [13][296/517]	Per Sample Total Time 0.07423	Per Sample Data Time 0.00149	Per Sample DNN Time 0.07274	Train Loss 0.4716	
Epoch: [13][396/517]	Per Sample Total Time 0.07402	Per Sample Data Time 0.00126	Per Sample DNN Time 0.07276	Train Loss 0.4689	
Epoch: [13][496/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00112	Per Sample DNN Time 0.07277	Train Loss 0.4693	
start validation
mAP: 0.249807
AUC: 0.502539
Avg Precision: 0.243293
Avg Recall: 0.643402
d_prime: 0.009000
train_loss: 0.469647
valid_loss: 0.742013
validation finished
normal learning rate scheduler step
Epoch-13 lr: 2.5e-05
Epoch-13 lr: 2.5e-05
epoch 13 training time: 373.859
---------------
2023-08-02 08:10:33.757653
current #epochs=14, #steps=6721
Epoch: [14][79/517]	Per Sample Total Time 0.07641	Per Sample Data Time 0.00362	Per Sample DNN Time 0.07279	Train Loss 0.4642	
Epoch: [14][179/517]	Per Sample Total Time 0.07491	Per Sample Data Time 0.00191	Per Sample DNN Time 0.07300	Train Loss 0.4550	
Epoch: [14][279/517]	Per Sample Total Time 0.07434	Per Sample Data Time 0.00142	Per Sample DNN Time 0.07292	Train Loss 0.4608	
Epoch: [14][379/517]	Per Sample Total Time 0.07407	Per Sample Data Time 0.00118	Per Sample DNN Time 0.07289	Train Loss 0.4612	
Epoch: [14][479/517]	Per Sample Total Time 0.07392	Per Sample Data Time 0.00105	Per Sample DNN Time 0.07287	Train Loss 0.4628	
start validation
mAP: 0.260605
AUC: 0.516685
Avg Precision: 0.252324
Avg Recall: 0.674539
d_prime: 0.059165
train_loss: 0.462219
valid_loss: 0.736289
validation finished
normal learning rate scheduler step
Epoch-14 lr: 2.5e-05
Epoch-14 lr: 2.5e-05
epoch 14 training time: 373.186
---------------
2023-08-02 08:16:46.943310
current #epochs=15, #steps=7238
Epoch: [15][62/517]	Per Sample Total Time 0.07659	Per Sample Data Time 0.00388	Per Sample DNN Time 0.07272	Train Loss 0.4628	
Epoch: [15][162/517]	Per Sample Total Time 0.07458	Per Sample Data Time 0.00182	Per Sample DNN Time 0.07275	Train Loss 0.4659	
Epoch: [15][262/517]	Per Sample Total Time 0.07411	Per Sample Data Time 0.00134	Per Sample DNN Time 0.07277	Train Loss 0.4608	
Epoch: [15][362/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00113	Per Sample DNN Time 0.07277	Train Loss 0.4583	
Epoch: [15][462/517]	Per Sample Total Time 0.07376	Per Sample Data Time 0.00100	Per Sample DNN Time 0.07276	Train Loss 0.4600	
start validation
mAP: 0.270159
AUC: 0.525127
Avg Precision: 0.254207
Avg Recall: 0.668028
d_prime: 0.089132
train_loss: 0.459135
valid_loss: 0.733844
validation finished
normal learning rate scheduler step
Epoch-15 lr: 1.25e-05
Epoch-15 lr: 1.25e-05
epoch 15 training time: 374.566
---------------
2023-08-02 08:23:01.508749
current #epochs=16, #steps=7755
Epoch: [16][45/517]	Per Sample Total Time 0.07754	Per Sample Data Time 0.00518	Per Sample DNN Time 0.07236	Train Loss 0.4615	
Epoch: [16][145/517]	Per Sample Total Time 0.07447	Per Sample Data Time 0.00199	Per Sample DNN Time 0.07248	Train Loss 0.4477	
Epoch: [16][245/517]	Per Sample Total Time 0.07393	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07254	Train Loss 0.4463	
Epoch: [16][345/517]	Per Sample Total Time 0.07372	Per Sample Data Time 0.00115	Per Sample DNN Time 0.07257	Train Loss 0.4465	
Epoch: [16][445/517]	Per Sample Total Time 0.07361	Per Sample Data Time 0.00102	Per Sample DNN Time 0.07259	Train Loss 0.4470	
start validation
mAP: 0.270920
AUC: 0.530263
Avg Precision: 0.254951
Avg Recall: 0.661806
d_prime: 0.107384
train_loss: 0.447819
valid_loss: 0.740316
validation finished
normal learning rate scheduler step
Epoch-16 lr: 1.25e-05
Epoch-16 lr: 1.25e-05
epoch 16 training time: 374.112
---------------
2023-08-02 08:29:15.620788
current #epochs=17, #steps=8272
Epoch: [17][28/517]	Per Sample Total Time 0.08033	Per Sample Data Time 0.00799	Per Sample DNN Time 0.07234	Train Loss 0.4327	
Epoch: [17][128/517]	Per Sample Total Time 0.07465	Per Sample Data Time 0.00218	Per Sample DNN Time 0.07247	Train Loss 0.4354	
Epoch: [17][228/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00145	Per Sample DNN Time 0.07255	Train Loss 0.4390	
Epoch: [17][328/517]	Per Sample Total Time 0.07376	Per Sample Data Time 0.00117	Per Sample DNN Time 0.07259	Train Loss 0.4383	
Epoch: [17][428/517]	Per Sample Total Time 0.07362	Per Sample Data Time 0.00102	Per Sample DNN Time 0.07260	Train Loss 0.4367	
start validation
mAP: 0.275744
AUC: 0.537529
Avg Precision: 0.259699
Avg Recall: 0.684446
d_prime: 0.133235
train_loss: 0.437572
valid_loss: 0.741854
validation finished
normal learning rate scheduler step
Epoch-17 lr: 1.25e-05
Epoch-17 lr: 1.25e-05
epoch 17 training time: 374.501
---------------
2023-08-02 08:35:30.122240
current #epochs=18, #steps=8789
Epoch: [18][11/517]	Per Sample Total Time 0.09096	Per Sample Data Time 0.01866	Per Sample DNN Time 0.07230	Train Loss 0.4555	
Epoch: [18][111/517]	Per Sample Total Time 0.07491	Per Sample Data Time 0.00245	Per Sample DNN Time 0.07246	Train Loss 0.4334	
Epoch: [18][211/517]	Per Sample Total Time 0.07409	Per Sample Data Time 0.00154	Per Sample DNN Time 0.07255	Train Loss 0.4281	
Epoch: [18][311/517]	Per Sample Total Time 0.07381	Per Sample Data Time 0.00121	Per Sample DNN Time 0.07260	Train Loss 0.4298	
Epoch: [18][411/517]	Per Sample Total Time 0.07365	Per Sample Data Time 0.00104	Per Sample DNN Time 0.07262	Train Loss 0.4302	
Epoch: [18][511/517]	Per Sample Total Time 0.07355	Per Sample Data Time 0.00093	Per Sample DNN Time 0.07262	Train Loss 0.4322	
start validation
mAP: 0.264411
AUC: 0.518188
Avg Precision: 0.251356
Avg Recall: 0.652916
d_prime: 0.064498
train_loss: 0.432817
valid_loss: 0.742653
validation finished
normal learning rate scheduler step
Epoch-18 lr: 1.25e-05
Epoch-18 lr: 1.25e-05
epoch 18 training time: 371.960
---------------
2023-08-02 08:41:42.082290
current #epochs=19, #steps=9306
Epoch: [19][94/517]	Per Sample Total Time 0.07517	Per Sample Data Time 0.00265	Per Sample DNN Time 0.07252	Train Loss 0.4117	
Epoch: [19][194/517]	Per Sample Total Time 0.07413	Per Sample Data Time 0.00156	Per Sample DNN Time 0.07257	Train Loss 0.4157	
Epoch: [19][294/517]	Per Sample Total Time 0.07380	Per Sample Data Time 0.00121	Per Sample DNN Time 0.07259	Train Loss 0.4143	
Epoch: [19][394/517]	Per Sample Total Time 0.07364	Per Sample Data Time 0.00104	Per Sample DNN Time 0.07260	Train Loss 0.4172	
Epoch: [19][494/517]	Per Sample Total Time 0.07354	Per Sample Data Time 0.00094	Per Sample DNN Time 0.07260	Train Loss 0.4195	
start validation
mAP: 0.258208
AUC: 0.513138
Avg Precision: 0.249027
Avg Recall: 0.651667
d_prime: 0.046580
train_loss: 0.419983
valid_loss: 0.746270
validation finished
normal learning rate scheduler step
Epoch-19 lr: 1.25e-05
Epoch-19 lr: 1.25e-05
epoch 19 training time: 371.507
---------------
2023-08-02 08:47:53.589517
current #epochs=20, #steps=9823
Epoch: [20][77/517]	Per Sample Total Time 0.07608	Per Sample Data Time 0.00349	Per Sample DNN Time 0.07259	Train Loss 0.4041	
Epoch: [20][177/517]	Per Sample Total Time 0.07449	Per Sample Data Time 0.00182	Per Sample DNN Time 0.07267	Train Loss 0.4158	
Epoch: [20][277/517]	Per Sample Total Time 0.07409	Per Sample Data Time 0.00137	Per Sample DNN Time 0.07272	Train Loss 0.4140	
Epoch: [20][377/517]	Per Sample Total Time 0.07389	Per Sample Data Time 0.00114	Per Sample DNN Time 0.07275	Train Loss 0.4138	
Epoch: [20][477/517]	Per Sample Total Time 0.07378	Per Sample Data Time 0.00101	Per Sample DNN Time 0.07277	Train Loss 0.4151	
start validation
mAP: 0.266865
AUC: 0.530940
Avg Precision: 0.254154
Avg Recall: 0.660887
d_prime: 0.109788
train_loss: 0.415096
valid_loss: 0.740358
validation finished
normal learning rate scheduler step
Epoch-20 lr: 6.25e-06
Epoch-20 lr: 6.25e-06
epoch 20 training time: 372.583
---------------
2023-08-02 08:54:06.172250
current #epochs=21, #steps=10340
Epoch: [21][60/517]	Per Sample Total Time 0.07700	Per Sample Data Time 0.00434	Per Sample DNN Time 0.07265	Train Loss 0.3752	
Epoch: [21][160/517]	Per Sample Total Time 0.07471	Per Sample Data Time 0.00198	Per Sample DNN Time 0.07273	Train Loss 0.3900	
Epoch: [21][260/517]	Per Sample Total Time 0.07419	Per Sample Data Time 0.00143	Per Sample DNN Time 0.07276	Train Loss 0.3917	
Epoch: [21][360/517]	Per Sample Total Time 0.07397	Per Sample Data Time 0.00119	Per Sample DNN Time 0.07278	Train Loss 0.3936	
Epoch: [21][460/517]	Per Sample Total Time 0.07384	Per Sample Data Time 0.00105	Per Sample DNN Time 0.07279	Train Loss 0.3958	
start validation
mAP: 0.266753
AUC: 0.527349
Avg Precision: 0.254719
Avg Recall: 0.669897
d_prime: 0.097027
train_loss: 0.394280
valid_loss: 0.744913
validation finished
normal learning rate scheduler step
Epoch-21 lr: 6.25e-06
Epoch-21 lr: 6.25e-06
epoch 21 training time: 372.769
---------------
2023-08-02 09:00:18.940782
current #epochs=22, #steps=10857
Epoch: [22][43/517]	Per Sample Total Time 0.07939	Per Sample Data Time 0.00682	Per Sample DNN Time 0.07257	Train Loss 0.4176	
Epoch: [22][143/517]	Per Sample Total Time 0.07508	Per Sample Data Time 0.00243	Per Sample DNN Time 0.07264	Train Loss 0.3998	
Epoch: [22][243/517]	Per Sample Total Time 0.07434	Per Sample Data Time 0.00165	Per Sample DNN Time 0.07269	Train Loss 0.3901	
Epoch: [22][343/517]	Per Sample Total Time 0.07405	Per Sample Data Time 0.00133	Per Sample DNN Time 0.07272	Train Loss 0.3848	
Epoch: [22][443/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00115	Per Sample DNN Time 0.07274	Train Loss 0.3860	
start validation
mAP: 0.251864
AUC: 0.494341
Avg Precision: 0.242189
Avg Recall: 0.618103
d_prime: -0.020060
train_loss: 0.382869
valid_loss: 0.741272
validation finished
normal learning rate scheduler step
Epoch-22 lr: 6.25e-06
Epoch-22 lr: 6.25e-06
epoch 22 training time: 373.688
---------------
2023-08-02 09:06:32.629495
current #epochs=23, #steps=11374
Epoch: [23][26/517]	Per Sample Total Time 0.08155	Per Sample Data Time 0.00891	Per Sample DNN Time 0.07264	Train Loss 0.4036	
Epoch: [23][126/517]	Per Sample Total Time 0.07504	Per Sample Data Time 0.00232	Per Sample DNN Time 0.07272	Train Loss 0.3741	
Epoch: [23][226/517]	Per Sample Total Time 0.07429	Per Sample Data Time 0.00154	Per Sample DNN Time 0.07276	Train Loss 0.3727	
Epoch: [23][326/517]	Per Sample Total Time 0.07400	Per Sample Data Time 0.00123	Per Sample DNN Time 0.07277	Train Loss 0.3763	
Epoch: [23][426/517]	Per Sample Total Time 0.07385	Per Sample Data Time 0.00107	Per Sample DNN Time 0.07278	Train Loss 0.3752	
start validation
mAP: 0.259576
AUC: 0.514099
Avg Precision: 0.250041
Avg Recall: 0.640778
d_prime: 0.049989
train_loss: 0.372499
valid_loss: 0.741403
validation finished
normal learning rate scheduler step
Epoch-23 lr: 6.25e-06
Epoch-23 lr: 6.25e-06
epoch 23 training time: 372.869
---------------
2023-08-02 09:12:45.498615
current #epochs=24, #steps=11891
Epoch: [24][9/517]	Per Sample Total Time 0.09754	Per Sample Data Time 0.02488	Per Sample DNN Time 0.07266	Train Loss 0.3280	
Epoch: [24][109/517]	Per Sample Total Time 0.07544	Per Sample Data Time 0.00272	Per Sample DNN Time 0.07271	Train Loss 0.3501	
Epoch: [24][209/517]	Per Sample Total Time 0.07443	Per Sample Data Time 0.00168	Per Sample DNN Time 0.07275	Train Loss 0.3584	
Epoch: [24][309/517]	Per Sample Total Time 0.07408	Per Sample Data Time 0.00131	Per Sample DNN Time 0.07277	Train Loss 0.3645	
Epoch: [24][409/517]	Per Sample Total Time 0.07392	Per Sample Data Time 0.00113	Per Sample DNN Time 0.07278	Train Loss 0.3639	
Epoch: [24][509/517]	Per Sample Total Time 0.07381	Per Sample Data Time 0.00103	Per Sample DNN Time 0.07278	Train Loss 0.3647	
start validation
mAP: 0.256028
AUC: 0.516118
Avg Precision: 0.249910
Avg Recall: 0.643039
d_prime: 0.057152
train_loss: 0.364378
valid_loss: 0.746203
validation finished
normal learning rate scheduler step
Epoch-24 lr: 6.25e-06
Epoch-24 lr: 6.25e-06
epoch 24 training time: 373.106
---------------
2023-08-02 09:18:58.604772
current #epochs=25, #steps=12408
Epoch: [25][92/517]	Per Sample Total Time 0.07624	Per Sample Data Time 0.00298	Per Sample DNN Time 0.07326	Train Loss 0.3544	
Epoch: [25][192/517]	Per Sample Total Time 0.07510	Per Sample Data Time 0.00172	Per Sample DNN Time 0.07338	Train Loss 0.3620	
Epoch: [25][292/517]	Per Sample Total Time 0.07451	Per Sample Data Time 0.00131	Per Sample DNN Time 0.07320	Train Loss 0.3644	
Epoch: [25][392/517]	Per Sample Total Time 0.07424	Per Sample Data Time 0.00113	Per Sample DNN Time 0.07311	Train Loss 0.3601	
Epoch: [25][492/517]	Per Sample Total Time 0.07406	Per Sample Data Time 0.00101	Per Sample DNN Time 0.07305	Train Loss 0.3593	
start validation
mAP: 0.257823
AUC: 0.515764
Avg Precision: 0.248469
Avg Recall: 0.640777
d_prime: 0.055897
train_loss: 0.358278
valid_loss: 0.743009
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.125e-06
Epoch-25 lr: 3.125e-06
epoch 25 training time: 373.766
---------------Training Finished---------------
weighted averaged models results
mAP: 0.257571
AUC: 0.519471
Avg Precision: 0.250405
Avg Recall: 0.669394
d_prime: 0.069052
train_loss: 0.000000
valid_loss: 0.743009
