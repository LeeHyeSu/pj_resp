pretrained model already downloaded.
I am process 13545, running on d1a9c2cba8d5: starting (Fri Aug  4 15:42:46 2023)
balanced sampler is not used
---------------the train dataloader---------------
now using following mask: 48 freq, 192 time
now using mix-up with rate 0.500000
now process icbhi
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 4
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process icbhi
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 4
Now train with icbhi with 4142 training samples, evaluate with 2756 samples
now load a SSL pretrained models from .//SSAST-Base-Patch-400.pth
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=10, time=10
fine-tuning number of patches=1212

Creating experiment directory: ./exp/230804_2-icbhi-f10-16-t10-16-b8-lr5e-5-ft_avgtok-base--SSAST-Base-Patch-400-1x-noiseFalse-3
Now starting fine-tuning for 50 epochs
running on cuda
Total parameter number is : 87.730 million
Total trainable parameter number is : 87.730 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 87.725 million
now training with icbhi, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fb7f46023a0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-08-04 15:43:03.346466
current #epochs=1, #steps=0
Epoch: [1][100/517]	Per Sample Total Time 0.08517	Per Sample Data Time 0.00168	Per Sample DNN Time 0.08349	Train Loss 0.5141	
Epoch: [1][200/517]	Per Sample Total Time 0.07873	Per Sample Data Time 0.00100	Per Sample DNN Time 0.07773	Train Loss 0.5092	
Epoch: [1][300/517]	Per Sample Total Time 0.07664	Per Sample Data Time 0.00076	Per Sample DNN Time 0.07588	Train Loss 0.5039	
Epoch: [1][400/517]	Per Sample Total Time 0.07563	Per Sample Data Time 0.00065	Per Sample DNN Time 0.07497	Train Loss 0.4999	
Epoch: [1][500/517]	Per Sample Total Time 0.07502	Per Sample Data Time 0.00058	Per Sample DNN Time 0.07444	Train Loss 0.4979	
start validation
mAP: 0.259830
AUC: 0.517385
Avg Precision: 0.257508
Avg Recall: 0.656686
d_prime: 0.061647
train_loss: 0.497901
valid_loss: 0.731024
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-1 lr: 5e-05
Epoch-1 lr: 5e-05
epoch 1 training time: 379.740
---------------
2023-08-04 15:49:23.087719
current #epochs=2, #steps=517
Epoch: [2][83/517]	Per Sample Total Time 0.07548	Per Sample Data Time 0.00346	Per Sample DNN Time 0.07201	Train Loss 0.5066	
Epoch: [2][183/517]	Per Sample Total Time 0.07391	Per Sample Data Time 0.00181	Per Sample DNN Time 0.07210	Train Loss 0.4964	
Epoch: [2][283/517]	Per Sample Total Time 0.07346	Per Sample Data Time 0.00132	Per Sample DNN Time 0.07214	Train Loss 0.4961	
Epoch: [2][383/517]	Per Sample Total Time 0.07325	Per Sample Data Time 0.00108	Per Sample DNN Time 0.07217	Train Loss 0.4943	
Epoch: [2][483/517]	Per Sample Total Time 0.07311	Per Sample Data Time 0.00094	Per Sample DNN Time 0.07217	Train Loss 0.4910	
start validation
mAP: 0.265625
AUC: 0.527903
Avg Precision: 0.259045
Avg Recall: 0.682568
d_prime: 0.098994
train_loss: 0.491699
valid_loss: 0.734513
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-2 lr: 5e-05
Epoch-2 lr: 5e-05
epoch 2 training time: 371.497
---------------
2023-08-04 15:55:34.584409
current #epochs=3, #steps=1034
Epoch: [3][66/517]	Per Sample Total Time 0.07776	Per Sample Data Time 0.00580	Per Sample DNN Time 0.07196	Train Loss 0.4917	
Epoch: [3][166/517]	Per Sample Total Time 0.07477	Per Sample Data Time 0.00273	Per Sample DNN Time 0.07205	Train Loss 0.4875	
Epoch: [3][266/517]	Per Sample Total Time 0.07403	Per Sample Data Time 0.00193	Per Sample DNN Time 0.07210	Train Loss 0.4906	
Epoch: [3][366/517]	Per Sample Total Time 0.07369	Per Sample Data Time 0.00156	Per Sample DNN Time 0.07213	Train Loss 0.4904	
Epoch: [3][466/517]	Per Sample Total Time 0.07348	Per Sample Data Time 0.00133	Per Sample DNN Time 0.07214	Train Loss 0.4892	
start validation
mAP: 0.266944
AUC: 0.525911
Avg Precision: 0.264491
Avg Recall: 0.668600
d_prime: 0.091918
train_loss: 0.489951
valid_loss: 0.735367
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-3 lr: 5e-05
Epoch-3 lr: 5e-05
epoch 3 training time: 374.841
---------------
2023-08-04 16:01:49.426041
current #epochs=4, #steps=1551
Epoch: [4][49/517]	Per Sample Total Time 0.08053	Per Sample Data Time 0.00847	Per Sample DNN Time 0.07206	Train Loss 0.4880	
Epoch: [4][149/517]	Per Sample Total Time 0.07539	Per Sample Data Time 0.00319	Per Sample DNN Time 0.07221	Train Loss 0.4932	
Epoch: [4][249/517]	Per Sample Total Time 0.07441	Per Sample Data Time 0.00212	Per Sample DNN Time 0.07229	Train Loss 0.4969	
Epoch: [4][349/517]	Per Sample Total Time 0.07400	Per Sample Data Time 0.00167	Per Sample DNN Time 0.07234	Train Loss 0.4926	
Epoch: [4][449/517]	Per Sample Total Time 0.07377	Per Sample Data Time 0.00142	Per Sample DNN Time 0.07236	Train Loss 0.4931	
start validation
mAP: 0.253735
AUC: 0.505760
Avg Precision: 0.255470
Avg Recall: 0.647571
d_prime: 0.020420
train_loss: 0.492057
valid_loss: 0.738144
S_p: 71.24762507915952, S_e: 10.875106202208082, Score: 41.0613656406838
validation finished
normal learning rate scheduler step
Epoch-4 lr: 5e-05
Epoch-4 lr: 5e-05
epoch 4 training time: 373.331
---------------
2023-08-04 16:08:02.756551
current #epochs=5, #steps=2068
Epoch: [5][32/517]	Per Sample Total Time 0.08428	Per Sample Data Time 0.01202	Per Sample DNN Time 0.07226	Train Loss 0.4807	
Epoch: [5][132/517]	Per Sample Total Time 0.07571	Per Sample Data Time 0.00340	Per Sample DNN Time 0.07230	Train Loss 0.4893	
Epoch: [5][232/517]	Per Sample Total Time 0.07451	Per Sample Data Time 0.00219	Per Sample DNN Time 0.07232	Train Loss 0.4842	
Epoch: [5][332/517]	Per Sample Total Time 0.07402	Per Sample Data Time 0.00170	Per Sample DNN Time 0.07232	Train Loss 0.4847	
Epoch: [5][432/517]	Per Sample Total Time 0.07377	Per Sample Data Time 0.00144	Per Sample DNN Time 0.07233	Train Loss 0.4879	
start validation
mAP: 0.251837
AUC: 0.507658
Avg Precision: 0.256487
Avg Recall: 0.664977
d_prime: 0.027148
train_loss: 0.488342
valid_loss: 0.736576
S_p: 99.99999999999366, S_e: 0.2548853016142519, Score: 50.12744265080396
validation finished
normal learning rate scheduler step
Epoch-5 lr: 5e-05
Epoch-5 lr: 5e-05
epoch 5 training time: 373.125
---------------
2023-08-04 16:14:15.881180
current #epochs=6, #steps=2585
Epoch: [6][15/517]	Per Sample Total Time 0.09578	Per Sample Data Time 0.02372	Per Sample DNN Time 0.07206	Train Loss 0.5228	
Epoch: [6][115/517]	Per Sample Total Time 0.07594	Per Sample Data Time 0.00374	Per Sample DNN Time 0.07220	Train Loss 0.4929	
Epoch: [6][215/517]	Per Sample Total Time 0.07451	Per Sample Data Time 0.00226	Per Sample DNN Time 0.07225	Train Loss 0.4862	
Epoch: [6][315/517]	Per Sample Total Time 0.07399	Per Sample Data Time 0.00172	Per Sample DNN Time 0.07227	Train Loss 0.4860	
Epoch: [6][415/517]	Per Sample Total Time 0.07372	Per Sample Data Time 0.00144	Per Sample DNN Time 0.07228	Train Loss 0.4864	
Epoch: [6][515/517]	Per Sample Total Time 0.07354	Per Sample Data Time 0.00126	Per Sample DNN Time 0.07228	Train Loss 0.4881	
start validation
mAP: 0.256644
AUC: 0.504430
Avg Precision: 0.254677
Avg Recall: 0.654858
d_prime: 0.015703
train_loss: 0.488047
valid_loss: 0.735282
S_p: 98.67004433184935, S_e: 0.5097706032285038, Score: 49.58990746753893
validation finished
normal learning rate scheduler step
Epoch-6 lr: 5e-05
Epoch-6 lr: 5e-05
epoch 6 training time: 372.513
---------------
2023-08-04 16:20:28.394053
current #epochs=7, #steps=3102
Epoch: [7][98/517]	Per Sample Total Time 0.07559	Per Sample Data Time 0.00346	Per Sample DNN Time 0.07213	Train Loss 0.4831	
Epoch: [7][198/517]	Per Sample Total Time 0.07417	Per Sample Data Time 0.00199	Per Sample DNN Time 0.07218	Train Loss 0.4849	
Epoch: [7][298/517]	Per Sample Total Time 0.07371	Per Sample Data Time 0.00150	Per Sample DNN Time 0.07221	Train Loss 0.4831	
Epoch: [7][398/517]	Per Sample Total Time 0.07348	Per Sample Data Time 0.00125	Per Sample DNN Time 0.07223	Train Loss 0.4813	
Epoch: [7][498/517]	Per Sample Total Time 0.07335	Per Sample Data Time 0.00110	Per Sample DNN Time 0.07224	Train Loss 0.4834	
start validation
mAP: 0.277430
AUC: 0.547331
Avg Precision: 0.262358
Avg Recall: 0.681943
d_prime: 0.168181
train_loss: 0.483348
valid_loss: 0.734292
S_p: 98.73337555414194, S_e: 0.7646559048427557, Score: 49.74901572949235
validation finished
normal learning rate scheduler step
Epoch-7 lr: 5e-05
Epoch-7 lr: 5e-05
epoch 7 training time: 373.281
---------------
2023-08-04 16:26:41.674707
current #epochs=8, #steps=3619
Epoch: [8][81/517]	Per Sample Total Time 0.07672	Per Sample Data Time 0.00465	Per Sample DNN Time 0.07208	Train Loss 0.4859	
Epoch: [8][181/517]	Per Sample Total Time 0.07451	Per Sample Data Time 0.00235	Per Sample DNN Time 0.07216	Train Loss 0.4753	
Epoch: [8][281/517]	Per Sample Total Time 0.07392	Per Sample Data Time 0.00171	Per Sample DNN Time 0.07221	Train Loss 0.4781	
Epoch: [8][381/517]	Per Sample Total Time 0.07364	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07224	Train Loss 0.4807	
Epoch: [8][481/517]	Per Sample Total Time 0.07347	Per Sample Data Time 0.00121	Per Sample DNN Time 0.07226	Train Loss 0.4830	
start validation
mAP: 0.266883
AUC: 0.534462
Avg Precision: 0.254418
Avg Recall: 0.672536
d_prime: 0.122318
train_loss: 0.482823
valid_loss: 0.731934
S_p: 97.34008866370503, S_e: 1.444350042480761, Score: 49.3922193530929
validation finished
normal learning rate scheduler step
Epoch-8 lr: 5e-05
Epoch-8 lr: 5e-05
epoch 8 training time: 371.761
---------------
2023-08-04 16:32:53.435762
current #epochs=9, #steps=4136
Epoch: [9][64/517]	Per Sample Total Time 0.07855	Per Sample Data Time 0.00641	Per Sample DNN Time 0.07214	Train Loss 0.4811	
Epoch: [9][164/517]	Per Sample Total Time 0.07505	Per Sample Data Time 0.00284	Per Sample DNN Time 0.07222	Train Loss 0.4862	
Epoch: [9][264/517]	Per Sample Total Time 0.07420	Per Sample Data Time 0.00195	Per Sample DNN Time 0.07225	Train Loss 0.4841	
Epoch: [9][364/517]	Per Sample Total Time 0.07381	Per Sample Data Time 0.00154	Per Sample DNN Time 0.07227	Train Loss 0.4811	
Epoch: [9][464/517]	Per Sample Total Time 0.07359	Per Sample Data Time 0.00131	Per Sample DNN Time 0.07228	Train Loss 0.4822	
start validation
mAP: 0.251586
AUC: 0.513787
Avg Precision: 0.246059
Avg Recall: 0.641878
d_prime: 0.048882
train_loss: 0.482240
valid_loss: 0.736711
S_p: 85.1171627612359, S_e: 5.26762956669454, Score: 45.19239616396522
validation finished
normal learning rate scheduler step
Epoch-9 lr: 5e-05
Epoch-9 lr: 5e-05
epoch 9 training time: 371.897
---------------
2023-08-04 16:39:05.333506
current #epochs=10, #steps=4653
Epoch: [10][47/517]	Per Sample Total Time 0.08002	Per Sample Data Time 0.00791	Per Sample DNN Time 0.07211	Train Loss 0.4869	
Epoch: [10][147/517]	Per Sample Total Time 0.07504	Per Sample Data Time 0.00284	Per Sample DNN Time 0.07220	Train Loss 0.4808	
Epoch: [10][247/517]	Per Sample Total Time 0.07412	Per Sample Data Time 0.00186	Per Sample DNN Time 0.07226	Train Loss 0.4831	
Epoch: [10][347/517]	Per Sample Total Time 0.07378	Per Sample Data Time 0.00148	Per Sample DNN Time 0.07230	Train Loss 0.4828	
Epoch: [10][447/517]	Per Sample Total Time 0.07361	Per Sample Data Time 0.00127	Per Sample DNN Time 0.07234	Train Loss 0.4809	
start validation
mAP: 0.256442
AUC: 0.516708
Avg Precision: 0.247540
Avg Recall: 0.652622
d_prime: 0.059245
train_loss: 0.479586
valid_loss: 0.735543
S_p: 75.99746675110349, S_e: 7.90144435004181, Score: 41.94945555057265
validation finished
normal learning rate scheduler step
Epoch-10 lr: 2.5e-05
Epoch-10 lr: 2.5e-05
epoch 10 training time: 373.311
---------------
2023-08-04 16:45:18.644695
current #epochs=11, #steps=5170
Epoch: [11][30/517]	Per Sample Total Time 0.08500	Per Sample Data Time 0.01274	Per Sample DNN Time 0.07226	Train Loss 0.4538	
Epoch: [11][130/517]	Per Sample Total Time 0.07585	Per Sample Data Time 0.00346	Per Sample DNN Time 0.07238	Train Loss 0.4604	
Epoch: [11][230/517]	Per Sample Total Time 0.07465	Per Sample Data Time 0.00221	Per Sample DNN Time 0.07244	Train Loss 0.4678	
Epoch: [11][330/517]	Per Sample Total Time 0.07417	Per Sample Data Time 0.00171	Per Sample DNN Time 0.07246	Train Loss 0.4701	
Epoch: [11][430/517]	Per Sample Total Time 0.07393	Per Sample Data Time 0.00144	Per Sample DNN Time 0.07248	Train Loss 0.4698	
start validation
mAP: 0.260978
AUC: 0.527550
Avg Precision: 0.248362
Avg Recall: 0.667842
d_prime: 0.097741
train_loss: 0.473085
valid_loss: 0.740911
S_p: 66.11779607346003, S_e: 11.809685641460337, Score: 38.96374085746018
validation finished
normal learning rate scheduler step
Epoch-11 lr: 2.5e-05
Epoch-11 lr: 2.5e-05
epoch 11 training time: 374.335
---------------
2023-08-04 16:51:32.979554
current #epochs=12, #steps=5687
Epoch: [12][13/517]	Per Sample Total Time 0.10352	Per Sample Data Time 0.03133	Per Sample DNN Time 0.07219	Train Loss 0.4851	
Epoch: [12][113/517]	Per Sample Total Time 0.07671	Per Sample Data Time 0.00430	Per Sample DNN Time 0.07241	Train Loss 0.4674	
Epoch: [12][213/517]	Per Sample Total Time 0.07500	Per Sample Data Time 0.00254	Per Sample DNN Time 0.07246	Train Loss 0.4704	
Epoch: [12][313/517]	Per Sample Total Time 0.07440	Per Sample Data Time 0.00190	Per Sample DNN Time 0.07250	Train Loss 0.4723	
Epoch: [12][413/517]	Per Sample Total Time 0.07410	Per Sample Data Time 0.00157	Per Sample DNN Time 0.07253	Train Loss 0.4713	
Epoch: [12][513/517]	Per Sample Total Time 0.07391	Per Sample Data Time 0.00137	Per Sample DNN Time 0.07253	Train Loss 0.4687	
start validation
mAP: 0.271148
AUC: 0.547338
Avg Precision: 0.255171
Avg Recall: 0.683995
d_prime: 0.168204
train_loss: 0.468755
valid_loss: 0.735053
S_p: 72.64091196959642, S_e: 9.770603228546323, Score: 41.20575759907137
validation finished
normal learning rate scheduler step
Epoch-12 lr: 2.5e-05
Epoch-12 lr: 2.5e-05
epoch 12 training time: 374.588
---------------
2023-08-04 16:57:47.567849
current #epochs=13, #steps=6204
Epoch: [13][96/517]	Per Sample Total Time 0.07691	Per Sample Data Time 0.00453	Per Sample DNN Time 0.07237	Train Loss 0.4683	
Epoch: [13][196/517]	Per Sample Total Time 0.07494	Per Sample Data Time 0.00251	Per Sample DNN Time 0.07243	Train Loss 0.4727	
Epoch: [13][296/517]	Per Sample Total Time 0.07431	Per Sample Data Time 0.00183	Per Sample DNN Time 0.07248	Train Loss 0.4690	
Epoch: [13][396/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00150	Per Sample DNN Time 0.07251	Train Loss 0.4685	
Epoch: [13][496/517]	Per Sample Total Time 0.07382	Per Sample Data Time 0.00130	Per Sample DNN Time 0.07252	Train Loss 0.4664	
start validation
mAP: 0.269051
AUC: 0.543268
Avg Precision: 0.256660
Avg Recall: 0.685118
d_prime: 0.153684
train_loss: 0.467058
valid_loss: 0.738727
S_p: 85.49715009499141, S_e: 6.202209005946797, Score: 45.849679550469105
validation finished
normal learning rate scheduler step
Epoch-13 lr: 2.5e-05
Epoch-13 lr: 2.5e-05
epoch 13 training time: 374.052
---------------
2023-08-04 17:04:01.619361
current #epochs=14, #steps=6721
Epoch: [14][79/517]	Per Sample Total Time 0.07758	Per Sample Data Time 0.00521	Per Sample DNN Time 0.07237	Train Loss 0.4784	
Epoch: [14][179/517]	Per Sample Total Time 0.07508	Per Sample Data Time 0.00262	Per Sample DNN Time 0.07246	Train Loss 0.4696	
Epoch: [14][279/517]	Per Sample Total Time 0.07439	Per Sample Data Time 0.00187	Per Sample DNN Time 0.07252	Train Loss 0.4677	
Epoch: [14][379/517]	Per Sample Total Time 0.07406	Per Sample Data Time 0.00152	Per Sample DNN Time 0.07254	Train Loss 0.4653	
Epoch: [14][479/517]	Per Sample Total Time 0.07387	Per Sample Data Time 0.00131	Per Sample DNN Time 0.07256	Train Loss 0.4652	
start validation
mAP: 0.263639
AUC: 0.521758
Avg Precision: 0.249548
Avg Recall: 0.658368
d_prime: 0.077169
train_loss: 0.465341
valid_loss: 0.733687
S_p: 72.32425585813348, S_e: 9.005947323703566, Score: 40.665101590918525
validation finished
normal learning rate scheduler step
Epoch-14 lr: 2.5e-05
Epoch-14 lr: 2.5e-05
epoch 14 training time: 374.172
---------------
2023-08-04 17:10:15.792024
current #epochs=15, #steps=7238
Epoch: [15][62/517]	Per Sample Total Time 0.07907	Per Sample Data Time 0.00677	Per Sample DNN Time 0.07230	Train Loss 0.4642	
Epoch: [15][162/517]	Per Sample Total Time 0.07537	Per Sample Data Time 0.00296	Per Sample DNN Time 0.07242	Train Loss 0.4614	
Epoch: [15][262/517]	Per Sample Total Time 0.07450	Per Sample Data Time 0.00203	Per Sample DNN Time 0.07247	Train Loss 0.4618	
Epoch: [15][362/517]	Per Sample Total Time 0.07412	Per Sample Data Time 0.00163	Per Sample DNN Time 0.07249	Train Loss 0.4632	
Epoch: [15][462/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07251	Train Loss 0.4660	
start validation
mAP: 0.269296
AUC: 0.535553
Avg Precision: 0.254261
Avg Recall: 0.680232
d_prime: 0.126199
train_loss: 0.465145
valid_loss: 0.736416
S_p: 86.63711209625798, S_e: 7.051826677994303, Score: 46.84446938712614
validation finished
normal learning rate scheduler step
Epoch-15 lr: 1.25e-05
Epoch-15 lr: 1.25e-05
epoch 15 training time: 374.252
---------------
2023-08-04 17:16:30.044238
current #epochs=16, #steps=7755
Epoch: [16][45/517]	Per Sample Total Time 0.08115	Per Sample Data Time 0.00878	Per Sample DNN Time 0.07237	Train Loss 0.4450	
Epoch: [16][145/517]	Per Sample Total Time 0.07558	Per Sample Data Time 0.00313	Per Sample DNN Time 0.07244	Train Loss 0.4533	
Epoch: [16][245/517]	Per Sample Total Time 0.07459	Per Sample Data Time 0.00208	Per Sample DNN Time 0.07251	Train Loss 0.4562	
Epoch: [16][345/517]	Per Sample Total Time 0.07418	Per Sample Data Time 0.00164	Per Sample DNN Time 0.07254	Train Loss 0.4575	
Epoch: [16][445/517]	Per Sample Total Time 0.07395	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07256	Train Loss 0.4580	
start validation
mAP: 0.269572
AUC: 0.542178
Avg Precision: 0.257254
Avg Recall: 0.676065
d_prime: 0.149797
train_loss: 0.457935
valid_loss: 0.737000
S_p: 79.16402786573279, S_e: 8.326253186065562, Score: 43.745140525899174
validation finished
normal learning rate scheduler step
Epoch-16 lr: 1.25e-05
Epoch-16 lr: 1.25e-05
epoch 16 training time: 374.238
---------------
2023-08-04 17:22:44.282387
current #epochs=17, #steps=8272
Epoch: [17][28/517]	Per Sample Total Time 0.08618	Per Sample Data Time 0.01386	Per Sample DNN Time 0.07232	Train Loss 0.4280	
Epoch: [17][128/517]	Per Sample Total Time 0.07592	Per Sample Data Time 0.00352	Per Sample DNN Time 0.07241	Train Loss 0.4425	
Epoch: [17][228/517]	Per Sample Total Time 0.07466	Per Sample Data Time 0.00221	Per Sample DNN Time 0.07245	Train Loss 0.4472	
Epoch: [17][328/517]	Per Sample Total Time 0.07418	Per Sample Data Time 0.00170	Per Sample DNN Time 0.07249	Train Loss 0.4494	
Epoch: [17][428/517]	Per Sample Total Time 0.07393	Per Sample Data Time 0.00142	Per Sample DNN Time 0.07251	Train Loss 0.4488	
start validation
mAP: 0.271412
AUC: 0.536570
Avg Precision: 0.255056
Avg Recall: 0.675243
d_prime: 0.129821
train_loss: 0.447745
valid_loss: 0.740656
S_p: 62.31792273590485, S_e: 16.05777400169787, Score: 39.18784836880136
validation finished
normal learning rate scheduler step
Epoch-17 lr: 1.25e-05
Epoch-17 lr: 1.25e-05
epoch 17 training time: 374.150
---------------
2023-08-04 17:28:58.432269
current #epochs=18, #steps=8789
Epoch: [18][11/517]	Per Sample Total Time 0.10542	Per Sample Data Time 0.03319	Per Sample DNN Time 0.07222	Train Loss 0.4386	
Epoch: [18][111/517]	Per Sample Total Time 0.07638	Per Sample Data Time 0.00399	Per Sample DNN Time 0.07239	Train Loss 0.4502	
Epoch: [18][211/517]	Per Sample Total Time 0.07482	Per Sample Data Time 0.00236	Per Sample DNN Time 0.07247	Train Loss 0.4500	
Epoch: [18][311/517]	Per Sample Total Time 0.07427	Per Sample Data Time 0.00176	Per Sample DNN Time 0.07251	Train Loss 0.4483	
Epoch: [18][411/517]	Per Sample Total Time 0.07400	Per Sample Data Time 0.00147	Per Sample DNN Time 0.07254	Train Loss 0.4458	
Epoch: [18][511/517]	Per Sample Total Time 0.07383	Per Sample Data Time 0.00128	Per Sample DNN Time 0.07255	Train Loss 0.4460	
start validation
mAP: 0.271338
AUC: 0.536253
Avg Precision: 0.256975
Avg Recall: 0.673845
d_prime: 0.128691
train_loss: 0.446263
valid_loss: 0.743165
S_p: 59.594680177323646, S_e: 17.33220050976913, Score: 38.46344034354639
validation finished
normal learning rate scheduler step
Epoch-18 lr: 1.25e-05
Epoch-18 lr: 1.25e-05
epoch 18 training time: 374.238
---------------
2023-08-04 17:35:12.670355
current #epochs=19, #steps=9306
Epoch: [19][94/517]	Per Sample Total Time 0.07726	Per Sample Data Time 0.00485	Per Sample DNN Time 0.07240	Train Loss 0.4550	
Epoch: [19][194/517]	Per Sample Total Time 0.07511	Per Sample Data Time 0.00264	Per Sample DNN Time 0.07247	Train Loss 0.4435	
Epoch: [19][294/517]	Per Sample Total Time 0.07441	Per Sample Data Time 0.00192	Per Sample DNN Time 0.07249	Train Loss 0.4473	
Epoch: [19][394/517]	Per Sample Total Time 0.07408	Per Sample Data Time 0.00156	Per Sample DNN Time 0.07251	Train Loss 0.4428	
Epoch: [19][494/517]	Per Sample Total Time 0.07387	Per Sample Data Time 0.00135	Per Sample DNN Time 0.07252	Train Loss 0.4439	
start validation
mAP: 0.272117
AUC: 0.537490
Avg Precision: 0.258497
Avg Recall: 0.678823
d_prime: 0.133093
train_loss: 0.443399
valid_loss: 0.739354
S_p: 72.70424319188899, S_e: 13.254035683941098, Score: 42.979139437915045
validation finished
normal learning rate scheduler step
Epoch-19 lr: 1.25e-05
Epoch-19 lr: 1.25e-05
epoch 19 training time: 373.604
---------------
2023-08-04 17:41:26.274122
current #epochs=20, #steps=9823
Epoch: [20][77/517]	Per Sample Total Time 0.07787	Per Sample Data Time 0.00553	Per Sample DNN Time 0.07234	Train Loss 0.4355	
Epoch: [20][177/517]	Per Sample Total Time 0.07517	Per Sample Data Time 0.00273	Per Sample DNN Time 0.07244	Train Loss 0.4391	
Epoch: [20][277/517]	Per Sample Total Time 0.07443	Per Sample Data Time 0.00193	Per Sample DNN Time 0.07250	Train Loss 0.4417	
Epoch: [20][377/517]	Per Sample Total Time 0.07408	Per Sample Data Time 0.00156	Per Sample DNN Time 0.07252	Train Loss 0.4421	
Epoch: [20][477/517]	Per Sample Total Time 0.07388	Per Sample Data Time 0.00134	Per Sample DNN Time 0.07253	Train Loss 0.4410	
start validation
mAP: 0.267125
AUC: 0.519959
Avg Precision: 0.253927
Avg Recall: 0.656333
d_prime: 0.070784
train_loss: 0.440324
valid_loss: 0.740982
S_p: 63.0145661811233, S_e: 18.52166525063564, Score: 40.76811571587947
validation finished
normal learning rate scheduler step
Epoch-20 lr: 6.25e-06
Epoch-20 lr: 6.25e-06
epoch 20 training time: 374.066
---------------
2023-08-04 17:47:40.340630
current #epochs=21, #steps=10340
Epoch: [21][60/517]	Per Sample Total Time 0.07928	Per Sample Data Time 0.00696	Per Sample DNN Time 0.07231	Train Loss 0.4294	
Epoch: [21][160/517]	Per Sample Total Time 0.07536	Per Sample Data Time 0.00295	Per Sample DNN Time 0.07241	Train Loss 0.4370	
Epoch: [21][260/517]	Per Sample Total Time 0.07448	Per Sample Data Time 0.00202	Per Sample DNN Time 0.07246	Train Loss 0.4352	
Epoch: [21][360/517]	Per Sample Total Time 0.07411	Per Sample Data Time 0.00161	Per Sample DNN Time 0.07250	Train Loss 0.4282	
Epoch: [21][460/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00138	Per Sample DNN Time 0.07252	Train Loss 0.4288	
start validation
mAP: 0.269041
AUC: 0.536801
Avg Precision: 0.258230
Avg Recall: 0.671987
d_prime: 0.130641
train_loss: 0.427722
valid_loss: 0.742836
S_p: 56.1114629512314, S_e: 23.364485981306427, Score: 39.737974466268916
validation finished
normal learning rate scheduler step
Epoch-21 lr: 6.25e-06
Epoch-21 lr: 6.25e-06
epoch 21 training time: 373.944
---------------
2023-08-04 17:53:54.284825
current #epochs=22, #steps=10857
Epoch: [22][43/517]	Per Sample Total Time 0.08160	Per Sample Data Time 0.00928	Per Sample DNN Time 0.07232	Train Loss 0.4245	
Epoch: [22][143/517]	Per Sample Total Time 0.07561	Per Sample Data Time 0.00320	Per Sample DNN Time 0.07241	Train Loss 0.4234	
Epoch: [22][243/517]	Per Sample Total Time 0.07457	Per Sample Data Time 0.00210	Per Sample DNN Time 0.07247	Train Loss 0.4232	
Epoch: [22][343/517]	Per Sample Total Time 0.07416	Per Sample Data Time 0.00164	Per Sample DNN Time 0.07253	Train Loss 0.4242	
Epoch: [22][443/517]	Per Sample Total Time 0.07394	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07256	Train Loss 0.4227	
start validation
mAP: 0.261102
AUC: 0.522128
Avg Precision: 0.253578
Avg Recall: 0.661209
d_prime: 0.078482
train_loss: 0.421332
valid_loss: 0.744774
S_p: 58.32805573147192, S_e: 18.77655055224989, Score: 38.552303141860904
validation finished
normal learning rate scheduler step
Epoch-22 lr: 6.25e-06
Epoch-22 lr: 6.25e-06
epoch 22 training time: 373.936
---------------
2023-08-04 18:00:08.220772
current #epochs=23, #steps=11374
Epoch: [23][26/517]	Per Sample Total Time 0.08734	Per Sample Data Time 0.01504	Per Sample DNN Time 0.07230	Train Loss 0.4292	
Epoch: [23][126/517]	Per Sample Total Time 0.07598	Per Sample Data Time 0.00358	Per Sample DNN Time 0.07241	Train Loss 0.4165	
Epoch: [23][226/517]	Per Sample Total Time 0.07470	Per Sample Data Time 0.00224	Per Sample DNN Time 0.07246	Train Loss 0.4187	
Epoch: [23][326/517]	Per Sample Total Time 0.07421	Per Sample Data Time 0.00172	Per Sample DNN Time 0.07249	Train Loss 0.4162	
Epoch: [23][426/517]	Per Sample Total Time 0.07395	Per Sample Data Time 0.00145	Per Sample DNN Time 0.07251	Train Loss 0.4147	
start validation
mAP: 0.268247
AUC: 0.532895
Avg Precision: 0.257600
Avg Recall: 0.665085
d_prime: 0.116742
train_loss: 0.415157
valid_loss: 0.743448
S_p: 54.021532615576064, S_e: 23.534409515715925, Score: 38.77797106564599
validation finished
normal learning rate scheduler step
Epoch-23 lr: 6.25e-06
Epoch-23 lr: 6.25e-06
epoch 23 training time: 373.733
---------------
2023-08-04 18:06:21.954183
current #epochs=24, #steps=11891
Epoch: [24][9/517]	Per Sample Total Time 0.11080	Per Sample Data Time 0.03854	Per Sample DNN Time 0.07225	Train Loss 0.4149	
Epoch: [24][109/517]	Per Sample Total Time 0.07635	Per Sample Data Time 0.00393	Per Sample DNN Time 0.07242	Train Loss 0.4242	
Epoch: [24][209/517]	Per Sample Total Time 0.07479	Per Sample Data Time 0.00231	Per Sample DNN Time 0.07248	Train Loss 0.4164	
Epoch: [24][309/517]	Per Sample Total Time 0.07426	Per Sample Data Time 0.00174	Per Sample DNN Time 0.07253	Train Loss 0.4132	
Epoch: [24][409/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00144	Per Sample DNN Time 0.07257	Train Loss 0.4097	
Epoch: [24][509/517]	Per Sample Total Time 0.07385	Per Sample Data Time 0.00127	Per Sample DNN Time 0.07258	Train Loss 0.4082	
start validation
mAP: 0.261455
AUC: 0.520180
Avg Precision: 0.253437
Avg Recall: 0.649665
d_prime: 0.071566
train_loss: 0.407740
valid_loss: 0.741754
S_p: 62.1279290690271, S_e: 20.050977060321152, Score: 41.089453064674125
validation finished
normal learning rate scheduler step
Epoch-24 lr: 6.25e-06
Epoch-24 lr: 6.25e-06
epoch 24 training time: 374.556
---------------
2023-08-04 18:12:36.509189
current #epochs=25, #steps=12408
Epoch: [25][92/517]	Per Sample Total Time 0.07705	Per Sample Data Time 0.00467	Per Sample DNN Time 0.07238	Train Loss 0.3851	
Epoch: [25][192/517]	Per Sample Total Time 0.07497	Per Sample Data Time 0.00252	Per Sample DNN Time 0.07245	Train Loss 0.3981	
Epoch: [25][292/517]	Per Sample Total Time 0.07433	Per Sample Data Time 0.00184	Per Sample DNN Time 0.07249	Train Loss 0.4008	
Epoch: [25][392/517]	Per Sample Total Time 0.07402	Per Sample Data Time 0.00150	Per Sample DNN Time 0.07252	Train Loss 0.3977	
Epoch: [25][492/517]	Per Sample Total Time 0.07384	Per Sample Data Time 0.00131	Per Sample DNN Time 0.07253	Train Loss 0.3980	
start validation
mAP: 0.263448
AUC: 0.518539
Avg Precision: 0.253584
Avg Recall: 0.649601
d_prime: 0.065744
train_loss: 0.398190
valid_loss: 0.741139
S_p: 58.51804939834968, S_e: 22.76975361087317, Score: 40.64390150461143
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.125e-06
Epoch-25 lr: 3.125e-06
epoch 25 training time: 374.157
---------------
2023-08-04 18:18:50.666491
current #epochs=26, #steps=12925
Epoch: [26][75/517]	Per Sample Total Time 0.07830	Per Sample Data Time 0.00594	Per Sample DNN Time 0.07236	Train Loss 0.3921	
Epoch: [26][175/517]	Per Sample Total Time 0.07533	Per Sample Data Time 0.00287	Per Sample DNN Time 0.07246	Train Loss 0.3924	
Epoch: [26][275/517]	Per Sample Total Time 0.07453	Per Sample Data Time 0.00202	Per Sample DNN Time 0.07252	Train Loss 0.3898	
Epoch: [26][375/517]	Per Sample Total Time 0.07418	Per Sample Data Time 0.00162	Per Sample DNN Time 0.07256	Train Loss 0.3879	
Epoch: [26][475/517]	Per Sample Total Time 0.07397	Per Sample Data Time 0.00140	Per Sample DNN Time 0.07257	Train Loss 0.3876	
start validation
mAP: 0.265306
AUC: 0.527432
Avg Precision: 0.256990
Avg Recall: 0.665428
d_prime: 0.097320
train_loss: 0.387571
valid_loss: 0.745362
S_p: 54.21152628245382, S_e: 23.364485981306427, Score: 38.788006131880124
validation finished
normal learning rate scheduler step
Epoch-26 lr: 3.125e-06
Epoch-26 lr: 3.125e-06
epoch 26 training time: 374.497
---------------
2023-08-04 18:25:05.163947
current #epochs=27, #steps=13442
Epoch: [27][58/517]	Per Sample Total Time 0.07975	Per Sample Data Time 0.00740	Per Sample DNN Time 0.07235	Train Loss 0.3983	
Epoch: [27][158/517]	Per Sample Total Time 0.07551	Per Sample Data Time 0.00307	Per Sample DNN Time 0.07244	Train Loss 0.3933	
Epoch: [27][258/517]	Per Sample Total Time 0.07458	Per Sample Data Time 0.00209	Per Sample DNN Time 0.07249	Train Loss 0.3833	
Epoch: [27][358/517]	Per Sample Total Time 0.07418	Per Sample Data Time 0.00166	Per Sample DNN Time 0.07252	Train Loss 0.3874	
Epoch: [27][458/517]	Per Sample Total Time 0.07396	Per Sample Data Time 0.00142	Per Sample DNN Time 0.07254	Train Loss 0.3882	
start validation
mAP: 0.266351
AUC: 0.525952
Avg Precision: 0.257460
Avg Recall: 0.659764
d_prime: 0.092064
train_loss: 0.385964
valid_loss: 0.742240
S_p: 55.47815072830554, S_e: 24.723874256582434, Score: 40.101012492443985
validation finished
normal learning rate scheduler step
Epoch-27 lr: 3.125e-06
Epoch-27 lr: 3.125e-06
epoch 27 training time: 374.264
---------------
2023-08-04 18:31:19.428200
current #epochs=28, #steps=13959
Epoch: [28][41/517]	Per Sample Total Time 0.08239	Per Sample Data Time 0.01003	Per Sample DNN Time 0.07236	Train Loss 0.3619	
Epoch: [28][141/517]	Per Sample Total Time 0.07578	Per Sample Data Time 0.00332	Per Sample DNN Time 0.07246	Train Loss 0.3665	
Epoch: [28][241/517]	Per Sample Total Time 0.07468	Per Sample Data Time 0.00216	Per Sample DNN Time 0.07252	Train Loss 0.3703	
Epoch: [28][341/517]	Per Sample Total Time 0.07425	Per Sample Data Time 0.00168	Per Sample DNN Time 0.07257	Train Loss 0.3717	
Epoch: [28][441/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00141	Per Sample DNN Time 0.07259	Train Loss 0.3714	
start validation
mAP: 0.263332
AUC: 0.522237
Avg Precision: 0.255599
Avg Recall: 0.663360
d_prime: 0.078868
train_loss: 0.374976
valid_loss: 0.741495
S_p: 59.21469284356813, S_e: 20.985556499573406, Score: 40.10012467157077
validation finished
normal learning rate scheduler step
Epoch-28 lr: 3.125e-06
Epoch-28 lr: 3.125e-06
epoch 28 training time: 374.375
---------------
2023-08-04 18:37:33.803706
current #epochs=29, #steps=14476
Epoch: [29][24/517]	Per Sample Total Time 0.08812	Per Sample Data Time 0.01580	Per Sample DNN Time 0.07231	Train Loss 0.3846	
Epoch: [29][124/517]	Per Sample Total Time 0.07594	Per Sample Data Time 0.00354	Per Sample DNN Time 0.07240	Train Loss 0.3765	
Epoch: [29][224/517]	Per Sample Total Time 0.07465	Per Sample Data Time 0.00219	Per Sample DNN Time 0.07246	Train Loss 0.3804	
Epoch: [29][324/517]	Per Sample Total Time 0.07416	Per Sample Data Time 0.00167	Per Sample DNN Time 0.07249	Train Loss 0.3767	
Epoch: [29][424/517]	Per Sample Total Time 0.07391	Per Sample Data Time 0.00140	Per Sample DNN Time 0.07251	Train Loss 0.3756	
start validation
mAP: 0.264598
AUC: 0.525488
Avg Precision: 0.254694
Avg Recall: 0.658741
d_prime: 0.090414
train_loss: 0.376064
valid_loss: 0.741984
S_p: 55.85813806206106, S_e: 22.344944774849417, Score: 39.10154141845524
validation finished
normal learning rate scheduler step
Epoch-29 lr: 3.125e-06
Epoch-29 lr: 3.125e-06
epoch 29 training time: 373.955
---------------
2023-08-04 18:43:47.758390
current #epochs=30, #steps=14993
Epoch: [30][7/517]	Per Sample Total Time 0.12264	Per Sample Data Time 0.05041	Per Sample DNN Time 0.07223	Train Loss 0.3351	
Epoch: [30][107/517]	Per Sample Total Time 0.07656	Per Sample Data Time 0.00416	Per Sample DNN Time 0.07241	Train Loss 0.3795	
Epoch: [30][207/517]	Per Sample Total Time 0.07492	Per Sample Data Time 0.00241	Per Sample DNN Time 0.07250	Train Loss 0.3760	
Epoch: [30][307/517]	Per Sample Total Time 0.07436	Per Sample Data Time 0.00180	Per Sample DNN Time 0.07256	Train Loss 0.3783	
Epoch: [30][407/517]	Per Sample Total Time 0.07407	Per Sample Data Time 0.00148	Per Sample DNN Time 0.07259	Train Loss 0.3744	
Epoch: [30][507/517]	Per Sample Total Time 0.07389	Per Sample Data Time 0.00129	Per Sample DNN Time 0.07260	Train Loss 0.3744	
start validation
mAP: 0.263035
AUC: 0.519925
Avg Precision: 0.254114
Avg Recall: 0.651400
d_prime: 0.070663
train_loss: 0.374386
valid_loss: 0.742389
S_p: 57.5047498416683, S_e: 21.750212404416164, Score: 39.62748112304223
validation finished
normal learning rate scheduler step
Epoch-30 lr: 1.5625e-06
Epoch-30 lr: 1.5625e-06
epoch 30 training time: 374.461
---------------
2023-08-04 18:50:02.219848
current #epochs=31, #steps=15510
Epoch: [31][90/517]	Per Sample Total Time 0.07707	Per Sample Data Time 0.00468	Per Sample DNN Time 0.07238	Train Loss 0.3478	
Epoch: [31][190/517]	Per Sample Total Time 0.07494	Per Sample Data Time 0.00250	Per Sample DNN Time 0.07244	Train Loss 0.3541	
Epoch: [31][290/517]	Per Sample Total Time 0.07430	Per Sample Data Time 0.00182	Per Sample DNN Time 0.07249	Train Loss 0.3603	
Epoch: [31][390/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00149	Per Sample DNN Time 0.07252	Train Loss 0.3572	
Epoch: [31][490/517]	Per Sample Total Time 0.07383	Per Sample Data Time 0.00129	Per Sample DNN Time 0.07254	Train Loss 0.3582	
start validation
mAP: 0.258325
AUC: 0.516529
Avg Precision: 0.252487
Avg Recall: 0.656041
d_prime: 0.058611
train_loss: 0.356089
valid_loss: 0.744524
S_p: 55.41481950601296, S_e: 21.920135938825663, Score: 38.667477722419314
validation finished
normal learning rate scheduler step
Epoch-31 lr: 1.5625e-06
Epoch-31 lr: 1.5625e-06
epoch 31 training time: 374.073
---------------
2023-08-04 18:56:16.292725
current #epochs=32, #steps=16027
Epoch: [32][73/517]	Per Sample Total Time 0.07842	Per Sample Data Time 0.00602	Per Sample DNN Time 0.07240	Train Loss 0.3596	
Epoch: [32][173/517]	Per Sample Total Time 0.07534	Per Sample Data Time 0.00286	Per Sample DNN Time 0.07248	Train Loss 0.3581	
Epoch: [32][273/517]	Per Sample Total Time 0.07454	Per Sample Data Time 0.00201	Per Sample DNN Time 0.07253	Train Loss 0.3516	
Epoch: [32][373/517]	Per Sample Total Time 0.07417	Per Sample Data Time 0.00161	Per Sample DNN Time 0.07256	Train Loss 0.3547	
Epoch: [32][473/517]	Per Sample Total Time 0.07395	Per Sample Data Time 0.00138	Per Sample DNN Time 0.07257	Train Loss 0.3546	
start validation
mAP: 0.257619
AUC: 0.513121
Avg Precision: 0.250106
Avg Recall: 0.639788
d_prime: 0.046522
train_loss: 0.355954
valid_loss: 0.742888
S_p: 56.74477517415727, S_e: 21.920135938825663, Score: 39.33245555649147
validation finished
normal learning rate scheduler step
Epoch-32 lr: 1.5625e-06
Epoch-32 lr: 1.5625e-06
epoch 32 training time: 374.613
---------------
2023-08-04 19:02:30.906042
current #epochs=33, #steps=16544
Epoch: [33][56/517]	Per Sample Total Time 0.07969	Per Sample Data Time 0.00737	Per Sample DNN Time 0.07232	Train Loss 0.3380	
Epoch: [33][156/517]	Per Sample Total Time 0.07540	Per Sample Data Time 0.00300	Per Sample DNN Time 0.07241	Train Loss 0.3451	
Epoch: [33][256/517]	Per Sample Total Time 0.07450	Per Sample Data Time 0.00203	Per Sample DNN Time 0.07246	Train Loss 0.3491	
Epoch: [33][356/517]	Per Sample Total Time 0.07411	Per Sample Data Time 0.00161	Per Sample DNN Time 0.07250	Train Loss 0.3538	
Epoch: [33][456/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00138	Per Sample DNN Time 0.07252	Train Loss 0.3549	
start validation
mAP: 0.258895
AUC: 0.513042
Avg Precision: 0.251867
Avg Recall: 0.642827
d_prime: 0.046242
train_loss: 0.355055
valid_loss: 0.743697
S_p: 55.794806839768476, S_e: 22.51486830925892, Score: 39.1548375745137
validation finished
normal learning rate scheduler step
Epoch-33 lr: 1.5625e-06
Epoch-33 lr: 1.5625e-06
epoch 33 training time: 374.048
---------------
2023-08-04 19:08:44.953482
current #epochs=34, #steps=17061
Epoch: [34][39/517]	Per Sample Total Time 0.08290	Per Sample Data Time 0.01049	Per Sample DNN Time 0.07241	Train Loss 0.3855	
Epoch: [34][139/517]	Per Sample Total Time 0.07584	Per Sample Data Time 0.00337	Per Sample DNN Time 0.07247	Train Loss 0.3712	
Epoch: [34][239/517]	Per Sample Total Time 0.07468	Per Sample Data Time 0.00217	Per Sample DNN Time 0.07251	Train Loss 0.3682	
Epoch: [34][339/517]	Per Sample Total Time 0.07423	Per Sample Data Time 0.00168	Per Sample DNN Time 0.07255	Train Loss 0.3622	
Epoch: [34][439/517]	Per Sample Total Time 0.07398	Per Sample Data Time 0.00141	Per Sample DNN Time 0.07257	Train Loss 0.3581	
start validation
mAP: 0.256267
AUC: 0.508679
Avg Precision: 0.249187
Avg Recall: 0.642997
d_prime: 0.030767
train_loss: 0.357833
valid_loss: 0.742923
S_p: 58.20139328688675, S_e: 20.815632965163903, Score: 39.50851312602533
validation finished
normal learning rate scheduler step
Epoch-34 lr: 1.5625e-06
Epoch-34 lr: 1.5625e-06
epoch 34 training time: 374.638
---------------
2023-08-04 19:14:59.591270
current #epochs=35, #steps=17578
Epoch: [35][22/517]	Per Sample Total Time 0.08799	Per Sample Data Time 0.01568	Per Sample DNN Time 0.07231	Train Loss 0.3448	
Epoch: [35][122/517]	Per Sample Total Time 0.07590	Per Sample Data Time 0.00349	Per Sample DNN Time 0.07240	Train Loss 0.3495	
Epoch: [35][222/517]	Per Sample Total Time 0.07469	Per Sample Data Time 0.00224	Per Sample DNN Time 0.07244	Train Loss 0.3446	
Epoch: [35][322/517]	Per Sample Total Time 0.07424	Per Sample Data Time 0.00176	Per Sample DNN Time 0.07248	Train Loss 0.3484	
Epoch: [35][422/517]	Per Sample Total Time 0.07403	Per Sample Data Time 0.00151	Per Sample DNN Time 0.07252	Train Loss 0.3472	
start validation
mAP: 0.255697
AUC: 0.510609
Avg Precision: 0.251450
Avg Recall: 0.645639
d_prime: 0.037613
train_loss: 0.348895
valid_loss: 0.745075
S_p: 55.47815072830554, S_e: 21.32540356839241, Score: 38.40177714834898
validation finished
normal learning rate scheduler step
Epoch-35 lr: 7.8125e-07
Epoch-35 lr: 7.8125e-07
epoch 35 training time: 374.780
---------------
2023-08-04 19:21:14.371127
current #epochs=36, #steps=18095
Epoch: [36][5/517]	Per Sample Total Time 0.14003	Per Sample Data Time 0.06776	Per Sample DNN Time 0.07226	Train Loss 0.3637	
Epoch: [36][105/517]	Per Sample Total Time 0.07678	Per Sample Data Time 0.00437	Per Sample DNN Time 0.07241	Train Loss 0.3531	
Epoch: [36][205/517]	Per Sample Total Time 0.07506	Per Sample Data Time 0.00257	Per Sample DNN Time 0.07248	Train Loss 0.3555	
Epoch: [36][305/517]	Per Sample Total Time 0.07446	Per Sample Data Time 0.00195	Per Sample DNN Time 0.07251	Train Loss 0.3519	
Epoch: [36][405/517]	Per Sample Total Time 0.07417	Per Sample Data Time 0.00162	Per Sample DNN Time 0.07255	Train Loss 0.3461	
Epoch: [36][505/517]	Per Sample Total Time 0.07398	Per Sample Data Time 0.00142	Per Sample DNN Time 0.07256	Train Loss 0.3454	
start validation
mAP: 0.254119
AUC: 0.506842
Avg Precision: 0.248840
Avg Recall: 0.640902
d_prime: 0.024256
train_loss: 0.345512
valid_loss: 0.743789
S_p: 56.61811272957209, S_e: 21.15548003398291, Score: 38.8867963817775
validation finished
normal learning rate scheduler step
Epoch-36 lr: 7.8125e-07
Epoch-36 lr: 7.8125e-07
epoch 36 training time: 374.944
---------------
2023-08-04 19:27:29.315319
current #epochs=37, #steps=18612
Epoch: [37][88/517]	Per Sample Total Time 0.07770	Per Sample Data Time 0.00534	Per Sample DNN Time 0.07236	Train Loss 0.3427	
Epoch: [37][188/517]	Per Sample Total Time 0.07525	Per Sample Data Time 0.00282	Per Sample DNN Time 0.07243	Train Loss 0.3386	
Epoch: [37][288/517]	Per Sample Total Time 0.07455	Per Sample Data Time 0.00205	Per Sample DNN Time 0.07249	Train Loss 0.3408	
Epoch: [37][388/517]	Per Sample Total Time 0.07421	Per Sample Data Time 0.00167	Per Sample DNN Time 0.07254	Train Loss 0.3419	
Epoch: [37][488/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00145	Per Sample DNN Time 0.07257	Train Loss 0.3425	
start validation
mAP: 0.255777
AUC: 0.511088
Avg Precision: 0.249262
Avg Recall: 0.644197
d_prime: 0.039310
train_loss: 0.344228
valid_loss: 0.744081
S_p: 57.251424952497956, S_e: 20.22090059473065, Score: 38.7361627736143
validation finished
normal learning rate scheduler step
Epoch-37 lr: 7.8125e-07
Epoch-37 lr: 7.8125e-07
epoch 37 training time: 375.086
---------------
2023-08-04 19:33:44.401505
current #epochs=38, #steps=19129
Epoch: [38][71/517]	Per Sample Total Time 0.07825	Per Sample Data Time 0.00586	Per Sample DNN Time 0.07239	Train Loss 0.3505	
Epoch: [38][171/517]	Per Sample Total Time 0.07518	Per Sample Data Time 0.00274	Per Sample DNN Time 0.07244	Train Loss 0.3405	
Epoch: [38][271/517]	Per Sample Total Time 0.07443	Per Sample Data Time 0.00193	Per Sample DNN Time 0.07250	Train Loss 0.3494	
Epoch: [38][371/517]	Per Sample Total Time 0.07410	Per Sample Data Time 0.00156	Per Sample DNN Time 0.07254	Train Loss 0.3497	
Epoch: [38][471/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00135	Per Sample DNN Time 0.07255	Train Loss 0.3500	
start validation
mAP: 0.255022
AUC: 0.507794
Avg Precision: 0.249092
Avg Recall: 0.645036
d_prime: 0.027630
train_loss: 0.349282
valid_loss: 0.743575
S_p: 57.378087397083135, S_e: 20.730671197959154, Score: 39.054379297521145
validation finished
normal learning rate scheduler step
Epoch-38 lr: 7.8125e-07
Epoch-38 lr: 7.8125e-07
epoch 38 training time: 374.374
---------------
2023-08-04 19:39:58.775482
current #epochs=39, #steps=19646
Epoch: [39][54/517]	Per Sample Total Time 0.07968	Per Sample Data Time 0.00732	Per Sample DNN Time 0.07235	Train Loss 0.3783	
Epoch: [39][154/517]	Per Sample Total Time 0.07540	Per Sample Data Time 0.00298	Per Sample DNN Time 0.07243	Train Loss 0.3518	
Epoch: [39][254/517]	Per Sample Total Time 0.07451	Per Sample Data Time 0.00203	Per Sample DNN Time 0.07248	Train Loss 0.3418	
Epoch: [39][354/517]	Per Sample Total Time 0.07413	Per Sample Data Time 0.00162	Per Sample DNN Time 0.07251	Train Loss 0.3456	
Epoch: [39][454/517]	Per Sample Total Time 0.07393	Per Sample Data Time 0.00138	Per Sample DNN Time 0.07255	Train Loss 0.3464	
start validation
mAP: 0.255040
AUC: 0.507774
Avg Precision: 0.248445
Avg Recall: 0.640124
d_prime: 0.027560
train_loss: 0.344862
valid_loss: 0.743518
S_p: 57.124762507912784, S_e: 20.730671197959154, Score: 38.92771685293597
validation finished
normal learning rate scheduler step
Epoch-39 lr: 7.8125e-07
Epoch-39 lr: 7.8125e-07
epoch 39 training time: 374.254
---------------
2023-08-04 19:46:13.029230
current #epochs=40, #steps=20163
Epoch: [40][37/517]	Per Sample Total Time 0.08208	Per Sample Data Time 0.00974	Per Sample DNN Time 0.07234	Train Loss 0.3615	
Epoch: [40][137/517]	Per Sample Total Time 0.07554	Per Sample Data Time 0.00309	Per Sample DNN Time 0.07245	Train Loss 0.3474	
Epoch: [40][237/517]	Per Sample Total Time 0.07451	Per Sample Data Time 0.00202	Per Sample DNN Time 0.07249	Train Loss 0.3430	
Epoch: [40][337/517]	Per Sample Total Time 0.07411	Per Sample Data Time 0.00159	Per Sample DNN Time 0.07252	Train Loss 0.3483	
Epoch: [40][437/517]	Per Sample Total Time 0.07389	Per Sample Data Time 0.00135	Per Sample DNN Time 0.07254	Train Loss 0.3485	
start validation
mAP: 0.255498
AUC: 0.510109
Avg Precision: 0.249283
Avg Recall: 0.643921
d_prime: 0.035839
train_loss: 0.347617
valid_loss: 0.744983
S_p: 54.781507283087095, S_e: 21.835174171620913, Score: 38.30834072735401
validation finished
normal learning rate scheduler step
Epoch-40 lr: 3.90625e-07
Epoch-40 lr: 3.90625e-07
epoch 40 training time: 374.076
---------------
2023-08-04 19:52:27.106322
current #epochs=41, #steps=20680
Epoch: [41][20/517]	Per Sample Total Time 0.09168	Per Sample Data Time 0.01939	Per Sample DNN Time 0.07230	Train Loss 0.3240	
Epoch: [41][120/517]	Per Sample Total Time 0.07628	Per Sample Data Time 0.00386	Per Sample DNN Time 0.07242	Train Loss 0.3364	
Epoch: [41][220/517]	Per Sample Total Time 0.07487	Per Sample Data Time 0.00239	Per Sample DNN Time 0.07248	Train Loss 0.3422	
Epoch: [41][320/517]	Per Sample Total Time 0.07434	Per Sample Data Time 0.00183	Per Sample DNN Time 0.07251	Train Loss 0.3443	
Epoch: [41][420/517]	Per Sample Total Time 0.07406	Per Sample Data Time 0.00153	Per Sample DNN Time 0.07253	Train Loss 0.3450	
start validation
mAP: 0.255408
AUC: 0.507942
Avg Precision: 0.248735
Avg Recall: 0.645001
d_prime: 0.028157
train_loss: 0.343739
valid_loss: 0.744039
S_p: 55.92146928435364, S_e: 21.410365335597163, Score: 38.6659173099754
validation finished
normal learning rate scheduler step
Epoch-41 lr: 3.90625e-07
Epoch-41 lr: 3.90625e-07
epoch 41 training time: 374.487
---------------
2023-08-04 19:58:41.592643
current #epochs=42, #steps=21197
Epoch: [42][3/517]	Per Sample Total Time 0.16746	Per Sample Data Time 0.09505	Per Sample DNN Time 0.07242	Train Loss 0.3290	
Epoch: [42][103/517]	Per Sample Total Time 0.07664	Per Sample Data Time 0.00417	Per Sample DNN Time 0.07247	Train Loss 0.3320	
Epoch: [42][203/517]	Per Sample Total Time 0.07491	Per Sample Data Time 0.00239	Per Sample DNN Time 0.07252	Train Loss 0.3367	
Epoch: [42][303/517]	Per Sample Total Time 0.07431	Per Sample Data Time 0.00177	Per Sample DNN Time 0.07253	Train Loss 0.3366	
Epoch: [42][403/517]	Per Sample Total Time 0.07401	Per Sample Data Time 0.00146	Per Sample DNN Time 0.07255	Train Loss 0.3338	
Epoch: [42][503/517]	Per Sample Total Time 0.07383	Per Sample Data Time 0.00127	Per Sample DNN Time 0.07256	Train Loss 0.3347	
start validation
mAP: 0.254301
AUC: 0.504503
Avg Precision: 0.247006
Avg Recall: 0.636959
d_prime: 0.015962
train_loss: 0.334815
valid_loss: 0.742055
S_p: 58.644711842934846, S_e: 19.88105352591165, Score: 39.262882684423246
validation finished
normal learning rate scheduler step
Epoch-42 lr: 3.90625e-07
Epoch-42 lr: 3.90625e-07
epoch 42 training time: 374.422
---------------
2023-08-04 20:04:56.014412
current #epochs=43, #steps=21714
Epoch: [43][86/517]	Per Sample Total Time 0.07761	Per Sample Data Time 0.00527	Per Sample DNN Time 0.07234	Train Loss 0.3490	
Epoch: [43][186/517]	Per Sample Total Time 0.07517	Per Sample Data Time 0.00274	Per Sample DNN Time 0.07243	Train Loss 0.3526	
Epoch: [43][286/517]	Per Sample Total Time 0.07446	Per Sample Data Time 0.00198	Per Sample DNN Time 0.07248	Train Loss 0.3456	
Epoch: [43][386/517]	Per Sample Total Time 0.07412	Per Sample Data Time 0.00161	Per Sample DNN Time 0.07251	Train Loss 0.3389	
Epoch: [43][486/517]	Per Sample Total Time 0.07392	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07254	Train Loss 0.3402	
start validation
mAP: 0.255671
AUC: 0.507184
Avg Precision: 0.248134
Avg Recall: 0.640232
d_prime: 0.025469
train_loss: 0.341854
valid_loss: 0.743555
S_p: 56.74477517415727, S_e: 20.815632965163903, Score: 38.780204069660584
validation finished
normal learning rate scheduler step
Epoch-43 lr: 3.90625e-07
Epoch-43 lr: 3.90625e-07
epoch 43 training time: 374.945
---------------
2023-08-04 20:11:10.959283
current #epochs=44, #steps=22231
Epoch: [44][69/517]	Per Sample Total Time 0.07873	Per Sample Data Time 0.00634	Per Sample DNN Time 0.07238	Train Loss 0.3337	
Epoch: [44][169/517]	Per Sample Total Time 0.07540	Per Sample Data Time 0.00292	Per Sample DNN Time 0.07248	Train Loss 0.3331	
Epoch: [44][269/517]	Per Sample Total Time 0.07456	Per Sample Data Time 0.00204	Per Sample DNN Time 0.07252	Train Loss 0.3391	
Epoch: [44][369/517]	Per Sample Total Time 0.07418	Per Sample Data Time 0.00163	Per Sample DNN Time 0.07255	Train Loss 0.3417	
Epoch: [44][469/517]	Per Sample Total Time 0.07396	Per Sample Data Time 0.00140	Per Sample DNN Time 0.07256	Train Loss 0.3408	
start validation
mAP: 0.254485
AUC: 0.504562
Avg Precision: 0.247063
Avg Recall: 0.634164
d_prime: 0.016171
train_loss: 0.340849
valid_loss: 0.742981
S_p: 57.251424952497956, S_e: 20.815632965163903, Score: 39.03352895883093
validation finished
normal learning rate scheduler step
Epoch-44 lr: 3.90625e-07
Epoch-44 lr: 3.90625e-07
epoch 44 training time: 374.449
---------------
2023-08-04 20:17:25.407747
current #epochs=45, #steps=22748
Epoch: [45][52/517]	Per Sample Total Time 0.08017	Per Sample Data Time 0.00784	Per Sample DNN Time 0.07233	Train Loss 0.3565	
Epoch: [45][152/517]	Per Sample Total Time 0.07547	Per Sample Data Time 0.00305	Per Sample DNN Time 0.07242	Train Loss 0.3579	
Epoch: [45][252/517]	Per Sample Total Time 0.07453	Per Sample Data Time 0.00206	Per Sample DNN Time 0.07248	Train Loss 0.3457	
Epoch: [45][352/517]	Per Sample Total Time 0.07415	Per Sample Data Time 0.00163	Per Sample DNN Time 0.07252	Train Loss 0.3432	
Epoch: [45][452/517]	Per Sample Total Time 0.07393	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07254	Train Loss 0.3428	
start validation
mAP: 0.254041
AUC: 0.505842
Avg Precision: 0.246650
Avg Recall: 0.639412
d_prime: 0.020709
train_loss: 0.342886
valid_loss: 0.744137
S_p: 55.92146928435364, S_e: 20.390824129140153, Score: 38.156146706746895
validation finished
normal learning rate scheduler step
Epoch-45 lr: 1.953125e-07
Epoch-45 lr: 1.953125e-07
epoch 45 training time: 374.529
---------------
2023-08-04 20:23:39.936680
current #epochs=46, #steps=23265
Epoch: [46][35/517]	Per Sample Total Time 0.08349	Per Sample Data Time 0.01115	Per Sample DNN Time 0.07233	Train Loss 0.3334	
Epoch: [46][135/517]	Per Sample Total Time 0.07583	Per Sample Data Time 0.00339	Per Sample DNN Time 0.07244	Train Loss 0.3407	
Epoch: [46][235/517]	Per Sample Total Time 0.07470	Per Sample Data Time 0.00220	Per Sample DNN Time 0.07250	Train Loss 0.3356	
Epoch: [46][335/517]	Per Sample Total Time 0.07425	Per Sample Data Time 0.00172	Per Sample DNN Time 0.07253	Train Loss 0.3421	
Epoch: [46][435/517]	Per Sample Total Time 0.07402	Per Sample Data Time 0.00147	Per Sample DNN Time 0.07255	Train Loss 0.3396	
start validation
mAP: 0.254554
AUC: 0.506254
Avg Precision: 0.247426
Avg Recall: 0.638306
d_prime: 0.022172
train_loss: 0.341375
valid_loss: 0.743796
S_p: 56.428119062694336, S_e: 20.390824129140153, Score: 38.409471595917246
validation finished
normal learning rate scheduler step
Epoch-46 lr: 1.953125e-07
Epoch-46 lr: 1.953125e-07
epoch 46 training time: 373.670
---------------
2023-08-04 20:29:53.607590
current #epochs=47, #steps=23782
Epoch: [47][18/517]	Per Sample Total Time 0.08720	Per Sample Data Time 0.01479	Per Sample DNN Time 0.07241	Train Loss 0.3142	
Epoch: [47][118/517]	Per Sample Total Time 0.07536	Per Sample Data Time 0.00291	Per Sample DNN Time 0.07246	Train Loss 0.3463	
Epoch: [47][218/517]	Per Sample Total Time 0.07436	Per Sample Data Time 0.00187	Per Sample DNN Time 0.07249	Train Loss 0.3386	
Epoch: [47][318/517]	Per Sample Total Time 0.07400	Per Sample Data Time 0.00149	Per Sample DNN Time 0.07252	Train Loss 0.3374	
Epoch: [47][418/517]	Per Sample Total Time 0.07384	Per Sample Data Time 0.00129	Per Sample DNN Time 0.07255	Train Loss 0.3364	
start validation
mAP: 0.254131
AUC: 0.505786
Avg Precision: 0.247217
Avg Recall: 0.636675
d_prime: 0.020510
train_loss: 0.339271
valid_loss: 0.744252
S_p: 56.428119062694336, S_e: 20.475785896344902, Score: 38.45195247951962
validation finished
normal learning rate scheduler step
Epoch-47 lr: 1.953125e-07
Epoch-47 lr: 1.953125e-07
epoch 47 training time: 373.968
---------------
2023-08-04 20:36:07.575974
current #epochs=48, #steps=24299
Epoch: [48][1/517]	Per Sample Total Time 0.24383	Per Sample Data Time 0.17151	Per Sample DNN Time 0.07232	Train Loss 0.2639	
Epoch: [48][101/517]	Per Sample Total Time 0.07638	Per Sample Data Time 0.00395	Per Sample DNN Time 0.07243	Train Loss 0.3599	
Epoch: [48][201/517]	Per Sample Total Time 0.07482	Per Sample Data Time 0.00232	Per Sample DNN Time 0.07250	Train Loss 0.3492	
Epoch: [48][301/517]	Per Sample Total Time 0.07429	Per Sample Data Time 0.00176	Per Sample DNN Time 0.07252	Train Loss 0.3486	
Epoch: [48][401/517]	Per Sample Total Time 0.07402	Per Sample Data Time 0.00148	Per Sample DNN Time 0.07254	Train Loss 0.3474	
Epoch: [48][501/517]	Per Sample Total Time 0.07385	Per Sample Data Time 0.00132	Per Sample DNN Time 0.07253	Train Loss 0.3429	
start validation
mAP: 0.254032
AUC: 0.505349
Avg Precision: 0.247254
Avg Recall: 0.636939
d_prime: 0.018962
train_loss: 0.341680
valid_loss: 0.743613
S_p: 56.998100063327605, S_e: 20.390824129140153, Score: 38.69446209623388
validation finished
normal learning rate scheduler step
Epoch-48 lr: 1.953125e-07
Epoch-48 lr: 1.953125e-07
epoch 48 training time: 374.251
---------------
2023-08-04 20:42:21.826178
current #epochs=49, #steps=24816
Epoch: [49][84/517]	Per Sample Total Time 0.07686	Per Sample Data Time 0.00449	Per Sample DNN Time 0.07237	Train Loss 0.3497	
Epoch: [49][184/517]	Per Sample Total Time 0.07482	Per Sample Data Time 0.00239	Per Sample DNN Time 0.07244	Train Loss 0.3430	
Epoch: [49][284/517]	Per Sample Total Time 0.07426	Per Sample Data Time 0.00176	Per Sample DNN Time 0.07251	Train Loss 0.3444	
Epoch: [49][384/517]	Per Sample Total Time 0.07399	Per Sample Data Time 0.00145	Per Sample DNN Time 0.07254	Train Loss 0.3423	
Epoch: [49][484/517]	Per Sample Total Time 0.07383	Per Sample Data Time 0.00128	Per Sample DNN Time 0.07255	Train Loss 0.3417	
start validation
mAP: 0.253890
AUC: 0.505303
Avg Precision: 0.246456
Avg Recall: 0.634220
d_prime: 0.018799
train_loss: 0.342325
valid_loss: 0.744564
S_p: 55.85813806206106, S_e: 20.730671197959154, Score: 38.294404630010106
validation finished
normal learning rate scheduler step
Epoch-49 lr: 1.953125e-07
Epoch-49 lr: 1.953125e-07
epoch 49 training time: 374.343
---------------
2023-08-04 20:48:36.169271
current #epochs=50, #steps=25333
Epoch: [50][67/517]	Per Sample Total Time 0.07877	Per Sample Data Time 0.00643	Per Sample DNN Time 0.07234	Train Loss 0.3208	
Epoch: [50][167/517]	Per Sample Total Time 0.07538	Per Sample Data Time 0.00297	Per Sample DNN Time 0.07242	Train Loss 0.3288	
Epoch: [50][267/517]	Per Sample Total Time 0.07456	Per Sample Data Time 0.00209	Per Sample DNN Time 0.07247	Train Loss 0.3309	
Epoch: [50][367/517]	Per Sample Total Time 0.07419	Per Sample Data Time 0.00169	Per Sample DNN Time 0.07250	Train Loss 0.3337	
Epoch: [50][467/517]	Per Sample Total Time 0.07398	Per Sample Data Time 0.00146	Per Sample DNN Time 0.07252	Train Loss 0.3340	
start validation
mAP: 0.253675
AUC: 0.505149
Avg Precision: 0.246744
Avg Recall: 0.635519
d_prime: 0.018254
train_loss: 0.335263
valid_loss: 0.744851
S_p: 55.28815706142778, S_e: 20.560747663549655, Score: 37.92445236248872
validation finished
normal learning rate scheduler step
Epoch-50 lr: 9.765625e-08
Epoch-50 lr: 9.765625e-08
epoch 50 training time: 374.847
---------------Training Finished---------------
weighted averaged models results
mAP: 0.266260
AUC: 0.536615
Avg Precision: 0.253047
Avg Recall: 0.676639
d_prime: 0.129979
train_loss: 0.000000
valid_loss: 0.744851
S_p: 71.88093730208539, S_e: 10.195412064570077, Score: 41.03817468332773
