+ . /data/sls/scratch/share-201907/slstoolchainrc
./run_icbhi.sh: line 15: /data/sls/scratch/share-201907/slstoolchainrc: No such file or directory
+ source ../../../venvssast/bin/activate
++ deactivate nondestructive
++ '[' -n '' ']'
++ '[' -n '' ']'
++ '[' -n /bin/bash -o -n '' ']'
++ hash -r
++ '[' -n '' ']'
++ unset VIRTUAL_ENV
++ '[' '!' nondestructive = nondestructive ']'
++ VIRTUAL_ENV=/workspace/pj_resp/ssast/venvssast
++ export VIRTUAL_ENV
++ _OLD_VIRTUAL_PATH=/workspace/pj_resp/ssast/venvssast/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/workspace/pj_resp/ssast/venvssast/bin:/workspace/pj_resp/ssast/venvssast/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export PATH
++ '[' -n '' ']'
++ '[' -z '' ']'
++ _OLD_VIRTUAL_PS1=
++ '[' 'x(venvssast) ' '!=' x ']'
++ PS1='(venvssast) '
++ export PS1
++ '[' -n /bin/bash -o -n '' ']'
++ hash -r
+ export TORCH_HOME=../../pretrained_models
+ TORCH_HOME=../../pretrained_models
+ mkdir -p ./exp
+ '[' -e SSAST-Base-Patch-400.pth ']'
+ echo 'pretrained model already downloaded.'
pretrained model already downloaded.
+ pretrain_exp=
+ pretrain_model=SSAST-Base-Patch-400
+ pretrain_path=.//SSAST-Base-Patch-400.pth
+ dataset=icbhi
+ dataset_mean=-4.2677393
+ dataset_std=4.5689974
+ target_length=1024
+ noise=False
+ task=ft_avgtok
+ model_size=base
+ head_lr=1
+ warmup=True
+ bal=none
+ lr=5e-5
+ epoch=50
+ tr_data=./data/icbhi_train.json
+ te_data=./data/icbhi_eval.json
+ freqm=48
+ timem=192
+ mixup=0.5
+ fstride=10
+ tstride=10
+ fshape=16
+ tshape=16
+ batch_size=8
+ filename=230806_2
+ exp_dir=./exp/230806_2-icbhi-f10-16-t10-16-b8-lr5e-5-ft_avgtok-base--SSAST-Base-Patch-400-1x-noiseFalse-3
+ CUDA_CACHE_DISABLE=1
+ python -W ignore ../../run.py --dataset icbhi --data-train ./data/icbhi_train.json --data-val ./data/icbhi_eval.json --exp-dir ./exp/230806_2-icbhi-f10-16-t10-16-b8-lr5e-5-ft_avgtok-base--SSAST-Base-Patch-400-1x-noiseFalse-3 --label-csv ./data/icbhi_class_labels_indices.csv --n_class 4 --lr 5e-5 --n-epochs 50 --batch-size 8 --save_model False --freqm 48 --timem 192 --mixup 0.5 --bal none --tstride 10 --fstride 10 --fshape 16 --tshape 16 --warmup False --task ft_avgtok --model_size base --adaptschedule False --pretrained_mdl_path .//SSAST-Base-Patch-400.pth --dataset_mean -4.2677393 --dataset_std 4.5689974 --target_length 1024 --num_mel_bins 128 --head_lr 1 --noise False --lrscheduler_start 10 --lrscheduler_step 5 --lrscheduler_decay 0.5 --wa True --wa_start 6 --wa_end 25 --loss BCE --metrics mAP
I am process 226, running on edb23cd42fbf: starting (Sun Aug  6 23:06:34 2023)
balanced sampler is not used
---------------the train dataloader---------------
now using following mask: 48 freq, 192 time
now using mix-up with rate 0.500000
now process icbhi
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 4
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process icbhi
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 4
Now train with icbhi with 4142 training samples, evaluate with 2756 samples
now load a SSL pretrained models from .//SSAST-Base-Patch-400.pth
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=10, time=10
fine-tuning number of patches=1212

Creating experiment directory: ./exp/230806_2-icbhi-f10-16-t10-16-b8-lr5e-5-ft_avgtok-base--SSAST-Base-Patch-400-1x-noiseFalse-3
Now starting fine-tuning for 50 epochs
running on cuda
Total parameter number is : 87.730 million
Total trainable parameter number is : 87.730 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 87.725 million
now training with icbhi, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f8175843490>
The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-08-06 23:06:47.168130
current #epochs=1, #steps=0
Epoch: [1][100/517]	Per Sample Total Time 0.08298	Per Sample Data Time 0.00215	Per Sample DNN Time 0.08083	Train Loss 0.4980	
Epoch: [1][200/517]	Per Sample Total Time 0.07741	Per Sample Data Time 0.00125	Per Sample DNN Time 0.07616	Train Loss 0.4966	
Epoch: [1][300/517]	Per Sample Total Time 0.07578	Per Sample Data Time 0.00095	Per Sample DNN Time 0.07484	Train Loss 0.4942	
Epoch: [1][400/517]	Per Sample Total Time 0.07502	Per Sample Data Time 0.00079	Per Sample DNN Time 0.07423	Train Loss 0.4955	
Epoch: [1][500/517]	Per Sample Total Time 0.07458	Per Sample Data Time 0.00070	Per Sample DNN Time 0.07388	Train Loss 0.4951	
start validation
mAP: 0.265894
AUC: 0.545613
Avg Precision: 0.267070
Avg Recall: 0.675223
d_prime: 0.162050
train_loss: 0.494866
valid_loss: 0.733939
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-1 lr: 5e-05
Epoch-1 lr: 5e-05
epoch 1 training time: 380.148
---------------
2023-08-06 23:13:07.316966
current #epochs=2, #steps=517
Epoch: [2][83/517]	Per Sample Total Time 0.07766	Per Sample Data Time 0.00405	Per Sample DNN Time 0.07362	Train Loss 0.5057	
Epoch: [2][183/517]	Per Sample Total Time 0.07497	Per Sample Data Time 0.00203	Per Sample DNN Time 0.07294	Train Loss 0.4944	
Epoch: [2][283/517]	Per Sample Total Time 0.07419	Per Sample Data Time 0.00143	Per Sample DNN Time 0.07276	Train Loss 0.4908	
Epoch: [2][383/517]	Per Sample Total Time 0.07381	Per Sample Data Time 0.00114	Per Sample DNN Time 0.07267	Train Loss 0.4912	
Epoch: [2][483/517]	Per Sample Total Time 0.07359	Per Sample Data Time 0.00098	Per Sample DNN Time 0.07262	Train Loss 0.4922	
start validation
mAP: 0.259322
AUC: 0.526728
Avg Precision: 0.258116
Avg Recall: 0.659521
d_prime: 0.094818
train_loss: 0.492187
valid_loss: 0.734084
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-2 lr: 5e-05
Epoch-2 lr: 5e-05
epoch 2 training time: 373.187
---------------
2023-08-06 23:19:20.504083
current #epochs=3, #steps=1034
Epoch: [3][66/517]	Per Sample Total Time 0.07784	Per Sample Data Time 0.00563	Per Sample DNN Time 0.07221	Train Loss 0.4930	
Epoch: [3][166/517]	Per Sample Total Time 0.07474	Per Sample Data Time 0.00246	Per Sample DNN Time 0.07229	Train Loss 0.4890	
Epoch: [3][266/517]	Per Sample Total Time 0.07398	Per Sample Data Time 0.00166	Per Sample DNN Time 0.07232	Train Loss 0.4925	
Epoch: [3][366/517]	Per Sample Total Time 0.07362	Per Sample Data Time 0.00129	Per Sample DNN Time 0.07233	Train Loss 0.4923	
Epoch: [3][466/517]	Per Sample Total Time 0.07343	Per Sample Data Time 0.00108	Per Sample DNN Time 0.07235	Train Loss 0.4918	
start validation
mAP: 0.248662
AUC: 0.496282
Avg Precision: 0.244084
Avg Recall: 0.626701
d_prime: -0.013179
train_loss: 0.491591
valid_loss: 0.733100
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-3 lr: 5e-05
Epoch-3 lr: 5e-05
epoch 3 training time: 371.185
---------------
2023-08-06 23:25:31.688965
current #epochs=4, #steps=1551
Epoch: [4][49/517]	Per Sample Total Time 0.07844	Per Sample Data Time 0.00624	Per Sample DNN Time 0.07221	Train Loss 0.4963	
Epoch: [4][149/517]	Per Sample Total Time 0.07458	Per Sample Data Time 0.00230	Per Sample DNN Time 0.07228	Train Loss 0.4855	
Epoch: [4][249/517]	Per Sample Total Time 0.07382	Per Sample Data Time 0.00151	Per Sample DNN Time 0.07231	Train Loss 0.4958	
Epoch: [4][349/517]	Per Sample Total Time 0.07350	Per Sample Data Time 0.00118	Per Sample DNN Time 0.07233	Train Loss 0.4948	
Epoch: [4][449/517]	Per Sample Total Time 0.07333	Per Sample Data Time 0.00099	Per Sample DNN Time 0.07234	Train Loss 0.4934	
start validation
mAP: 0.260810
AUC: 0.512044
Avg Precision: 0.251079
Avg Recall: 0.637136
d_prime: 0.042700
train_loss: 0.492395
valid_loss: 0.735532
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-4 lr: 5e-05
Epoch-4 lr: 5e-05
epoch 4 training time: 370.589
---------------
2023-08-06 23:31:42.278087
current #epochs=5, #steps=2068
Epoch: [5][32/517]	Per Sample Total Time 0.08113	Per Sample Data Time 0.00892	Per Sample DNN Time 0.07221	Train Loss 0.4954	
Epoch: [5][132/517]	Per Sample Total Time 0.07472	Per Sample Data Time 0.00245	Per Sample DNN Time 0.07227	Train Loss 0.4907	
Epoch: [5][232/517]	Per Sample Total Time 0.07386	Per Sample Data Time 0.00154	Per Sample DNN Time 0.07232	Train Loss 0.4922	
Epoch: [5][332/517]	Per Sample Total Time 0.07351	Per Sample Data Time 0.00117	Per Sample DNN Time 0.07234	Train Loss 0.4911	
Epoch: [5][432/517]	Per Sample Total Time 0.07333	Per Sample Data Time 0.00098	Per Sample DNN Time 0.07236	Train Loss 0.4902	
start validation
mAP: 0.275100
AUC: 0.556706
Avg Precision: 0.264086
Avg Recall: 0.702787
d_prime: 0.201698
train_loss: 0.489264
valid_loss: 0.737910
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-5 lr: 5e-05
Epoch-5 lr: 5e-05
epoch 5 training time: 373.305
---------------
2023-08-06 23:37:55.583634
current #epochs=6, #steps=2585
Epoch: [6][15/517]	Per Sample Total Time 0.09246	Per Sample Data Time 0.02054	Per Sample DNN Time 0.07192	Train Loss 0.5023	
Epoch: [6][115/517]	Per Sample Total Time 0.07527	Per Sample Data Time 0.00311	Per Sample DNN Time 0.07216	Train Loss 0.4988	
Epoch: [6][215/517]	Per Sample Total Time 0.07407	Per Sample Data Time 0.00183	Per Sample DNN Time 0.07225	Train Loss 0.4921	
Epoch: [6][315/517]	Per Sample Total Time 0.07367	Per Sample Data Time 0.00135	Per Sample DNN Time 0.07231	Train Loss 0.4915	
Epoch: [6][415/517]	Per Sample Total Time 0.07345	Per Sample Data Time 0.00111	Per Sample DNN Time 0.07233	Train Loss 0.4913	
Epoch: [6][515/517]	Per Sample Total Time 0.07331	Per Sample Data Time 0.00096	Per Sample DNN Time 0.07234	Train Loss 0.4897	
start validation
mAP: 0.245529
AUC: 0.493678
Avg Precision: 0.250900
Avg Recall: 0.656314
d_prime: -0.022412
train_loss: 0.489706
valid_loss: 0.734728
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-6 lr: 5e-05
Epoch-6 lr: 5e-05
epoch 6 training time: 371.075
---------------
2023-08-06 23:44:06.658502
current #epochs=7, #steps=3102
Epoch: [7][98/517]	Per Sample Total Time 0.07541	Per Sample Data Time 0.00317	Per Sample DNN Time 0.07224	Train Loss 0.4785	
Epoch: [7][198/517]	Per Sample Total Time 0.07405	Per Sample Data Time 0.00174	Per Sample DNN Time 0.07231	Train Loss 0.4905	
Epoch: [7][298/517]	Per Sample Total Time 0.07360	Per Sample Data Time 0.00127	Per Sample DNN Time 0.07233	Train Loss 0.4888	
Epoch: [7][398/517]	Per Sample Total Time 0.07338	Per Sample Data Time 0.00103	Per Sample DNN Time 0.07234	Train Loss 0.4882	
Epoch: [7][498/517]	Per Sample Total Time 0.07324	Per Sample Data Time 0.00089	Per Sample DNN Time 0.07235	Train Loss 0.4878	
start validation
mAP: 0.258429
AUC: 0.536362
Avg Precision: 0.262167
Avg Recall: 0.695270
d_prime: 0.129079
train_loss: 0.487174
valid_loss: 0.729010
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-7 lr: 5e-05
Epoch-7 lr: 5e-05
epoch 7 training time: 371.244
---------------
2023-08-06 23:50:17.903386
current #epochs=8, #steps=3619
Epoch: [8][81/517]	Per Sample Total Time 0.07673	Per Sample Data Time 0.00451	Per Sample DNN Time 0.07222	Train Loss 0.4913	
Epoch: [8][181/517]	Per Sample Total Time 0.07450	Per Sample Data Time 0.00221	Per Sample DNN Time 0.07229	Train Loss 0.4894	
Epoch: [8][281/517]	Per Sample Total Time 0.07387	Per Sample Data Time 0.00155	Per Sample DNN Time 0.07233	Train Loss 0.4857	
Epoch: [8][381/517]	Per Sample Total Time 0.07359	Per Sample Data Time 0.00123	Per Sample DNN Time 0.07236	Train Loss 0.4859	
Epoch: [8][481/517]	Per Sample Total Time 0.07343	Per Sample Data Time 0.00105	Per Sample DNN Time 0.07238	Train Loss 0.4892	
start validation
mAP: 0.261247
AUC: 0.513755
Avg Precision: 0.250517
Avg Recall: 0.640946
d_prime: 0.048770
train_loss: 0.489261
valid_loss: 0.737610
S_p: 99.74667511082332, S_e: 0.16992353440950128, Score: 49.95829932261641
validation finished
normal learning rate scheduler step
Epoch-8 lr: 5e-05
Epoch-8 lr: 5e-05
epoch 8 training time: 371.834
---------------
2023-08-06 23:56:29.736516
current #epochs=9, #steps=4136
Epoch: [9][64/517]	Per Sample Total Time 0.07737	Per Sample Data Time 0.00510	Per Sample DNN Time 0.07227	Train Loss 0.5011	
Epoch: [9][164/517]	Per Sample Total Time 0.07454	Per Sample Data Time 0.00222	Per Sample DNN Time 0.07233	Train Loss 0.4905	
Epoch: [9][264/517]	Per Sample Total Time 0.07387	Per Sample Data Time 0.00150	Per Sample DNN Time 0.07237	Train Loss 0.4881	
Epoch: [9][364/517]	Per Sample Total Time 0.07357	Per Sample Data Time 0.00118	Per Sample DNN Time 0.07239	Train Loss 0.4848	
Epoch: [9][464/517]	Per Sample Total Time 0.07339	Per Sample Data Time 0.00100	Per Sample DNN Time 0.07239	Train Loss 0.4830	
start validation
mAP: 0.242168
AUC: 0.482514
Avg Precision: 0.235788
Avg Recall: 0.613090
d_prime: -0.062007
train_loss: 0.483357
valid_loss: 0.735588
S_p: 99.99999999999366, S_e: 0.0, Score: 49.99999999999683
validation finished
normal learning rate scheduler step
Epoch-9 lr: 5e-05
Epoch-9 lr: 5e-05
epoch 9 training time: 371.299
---------------
2023-08-07 00:02:41.035498
current #epochs=10, #steps=4653
Epoch: [10][47/517]	Per Sample Total Time 0.08030	Per Sample Data Time 0.00809	Per Sample DNN Time 0.07220	Train Loss 0.4905	
Epoch: [10][147/517]	Per Sample Total Time 0.07512	Per Sample Data Time 0.00284	Per Sample DNN Time 0.07228	Train Loss 0.4831	
Epoch: [10][247/517]	Per Sample Total Time 0.07415	Per Sample Data Time 0.00183	Per Sample DNN Time 0.07232	Train Loss 0.4869	
Epoch: [10][347/517]	Per Sample Total Time 0.07375	Per Sample Data Time 0.00140	Per Sample DNN Time 0.07235	Train Loss 0.4858	
Epoch: [10][447/517]	Per Sample Total Time 0.07354	Per Sample Data Time 0.00118	Per Sample DNN Time 0.07236	Train Loss 0.4826	
start validation
mAP: 0.265186
AUC: 0.533845
Avg Precision: 0.260922
Avg Recall: 0.672694
d_prime: 0.120120
train_loss: 0.484252
valid_loss: 0.735074
S_p: 83.09056364787314, S_e: 5.862361937127794, Score: 44.47646279250047
validation finished
normal learning rate scheduler step
Epoch-10 lr: 2.5e-05
Epoch-10 lr: 2.5e-05
epoch 10 training time: 372.187
---------------
2023-08-07 00:08:53.222562
current #epochs=11, #steps=5170
Epoch: [11][30/517]	Per Sample Total Time 0.08200	Per Sample Data Time 0.00987	Per Sample DNN Time 0.07212	Train Loss 0.4906	
Epoch: [11][130/517]	Per Sample Total Time 0.07482	Per Sample Data Time 0.00258	Per Sample DNN Time 0.07224	Train Loss 0.4880	
Epoch: [11][230/517]	Per Sample Total Time 0.07391	Per Sample Data Time 0.00161	Per Sample DNN Time 0.07230	Train Loss 0.4853	
Epoch: [11][330/517]	Per Sample Total Time 0.07357	Per Sample Data Time 0.00124	Per Sample DNN Time 0.07234	Train Loss 0.4787	
Epoch: [11][430/517]	Per Sample Total Time 0.07338	Per Sample Data Time 0.00103	Per Sample DNN Time 0.07235	Train Loss 0.4815	
start validation
mAP: 0.246649
AUC: 0.498466
Avg Precision: 0.245075
Avg Recall: 0.626046
d_prime: -0.005439
train_loss: 0.481841
valid_loss: 0.732463
S_p: 99.3666877770678, S_e: 0.08496176720475064, Score: 49.72582477213627
validation finished
normal learning rate scheduler step
Epoch-11 lr: 2.5e-05
Epoch-11 lr: 2.5e-05
epoch 11 training time: 371.279
---------------
2023-08-07 00:15:04.501551
current #epochs=12, #steps=5687
Epoch: [12][13/517]	Per Sample Total Time 0.09850	Per Sample Data Time 0.02641	Per Sample DNN Time 0.07209	Train Loss 0.5295	
Epoch: [12][113/517]	Per Sample Total Time 0.07581	Per Sample Data Time 0.00354	Per Sample DNN Time 0.07227	Train Loss 0.4880	
Epoch: [12][213/517]	Per Sample Total Time 0.07439	Per Sample Data Time 0.00206	Per Sample DNN Time 0.07232	Train Loss 0.4833	
Epoch: [12][313/517]	Per Sample Total Time 0.07389	Per Sample Data Time 0.00153	Per Sample DNN Time 0.07236	Train Loss 0.4812	
Epoch: [12][413/517]	Per Sample Total Time 0.07364	Per Sample Data Time 0.00125	Per Sample DNN Time 0.07238	Train Loss 0.4778	
Epoch: [12][513/517]	Per Sample Total Time 0.07348	Per Sample Data Time 0.00108	Per Sample DNN Time 0.07240	Train Loss 0.4762	
start validation
mAP: 0.249825
AUC: 0.508360
Avg Precision: 0.247050
Avg Recall: 0.650765
d_prime: 0.029638
train_loss: 0.476099
valid_loss: 0.736619
S_p: 89.80367321088728, S_e: 3.398470688190026, Score: 46.60107194953866
validation finished
normal learning rate scheduler step
Epoch-12 lr: 2.5e-05
Epoch-12 lr: 2.5e-05
epoch 12 training time: 372.151
---------------
2023-08-07 00:21:16.652606
current #epochs=13, #steps=6204
Epoch: [13][96/517]	Per Sample Total Time 0.07562	Per Sample Data Time 0.00336	Per Sample DNN Time 0.07226	Train Loss 0.4740	
Epoch: [13][196/517]	Per Sample Total Time 0.07420	Per Sample Data Time 0.00189	Per Sample DNN Time 0.07231	Train Loss 0.4718	
Epoch: [13][296/517]	Per Sample Total Time 0.07375	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07235	Train Loss 0.4729	
Epoch: [13][396/517]	Per Sample Total Time 0.07353	Per Sample Data Time 0.00115	Per Sample DNN Time 0.07238	Train Loss 0.4753	
Epoch: [13][496/517]	Per Sample Total Time 0.07340	Per Sample Data Time 0.00100	Per Sample DNN Time 0.07239	Train Loss 0.4748	
start validation
mAP: 0.246929
AUC: 0.503225
Avg Precision: 0.248917
Avg Recall: 0.644866
d_prime: 0.011433
train_loss: 0.474637
valid_loss: 0.730935
S_p: 96.64344521848659, S_e: 1.3593882752760102, Score: 49.0014167468813
validation finished
normal learning rate scheduler step
Epoch-13 lr: 2.5e-05
Epoch-13 lr: 2.5e-05
epoch 13 training time: 372.635
---------------
2023-08-07 00:27:29.288485
current #epochs=14, #steps=6721
Epoch: [14][79/517]	Per Sample Total Time 0.07826	Per Sample Data Time 0.00604	Per Sample DNN Time 0.07222	Train Loss 0.4688	
Epoch: [14][179/517]	Per Sample Total Time 0.07522	Per Sample Data Time 0.00289	Per Sample DNN Time 0.07232	Train Loss 0.4636	
Epoch: [14][279/517]	Per Sample Total Time 0.07436	Per Sample Data Time 0.00199	Per Sample DNN Time 0.07237	Train Loss 0.4664	
Epoch: [14][379/517]	Per Sample Total Time 0.07397	Per Sample Data Time 0.00157	Per Sample DNN Time 0.07240	Train Loss 0.4688	
Epoch: [14][479/517]	Per Sample Total Time 0.07374	Per Sample Data Time 0.00132	Per Sample DNN Time 0.07242	Train Loss 0.4697	
start validation
mAP: 0.245223
AUC: 0.494356
Avg Precision: 0.246365
Avg Recall: 0.635839
d_prime: -0.020007
train_loss: 0.471112
valid_loss: 0.737644
S_p: 92.21025965800555, S_e: 2.548853016142519, Score: 47.379556337074035
validation finished
normal learning rate scheduler step
Epoch-14 lr: 2.5e-05
Epoch-14 lr: 2.5e-05
epoch 14 training time: 374.165
---------------
2023-08-07 00:33:43.452750
current #epochs=15, #steps=7238
Epoch: [15][62/517]	Per Sample Total Time 0.08157	Per Sample Data Time 0.00928	Per Sample DNN Time 0.07229	Train Loss 0.4685	
Epoch: [15][162/517]	Per Sample Total Time 0.07632	Per Sample Data Time 0.00390	Per Sample DNN Time 0.07242	Train Loss 0.4684	
Epoch: [15][262/517]	Per Sample Total Time 0.07511	Per Sample Data Time 0.00261	Per Sample DNN Time 0.07250	Train Loss 0.4664	
Epoch: [15][362/517]	Per Sample Total Time 0.07457	Per Sample Data Time 0.00203	Per Sample DNN Time 0.07253	Train Loss 0.4630	
Epoch: [15][462/517]	Per Sample Total Time 0.07425	Per Sample Data Time 0.00170	Per Sample DNN Time 0.07255	Train Loss 0.4629	
start validation
mAP: 0.258807
AUC: 0.516322
Avg Precision: 0.254981
Avg Recall: 0.654559
d_prime: 0.057875
train_loss: 0.463354
valid_loss: 0.744582
S_p: 63.96453451551209, S_e: 17.67204757858813, Score: 40.81829104705011
validation finished
normal learning rate scheduler step
Epoch-15 lr: 1.25e-05
Epoch-15 lr: 1.25e-05
epoch 15 training time: 376.983
---------------
2023-08-07 00:40:00.436164
current #epochs=16, #steps=7755
Epoch: [16][45/517]	Per Sample Total Time 0.08079	Per Sample Data Time 0.00858	Per Sample DNN Time 0.07221	Train Loss 0.4470	
Epoch: [16][145/517]	Per Sample Total Time 0.07548	Per Sample Data Time 0.00317	Per Sample DNN Time 0.07230	Train Loss 0.4546	
Epoch: [16][245/517]	Per Sample Total Time 0.07455	Per Sample Data Time 0.00218	Per Sample DNN Time 0.07236	Train Loss 0.4515	
Epoch: [16][345/517]	Per Sample Total Time 0.07414	Per Sample Data Time 0.00175	Per Sample DNN Time 0.07239	Train Loss 0.4513	
Epoch: [16][445/517]	Per Sample Total Time 0.07391	Per Sample Data Time 0.00151	Per Sample DNN Time 0.07240	Train Loss 0.4523	
start validation
mAP: 0.239579
AUC: 0.485453
Avg Precision: 0.240931
Avg Recall: 0.623106
d_prime: -0.051579
train_loss: 0.451449
valid_loss: 0.737515
S_p: 77.01076630778486, S_e: 11.724723874255588, Score: 44.367745091020225
validation finished
normal learning rate scheduler step
Epoch-16 lr: 1.25e-05
Epoch-16 lr: 1.25e-05
epoch 16 training time: 375.423
---------------
2023-08-07 00:46:15.859054
current #epochs=17, #steps=8272
Epoch: [17][28/517]	Per Sample Total Time 0.09077	Per Sample Data Time 0.01875	Per Sample DNN Time 0.07203	Train Loss 0.4336	
Epoch: [17][128/517]	Per Sample Total Time 0.07679	Per Sample Data Time 0.00458	Per Sample DNN Time 0.07221	Train Loss 0.4280	
Epoch: [17][228/517]	Per Sample Total Time 0.07509	Per Sample Data Time 0.00280	Per Sample DNN Time 0.07229	Train Loss 0.4335	
Epoch: [17][328/517]	Per Sample Total Time 0.07443	Per Sample Data Time 0.00210	Per Sample DNN Time 0.07233	Train Loss 0.4369	
Epoch: [17][428/517]	Per Sample Total Time 0.07407	Per Sample Data Time 0.00172	Per Sample DNN Time 0.07235	Train Loss 0.4376	
start validation
mAP: 0.249175
AUC: 0.509928
Avg Precision: 0.248653
Avg Recall: 0.645417
d_prime: 0.035196
train_loss: 0.439668
valid_loss: 0.743553
S_p: 65.29449018365641, S_e: 18.52166525063564, Score: 41.90807771714602
validation finished
normal learning rate scheduler step
Epoch-17 lr: 1.25e-05
Epoch-17 lr: 1.25e-05
epoch 17 training time: 375.115
---------------
2023-08-07 00:52:30.974235
current #epochs=18, #steps=8789
Epoch: [18][11/517]	Per Sample Total Time 0.11080	Per Sample Data Time 0.03891	Per Sample DNN Time 0.07189	Train Loss 0.4508	
Epoch: [18][111/517]	Per Sample Total Time 0.07668	Per Sample Data Time 0.00458	Per Sample DNN Time 0.07211	Train Loss 0.4297	
Epoch: [18][211/517]	Per Sample Total Time 0.07482	Per Sample Data Time 0.00266	Per Sample DNN Time 0.07216	Train Loss 0.4268	
Epoch: [18][311/517]	Per Sample Total Time 0.07413	Per Sample Data Time 0.00197	Per Sample DNN Time 0.07215	Train Loss 0.4267	
Epoch: [18][411/517]	Per Sample Total Time 0.07380	Per Sample Data Time 0.00162	Per Sample DNN Time 0.07218	Train Loss 0.4262	
Epoch: [18][511/517]	Per Sample Total Time 0.07362	Per Sample Data Time 0.00141	Per Sample DNN Time 0.07221	Train Loss 0.4226	
start validation
mAP: 0.241534
AUC: 0.481536
Avg Precision: 0.241041
Avg Recall: 0.616822
d_prime: -0.065476
train_loss: 0.423147
valid_loss: 0.742068
S_p: 65.16782773907124, S_e: 16.05777400169787, Score: 40.612800870384554
validation finished
normal learning rate scheduler step
Epoch-18 lr: 1.25e-05
Epoch-18 lr: 1.25e-05
epoch 18 training time: 374.404
---------------
2023-08-07 00:58:45.377852
current #epochs=19, #steps=9306
Epoch: [19][94/517]	Per Sample Total Time 0.07791	Per Sample Data Time 0.00575	Per Sample DNN Time 0.07216	Train Loss 0.4210	
Epoch: [19][194/517]	Per Sample Total Time 0.07528	Per Sample Data Time 0.00308	Per Sample DNN Time 0.07221	Train Loss 0.4143	
Epoch: [19][294/517]	Per Sample Total Time 0.07448	Per Sample Data Time 0.00224	Per Sample DNN Time 0.07223	Train Loss 0.4166	
Epoch: [19][394/517]	Per Sample Total Time 0.07408	Per Sample Data Time 0.00184	Per Sample DNN Time 0.07225	Train Loss 0.4164	
Epoch: [19][494/517]	Per Sample Total Time 0.07384	Per Sample Data Time 0.00159	Per Sample DNN Time 0.07226	Train Loss 0.4166	
start validation
mAP: 0.247390
AUC: 0.489724
Avg Precision: 0.241892
Avg Recall: 0.616733
d_prime: -0.036432
train_loss: 0.416406
valid_loss: 0.741713
S_p: 61.177960734638305, S_e: 19.11639762106889, Score: 40.1471791778536
validation finished
normal learning rate scheduler step
Epoch-19 lr: 1.25e-05
Epoch-19 lr: 1.25e-05
epoch 19 training time: 375.274
---------------
2023-08-07 01:05:00.652305
current #epochs=20, #steps=9823
Epoch: [20][77/517]	Per Sample Total Time 0.07967	Per Sample Data Time 0.00779	Per Sample DNN Time 0.07189	Train Loss 0.4056	
Epoch: [20][177/517]	Per Sample Total Time 0.07569	Per Sample Data Time 0.00372	Per Sample DNN Time 0.07197	Train Loss 0.4032	
Epoch: [20][277/517]	Per Sample Total Time 0.07459	Per Sample Data Time 0.00257	Per Sample DNN Time 0.07201	Train Loss 0.4059	
Epoch: [20][377/517]	Per Sample Total Time 0.07408	Per Sample Data Time 0.00203	Per Sample DNN Time 0.07205	Train Loss 0.4047	
Epoch: [20][477/517]	Per Sample Total Time 0.07379	Per Sample Data Time 0.00172	Per Sample DNN Time 0.07207	Train Loss 0.4019	
start validation
mAP: 0.251818
AUC: 0.512248
Avg Precision: 0.248404
Avg Recall: 0.655885
d_prime: 0.043424
train_loss: 0.402813
valid_loss: 0.747123
S_p: 50.094996833435715, S_e: 23.534409515715925, Score: 36.81470317457582
validation finished
normal learning rate scheduler step
Epoch-20 lr: 6.25e-06
Epoch-20 lr: 6.25e-06
epoch 20 training time: 373.341
---------------
2023-08-07 01:11:13.993368
current #epochs=21, #steps=10340
Epoch: [21][60/517]	Per Sample Total Time 0.08009	Per Sample Data Time 0.00820	Per Sample DNN Time 0.07189	Train Loss 0.3988	
Epoch: [21][160/517]	Per Sample Total Time 0.07547	Per Sample Data Time 0.00347	Per Sample DNN Time 0.07199	Train Loss 0.3973	
Epoch: [21][260/517]	Per Sample Total Time 0.07440	Per Sample Data Time 0.00234	Per Sample DNN Time 0.07206	Train Loss 0.3954	
Epoch: [21][360/517]	Per Sample Total Time 0.07394	Per Sample Data Time 0.00185	Per Sample DNN Time 0.07209	Train Loss 0.3959	
Epoch: [21][460/517]	Per Sample Total Time 0.07366	Per Sample Data Time 0.00155	Per Sample DNN Time 0.07211	Train Loss 0.3925	
start validation
mAP: 0.243689
AUC: 0.494367
Avg Precision: 0.243962
Avg Recall: 0.626614
d_prime: -0.019969
train_loss: 0.391736
valid_loss: 0.752170
S_p: 50.854971500946746, S_e: 19.11639762106889, Score: 34.985684561007815
validation finished
normal learning rate scheduler step
Epoch-21 lr: 6.25e-06
Epoch-21 lr: 6.25e-06
epoch 21 training time: 373.490
---------------
2023-08-07 01:17:27.483571
current #epochs=22, #steps=10857
Epoch: [22][43/517]	Per Sample Total Time 0.08290	Per Sample Data Time 0.01106	Per Sample DNN Time 0.07184	Train Loss 0.4010	
Epoch: [22][143/517]	Per Sample Total Time 0.07568	Per Sample Data Time 0.00371	Per Sample DNN Time 0.07197	Train Loss 0.3715	
Epoch: [22][243/517]	Per Sample Total Time 0.07444	Per Sample Data Time 0.00239	Per Sample DNN Time 0.07205	Train Loss 0.3710	
Epoch: [22][343/517]	Per Sample Total Time 0.07392	Per Sample Data Time 0.00183	Per Sample DNN Time 0.07210	Train Loss 0.3728	
Epoch: [22][443/517]	Per Sample Total Time 0.07364	Per Sample Data Time 0.00152	Per Sample DNN Time 0.07212	Train Loss 0.3785	
start validation
mAP: 0.246770
AUC: 0.495117
Avg Precision: 0.246573
Avg Recall: 0.624334
d_prime: -0.017310
train_loss: 0.382430
valid_loss: 0.757267
S_p: 44.965167827736224, S_e: 20.730671197959154, Score: 32.84791951284769
validation finished
normal learning rate scheduler step
Epoch-22 lr: 6.25e-06
Epoch-22 lr: 6.25e-06
epoch 22 training time: 373.280
---------------
2023-08-07 01:23:40.763994
current #epochs=23, #steps=11374
Epoch: [23][26/517]	Per Sample Total Time 0.08839	Per Sample Data Time 0.01654	Per Sample DNN Time 0.07185	Train Loss 0.3809	
Epoch: [23][126/517]	Per Sample Total Time 0.07584	Per Sample Data Time 0.00388	Per Sample DNN Time 0.07196	Train Loss 0.3806	
Epoch: [23][226/517]	Per Sample Total Time 0.07446	Per Sample Data Time 0.00241	Per Sample DNN Time 0.07204	Train Loss 0.3822	
Epoch: [23][326/517]	Per Sample Total Time 0.07394	Per Sample Data Time 0.00185	Per Sample DNN Time 0.07209	Train Loss 0.3824	
Epoch: [23][426/517]	Per Sample Total Time 0.07366	Per Sample Data Time 0.00154	Per Sample DNN Time 0.07212	Train Loss 0.3784	
start validation
mAP: 0.242251
AUC: 0.485683
Avg Precision: 0.239484
Avg Recall: 0.603593
d_prime: -0.050762
train_loss: 0.376065
valid_loss: 0.747428
S_p: 57.18809373020537, S_e: 19.371282922683143, Score: 38.27968832644426
validation finished
normal learning rate scheduler step
Epoch-23 lr: 6.25e-06
Epoch-23 lr: 6.25e-06
epoch 23 training time: 373.249
---------------
2023-08-07 01:29:54.012867
current #epochs=24, #steps=11891
Epoch: [24][9/517]	Per Sample Total Time 0.12264	Per Sample Data Time 0.05087	Per Sample DNN Time 0.07177	Train Loss 0.3836	
Epoch: [24][109/517]	Per Sample Total Time 0.07702	Per Sample Data Time 0.00505	Per Sample DNN Time 0.07196	Train Loss 0.3701	
Epoch: [24][209/517]	Per Sample Total Time 0.07496	Per Sample Data Time 0.00291	Per Sample DNN Time 0.07205	Train Loss 0.3727	
Epoch: [24][309/517]	Per Sample Total Time 0.07423	Per Sample Data Time 0.00214	Per Sample DNN Time 0.07209	Train Loss 0.3688	
Epoch: [24][409/517]	Per Sample Total Time 0.07388	Per Sample Data Time 0.00176	Per Sample DNN Time 0.07212	Train Loss 0.3714	
Epoch: [24][509/517]	Per Sample Total Time 0.07365	Per Sample Data Time 0.00151	Per Sample DNN Time 0.07213	Train Loss 0.3692	
start validation
mAP: 0.244379
AUC: 0.491383
Avg Precision: 0.243537
Avg Recall: 0.625697
d_prime: -0.030547
train_loss: 0.368379
valid_loss: 0.748579
S_p: 56.17479417352399, S_e: 17.24723874256438, Score: 36.711016458044185
validation finished
normal learning rate scheduler step
Epoch-24 lr: 6.25e-06
Epoch-24 lr: 6.25e-06
epoch 24 training time: 374.064
---------------
2023-08-07 01:36:08.076741
current #epochs=25, #steps=12408
Epoch: [25][92/517]	Per Sample Total Time 0.07798	Per Sample Data Time 0.00605	Per Sample DNN Time 0.07193	Train Loss 0.3583	
Epoch: [25][192/517]	Per Sample Total Time 0.07523	Per Sample Data Time 0.00319	Per Sample DNN Time 0.07203	Train Loss 0.3572	
Epoch: [25][292/517]	Per Sample Total Time 0.07437	Per Sample Data Time 0.00228	Per Sample DNN Time 0.07209	Train Loss 0.3601	
Epoch: [25][392/517]	Per Sample Total Time 0.07396	Per Sample Data Time 0.00184	Per Sample DNN Time 0.07212	Train Loss 0.3598	
Epoch: [25][492/517]	Per Sample Total Time 0.07370	Per Sample Data Time 0.00157	Per Sample DNN Time 0.07213	Train Loss 0.3636	
start validation
mAP: 0.246952
AUC: 0.493166
Avg Precision: 0.243346
Avg Recall: 0.625959
d_prime: -0.024227
train_loss: 0.363567
valid_loss: 0.748124
S_p: 55.28815706142778, S_e: 17.587085811383382, Score: 36.43762143640558
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.125e-06
Epoch-25 lr: 3.125e-06
epoch 25 training time: 373.819
---------------
2023-08-07 01:42:21.895737
current #epochs=26, #steps=12925
Epoch: [26][75/517]	Per Sample Total Time 0.07863	Per Sample Data Time 0.00668	Per Sample DNN Time 0.07195	Train Loss 0.3510	
Epoch: [26][175/517]	Per Sample Total Time 0.07523	Per Sample Data Time 0.00319	Per Sample DNN Time 0.07204	Train Loss 0.3422	
Epoch: [26][275/517]	Per Sample Total Time 0.07430	Per Sample Data Time 0.00221	Per Sample DNN Time 0.07209	Train Loss 0.3408	
Epoch: [26][375/517]	Per Sample Total Time 0.07388	Per Sample Data Time 0.00176	Per Sample DNN Time 0.07212	Train Loss 0.3457	
Epoch: [26][475/517]	Per Sample Total Time 0.07363	Per Sample Data Time 0.00150	Per Sample DNN Time 0.07214	Train Loss 0.3478	
start validation
mAP: 0.244919
AUC: 0.488394
Avg Precision: 0.242043
Avg Recall: 0.617695
d_prime: -0.041147
train_loss: 0.347085
valid_loss: 0.746872
S_p: 60.79797340088279, S_e: 14.273576890398108, Score: 37.53577514564045
validation finished
normal learning rate scheduler step
Epoch-26 lr: 3.125e-06
Epoch-26 lr: 3.125e-06
epoch 26 training time: 373.406
---------------
2023-08-07 01:48:35.301789
current #epochs=27, #steps=13442
Epoch: [27][58/517]	Per Sample Total Time 0.08065	Per Sample Data Time 0.00869	Per Sample DNN Time 0.07196	Train Loss 0.3526	
Epoch: [27][158/517]	Per Sample Total Time 0.07560	Per Sample Data Time 0.00354	Per Sample DNN Time 0.07205	Train Loss 0.3502	
Epoch: [27][258/517]	Per Sample Total Time 0.07447	Per Sample Data Time 0.00238	Per Sample DNN Time 0.07210	Train Loss 0.3470	
Epoch: [27][358/517]	Per Sample Total Time 0.07397	Per Sample Data Time 0.00185	Per Sample DNN Time 0.07212	Train Loss 0.3454	
Epoch: [27][458/517]	Per Sample Total Time 0.07368	Per Sample Data Time 0.00155	Per Sample DNN Time 0.07214	Train Loss 0.3467	
start validation
mAP: 0.245520
AUC: 0.488040
Avg Precision: 0.242236
Avg Recall: 0.611257
d_prime: -0.042405
train_loss: 0.346830
valid_loss: 0.747239
S_p: 55.98480050664622, S_e: 17.41716227697388, Score: 36.70098139181005
validation finished
normal learning rate scheduler step
Epoch-27 lr: 3.125e-06
Epoch-27 lr: 3.125e-06
epoch 27 training time: 373.481
---------------
2023-08-07 01:54:48.782882
current #epochs=28, #steps=13959
Epoch: [28][41/517]	Per Sample Total Time 0.08370	Per Sample Data Time 0.01182	Per Sample DNN Time 0.07188	Train Loss 0.3061	
Epoch: [28][141/517]	Per Sample Total Time 0.07580	Per Sample Data Time 0.00378	Per Sample DNN Time 0.07202	Train Loss 0.3407	
Epoch: [28][241/517]	Per Sample Total Time 0.07447	Per Sample Data Time 0.00239	Per Sample DNN Time 0.07209	Train Loss 0.3404	
Epoch: [28][341/517]	Per Sample Total Time 0.07392	Per Sample Data Time 0.00181	Per Sample DNN Time 0.07211	Train Loss 0.3427	
Epoch: [28][441/517]	Per Sample Total Time 0.07362	Per Sample Data Time 0.00149	Per Sample DNN Time 0.07213	Train Loss 0.3421	
start validation
mAP: 0.241923
AUC: 0.484594
Avg Precision: 0.239796
Avg Recall: 0.608007
d_prime: -0.054628
train_loss: 0.342530
valid_loss: 0.747779
S_p: 58.581380620642264, S_e: 16.14273576890262, Score: 37.362058194772445
validation finished
normal learning rate scheduler step
Epoch-28 lr: 3.125e-06
Epoch-28 lr: 3.125e-06
epoch 28 training time: 372.746
---------------
2023-08-07 02:01:01.529284
current #epochs=29, #steps=14476
Epoch: [29][24/517]	Per Sample Total Time 0.08958	Per Sample Data Time 0.01766	Per Sample DNN Time 0.07192	Train Loss 0.3462	
Epoch: [29][124/517]	Per Sample Total Time 0.07592	Per Sample Data Time 0.00388	Per Sample DNN Time 0.07204	Train Loss 0.3342	
Epoch: [29][224/517]	Per Sample Total Time 0.07445	Per Sample Data Time 0.00235	Per Sample DNN Time 0.07210	Train Loss 0.3403	
Epoch: [29][324/517]	Per Sample Total Time 0.07390	Per Sample Data Time 0.00177	Per Sample DNN Time 0.07213	Train Loss 0.3377	
Epoch: [29][424/517]	Per Sample Total Time 0.07360	Per Sample Data Time 0.00146	Per Sample DNN Time 0.07215	Train Loss 0.3395	
start validation
mAP: 0.246074
AUC: 0.492237
Avg Precision: 0.246132
Avg Recall: 0.625404
d_prime: -0.027521
train_loss: 0.339487
valid_loss: 0.748855
S_p: 53.894870170990885, S_e: 18.946474086659393, Score: 36.42067212882514
validation finished
normal learning rate scheduler step
Epoch-29 lr: 3.125e-06
Epoch-29 lr: 3.125e-06
epoch 29 training time: 372.617
---------------
2023-08-07 02:07:14.146805
current #epochs=30, #steps=14993
Epoch: [30][7/517]	Per Sample Total Time 0.12163	Per Sample Data Time 0.04981	Per Sample DNN Time 0.07182	Train Loss 0.3672	
Epoch: [30][107/517]	Per Sample Total Time 0.07609	Per Sample Data Time 0.00407	Per Sample DNN Time 0.07202	Train Loss 0.3454	
Epoch: [30][207/517]	Per Sample Total Time 0.07442	Per Sample Data Time 0.00233	Per Sample DNN Time 0.07209	Train Loss 0.3434	
Epoch: [30][307/517]	Per Sample Total Time 0.07385	Per Sample Data Time 0.00172	Per Sample DNN Time 0.07213	Train Loss 0.3436	
Epoch: [30][407/517]	Per Sample Total Time 0.07356	Per Sample Data Time 0.00141	Per Sample DNN Time 0.07215	Train Loss 0.3367	
Epoch: [30][507/517]	Per Sample Total Time 0.07338	Per Sample Data Time 0.00122	Per Sample DNN Time 0.07216	Train Loss 0.3356	
start validation
mAP: 0.245298
AUC: 0.491103
Avg Precision: 0.241484
Avg Recall: 0.610765
d_prime: -0.031540
train_loss: 0.335125
valid_loss: 0.743894
S_p: 58.771374287520025, S_e: 17.75700934579288, Score: 38.26419181665645
validation finished
normal learning rate scheduler step
Epoch-30 lr: 1.5625e-06
Epoch-30 lr: 1.5625e-06
epoch 30 training time: 372.335
---------------
2023-08-07 02:13:26.481742
current #epochs=31, #steps=15510
Epoch: [31][90/517]	Per Sample Total Time 0.07710	Per Sample Data Time 0.00509	Per Sample DNN Time 0.07200	Train Loss 0.3254	
Epoch: [31][190/517]	Per Sample Total Time 0.07475	Per Sample Data Time 0.00267	Per Sample DNN Time 0.07208	Train Loss 0.3227	
Epoch: [31][290/517]	Per Sample Total Time 0.07406	Per Sample Data Time 0.00194	Per Sample DNN Time 0.07212	Train Loss 0.3281	
Epoch: [31][390/517]	Per Sample Total Time 0.07374	Per Sample Data Time 0.00159	Per Sample DNN Time 0.07214	Train Loss 0.3308	
Epoch: [31][490/517]	Per Sample Total Time 0.07354	Per Sample Data Time 0.00139	Per Sample DNN Time 0.07216	Train Loss 0.3327	
start validation
mAP: 0.242809
AUC: 0.488671
Avg Precision: 0.241080
Avg Recall: 0.608847
d_prime: -0.040164
train_loss: 0.331354
valid_loss: 0.749566
S_p: 54.654844838501916, S_e: 17.587085811383382, Score: 36.120965324942645
validation finished
normal learning rate scheduler step
Epoch-31 lr: 1.5625e-06
Epoch-31 lr: 1.5625e-06
epoch 31 training time: 374.204
---------------
2023-08-07 02:19:40.686298
current #epochs=32, #steps=16027
Epoch: [32][73/517]	Per Sample Total Time 0.07996	Per Sample Data Time 0.00803	Per Sample DNN Time 0.07193	Train Loss 0.3406	
Epoch: [32][173/517]	Per Sample Total Time 0.07576	Per Sample Data Time 0.00373	Per Sample DNN Time 0.07203	Train Loss 0.3412	
Epoch: [32][273/517]	Per Sample Total Time 0.07465	Per Sample Data Time 0.00257	Per Sample DNN Time 0.07208	Train Loss 0.3385	
Epoch: [32][373/517]	Per Sample Total Time 0.07415	Per Sample Data Time 0.00203	Per Sample DNN Time 0.07212	Train Loss 0.3373	
Epoch: [32][473/517]	Per Sample Total Time 0.07384	Per Sample Data Time 0.00171	Per Sample DNN Time 0.07213	Train Loss 0.3363	
start validation
mAP: 0.242792
AUC: 0.489252
Avg Precision: 0.241599
Avg Recall: 0.612997
d_prime: -0.038106
train_loss: 0.335554
valid_loss: 0.747603
S_p: 56.17479417352399, S_e: 17.502124044178633, Score: 36.83845910885131
validation finished
normal learning rate scheduler step
Epoch-32 lr: 1.5625e-06
Epoch-32 lr: 1.5625e-06
epoch 32 training time: 374.824
---------------
2023-08-07 02:25:55.510187
current #epochs=33, #steps=16544
Epoch: [33][56/517]	Per Sample Total Time 0.08146	Per Sample Data Time 0.00957	Per Sample DNN Time 0.07189	Train Loss 0.3303	
Epoch: [33][156/517]	Per Sample Total Time 0.07583	Per Sample Data Time 0.00384	Per Sample DNN Time 0.07200	Train Loss 0.3294	
Epoch: [33][256/517]	Per Sample Total Time 0.07461	Per Sample Data Time 0.00256	Per Sample DNN Time 0.07205	Train Loss 0.3269	
Epoch: [33][356/517]	Per Sample Total Time 0.07407	Per Sample Data Time 0.00199	Per Sample DNN Time 0.07209	Train Loss 0.3277	
Epoch: [33][456/517]	Per Sample Total Time 0.07378	Per Sample Data Time 0.00167	Per Sample DNN Time 0.07211	Train Loss 0.3290	
start validation
mAP: 0.242212
AUC: 0.486957
Avg Precision: 0.241191
Avg Recall: 0.617001
d_prime: -0.046243
train_loss: 0.327451
valid_loss: 0.750274
S_p: 54.084863837868646, S_e: 16.737468139335874, Score: 35.411165988602264
validation finished
normal learning rate scheduler step
Epoch-33 lr: 1.5625e-06
Epoch-33 lr: 1.5625e-06
epoch 33 training time: 373.272
---------------
2023-08-07 02:32:08.782323
current #epochs=34, #steps=17061
Epoch: [34][39/517]	Per Sample Total Time 0.08356	Per Sample Data Time 0.01165	Per Sample DNN Time 0.07191	Train Loss 0.3374	
Epoch: [34][139/517]	Per Sample Total Time 0.07577	Per Sample Data Time 0.00373	Per Sample DNN Time 0.07205	Train Loss 0.3298	
Epoch: [34][239/517]	Per Sample Total Time 0.07450	Per Sample Data Time 0.00241	Per Sample DNN Time 0.07210	Train Loss 0.3247	
Epoch: [34][339/517]	Per Sample Total Time 0.07398	Per Sample Data Time 0.00186	Per Sample DNN Time 0.07212	Train Loss 0.3260	
Epoch: [34][439/517]	Per Sample Total Time 0.07367	Per Sample Data Time 0.00154	Per Sample DNN Time 0.07213	Train Loss 0.3244	
start validation
mAP: 0.242153
AUC: 0.488102
Avg Precision: 0.241251
Avg Recall: 0.614121
d_prime: -0.042185
train_loss: 0.328830
valid_loss: 0.748040
S_p: 54.97150094996485, S_e: 17.926932880202383, Score: 36.44921691508362
validation finished
normal learning rate scheduler step
Epoch-34 lr: 1.5625e-06
Epoch-34 lr: 1.5625e-06
epoch 34 training time: 372.086
---------------
2023-08-07 02:38:20.868799
current #epochs=35, #steps=17578
Epoch: [35][22/517]	Per Sample Total Time 0.09284	Per Sample Data Time 0.02098	Per Sample DNN Time 0.07186	Train Loss 0.3310	
Epoch: [35][122/517]	Per Sample Total Time 0.07635	Per Sample Data Time 0.00432	Per Sample DNN Time 0.07203	Train Loss 0.3330	
Epoch: [35][222/517]	Per Sample Total Time 0.07468	Per Sample Data Time 0.00259	Per Sample DNN Time 0.07209	Train Loss 0.3283	
Epoch: [35][322/517]	Per Sample Total Time 0.07406	Per Sample Data Time 0.00194	Per Sample DNN Time 0.07212	Train Loss 0.3257	
Epoch: [35][422/517]	Per Sample Total Time 0.07375	Per Sample Data Time 0.00162	Per Sample DNN Time 0.07213	Train Loss 0.3271	
start validation
mAP: 0.241634
AUC: 0.485867
Avg Precision: 0.239196
Avg Recall: 0.604474
d_prime: -0.050109
train_loss: 0.326678
valid_loss: 0.749293
S_p: 55.28815706142778, S_e: 16.482582837721623, Score: 35.8853699495747
validation finished
normal learning rate scheduler step
Epoch-35 lr: 7.8125e-07
Epoch-35 lr: 7.8125e-07
epoch 35 training time: 374.064
---------------
2023-08-07 02:44:34.932997
current #epochs=36, #steps=18095
Epoch: [36][5/517]	Per Sample Total Time 0.15861	Per Sample Data Time 0.08685	Per Sample DNN Time 0.07176	Train Loss 0.3484	
Epoch: [36][105/517]	Per Sample Total Time 0.07752	Per Sample Data Time 0.00560	Per Sample DNN Time 0.07192	Train Loss 0.3267	
Epoch: [36][205/517]	Per Sample Total Time 0.07521	Per Sample Data Time 0.00321	Per Sample DNN Time 0.07201	Train Loss 0.3261	
Epoch: [36][305/517]	Per Sample Total Time 0.07440	Per Sample Data Time 0.00237	Per Sample DNN Time 0.07204	Train Loss 0.3230	
Epoch: [36][405/517]	Per Sample Total Time 0.07399	Per Sample Data Time 0.00193	Per Sample DNN Time 0.07206	Train Loss 0.3236	
Epoch: [36][505/517]	Per Sample Total Time 0.07374	Per Sample Data Time 0.00166	Per Sample DNN Time 0.07208	Train Loss 0.3212	
start validation
mAP: 0.241706
AUC: 0.486626
Avg Precision: 0.241311
Avg Recall: 0.611428
d_prime: -0.047417
train_loss: 0.321825
valid_loss: 0.749824
S_p: 54.781507283087095, S_e: 16.737468139335874, Score: 35.759487711211484
validation finished
normal learning rate scheduler step
Epoch-36 lr: 7.8125e-07
Epoch-36 lr: 7.8125e-07
epoch 36 training time: 374.294
---------------
2023-08-07 02:50:49.227200
current #epochs=37, #steps=18612
Epoch: [37][88/517]	Per Sample Total Time 0.07794	Per Sample Data Time 0.00602	Per Sample DNN Time 0.07192	Train Loss 0.3322	
Epoch: [37][188/517]	Per Sample Total Time 0.07508	Per Sample Data Time 0.00307	Per Sample DNN Time 0.07201	Train Loss 0.3321	
Epoch: [37][288/517]	Per Sample Total Time 0.07425	Per Sample Data Time 0.00220	Per Sample DNN Time 0.07206	Train Loss 0.3245	
Epoch: [37][388/517]	Per Sample Total Time 0.07386	Per Sample Data Time 0.00177	Per Sample DNN Time 0.07209	Train Loss 0.3264	
Epoch: [37][488/517]	Per Sample Total Time 0.07364	Per Sample Data Time 0.00151	Per Sample DNN Time 0.07213	Train Loss 0.3275	
start validation
mAP: 0.243409
AUC: 0.488948
Avg Precision: 0.243095
Avg Recall: 0.616243
d_prime: -0.039183
train_loss: 0.327857
valid_loss: 0.748866
S_p: 55.35148828372037, S_e: 16.99235344095013, Score: 36.17192086233525
validation finished
normal learning rate scheduler step
Epoch-37 lr: 7.8125e-07
Epoch-37 lr: 7.8125e-07
epoch 37 training time: 378.811
---------------
2023-08-07 02:57:08.038848
current #epochs=38, #steps=19129
Epoch: [38][71/517]	Per Sample Total Time 0.08596	Per Sample Data Time 0.00719	Per Sample DNN Time 0.07877	Train Loss 0.3146	
Epoch: [38][171/517]	Per Sample Total Time 0.07830	Per Sample Data Time 0.00327	Per Sample DNN Time 0.07503	Train Loss 0.3180	
Epoch: [38][271/517]	Per Sample Total Time 0.07633	Per Sample Data Time 0.00223	Per Sample DNN Time 0.07409	Train Loss 0.3227	
Epoch: [38][371/517]	Per Sample Total Time 0.07543	Per Sample Data Time 0.00175	Per Sample DNN Time 0.07368	Train Loss 0.3242	
Epoch: [38][471/517]	Per Sample Total Time 0.07493	Per Sample Data Time 0.00149	Per Sample DNN Time 0.07344	Train Loss 0.3275	
start validation
mAP: 0.243832
AUC: 0.490536
Avg Precision: 0.242601
Avg Recall: 0.612705
d_prime: -0.033551
train_loss: 0.327605
valid_loss: 0.748470
S_p: 54.71817606079451, S_e: 17.162276975359628, Score: 35.94022651807707
validation finished
normal learning rate scheduler step
Epoch-38 lr: 7.8125e-07
Epoch-38 lr: 7.8125e-07
epoch 38 training time: 378.284
---------------
2023-08-07 03:03:26.322118
current #epochs=39, #steps=19646
Epoch: [39][54/517]	Per Sample Total Time 0.08148	Per Sample Data Time 0.00928	Per Sample DNN Time 0.07220	Train Loss 0.3432	
Epoch: [39][154/517]	Per Sample Total Time 0.07586	Per Sample Data Time 0.00358	Per Sample DNN Time 0.07228	Train Loss 0.3339	
Epoch: [39][254/517]	Per Sample Total Time 0.07467	Per Sample Data Time 0.00236	Per Sample DNN Time 0.07232	Train Loss 0.3303	
Epoch: [39][354/517]	Per Sample Total Time 0.07417	Per Sample Data Time 0.00184	Per Sample DNN Time 0.07233	Train Loss 0.3292	
Epoch: [39][454/517]	Per Sample Total Time 0.07388	Per Sample Data Time 0.00154	Per Sample DNN Time 0.07234	Train Loss 0.3296	
start validation
mAP: 0.243703
AUC: 0.491246
Avg Precision: 0.242332
Avg Recall: 0.615874
d_prime: -0.031034
train_loss: 0.329926
valid_loss: 0.748497
S_p: 54.97150094996485, S_e: 17.33220050976913, Score: 36.15185072986699
validation finished
normal learning rate scheduler step
Epoch-39 lr: 7.8125e-07
Epoch-39 lr: 7.8125e-07
epoch 39 training time: 374.335
---------------
2023-08-07 03:09:40.657181
current #epochs=40, #steps=20163
Epoch: [40][37/517]	Per Sample Total Time 0.08656	Per Sample Data Time 0.01446	Per Sample DNN Time 0.07211	Train Loss 0.3433	
Epoch: [40][137/517]	Per Sample Total Time 0.07661	Per Sample Data Time 0.00437	Per Sample DNN Time 0.07224	Train Loss 0.3326	
Epoch: [40][237/517]	Per Sample Total Time 0.07508	Per Sample Data Time 0.00277	Per Sample DNN Time 0.07231	Train Loss 0.3243	
Epoch: [40][337/517]	Per Sample Total Time 0.07447	Per Sample Data Time 0.00210	Per Sample DNN Time 0.07237	Train Loss 0.3223	
Epoch: [40][437/517]	Per Sample Total Time 0.07415	Per Sample Data Time 0.00175	Per Sample DNN Time 0.07240	Train Loss 0.3239	
start validation
mAP: 0.243929
AUC: 0.490953
Avg Precision: 0.241694
Avg Recall: 0.607699
d_prime: -0.032072
train_loss: 0.323310
valid_loss: 0.747248
S_p: 56.1114629512314, S_e: 17.587085811383382, Score: 36.849274381307396
validation finished
normal learning rate scheduler step
Epoch-40 lr: 3.90625e-07
Epoch-40 lr: 3.90625e-07
epoch 40 training time: 375.805
---------------
2023-08-07 03:15:56.462392
current #epochs=41, #steps=20680
Epoch: [41][20/517]	Per Sample Total Time 0.09789	Per Sample Data Time 0.02571	Per Sample DNN Time 0.07218	Train Loss 0.3625	
Epoch: [41][120/517]	Per Sample Total Time 0.07717	Per Sample Data Time 0.00487	Per Sample DNN Time 0.07230	Train Loss 0.3305	
Epoch: [41][220/517]	Per Sample Total Time 0.07525	Per Sample Data Time 0.00289	Per Sample DNN Time 0.07236	Train Loss 0.3254	
Epoch: [41][320/517]	Per Sample Total Time 0.07454	Per Sample Data Time 0.00214	Per Sample DNN Time 0.07239	Train Loss 0.3212	
Epoch: [41][420/517]	Per Sample Total Time 0.07419	Per Sample Data Time 0.00176	Per Sample DNN Time 0.07243	Train Loss 0.3220	
start validation
mAP: 0.243333
AUC: 0.490138
Avg Precision: 0.241011
Avg Recall: 0.609180
d_prime: -0.034963
train_loss: 0.325024
valid_loss: 0.748951
S_p: 54.338188727039, S_e: 17.502124044178633, Score: 35.92015638560881
validation finished
normal learning rate scheduler step
Epoch-41 lr: 3.90625e-07
Epoch-41 lr: 3.90625e-07
epoch 41 training time: 375.689
---------------
2023-08-07 03:22:12.151424
current #epochs=42, #steps=21197
Epoch: [42][3/517]	Per Sample Total Time 0.20274	Per Sample Data Time 0.13078	Per Sample DNN Time 0.07196	Train Loss 0.2942	
Epoch: [42][103/517]	Per Sample Total Time 0.07764	Per Sample Data Time 0.00553	Per Sample DNN Time 0.07211	Train Loss 0.3161	
Epoch: [42][203/517]	Per Sample Total Time 0.07524	Per Sample Data Time 0.00309	Per Sample DNN Time 0.07215	Train Loss 0.3209	
Epoch: [42][303/517]	Per Sample Total Time 0.07441	Per Sample Data Time 0.00224	Per Sample DNN Time 0.07217	Train Loss 0.3176	
Epoch: [42][403/517]	Per Sample Total Time 0.07399	Per Sample Data Time 0.00181	Per Sample DNN Time 0.07218	Train Loss 0.3173	
Epoch: [42][503/517]	Per Sample Total Time 0.07374	Per Sample Data Time 0.00155	Per Sample DNN Time 0.07218	Train Loss 0.3212	
start validation
mAP: 0.243542
AUC: 0.490467
Avg Precision: 0.242149
Avg Recall: 0.615890
d_prime: -0.033798
train_loss: 0.321081
valid_loss: 0.747420
S_p: 56.30145661810916, S_e: 16.99235344095013, Score: 36.64690502952964
validation finished
normal learning rate scheduler step
Epoch-42 lr: 3.90625e-07
Epoch-42 lr: 3.90625e-07
epoch 42 training time: 374.062
---------------
2023-08-07 03:28:26.213426
current #epochs=43, #steps=21714
Epoch: [43][86/517]	Per Sample Total Time 0.07769	Per Sample Data Time 0.00570	Per Sample DNN Time 0.07199	Train Loss 0.3120	
Epoch: [43][186/517]	Per Sample Total Time 0.07501	Per Sample Data Time 0.00294	Per Sample DNN Time 0.07208	Train Loss 0.3121	
Epoch: [43][286/517]	Per Sample Total Time 0.07423	Per Sample Data Time 0.00210	Per Sample DNN Time 0.07212	Train Loss 0.3125	
Epoch: [43][386/517]	Per Sample Total Time 0.07384	Per Sample Data Time 0.00169	Per Sample DNN Time 0.07215	Train Loss 0.3150	
Epoch: [43][486/517]	Per Sample Total Time 0.07361	Per Sample Data Time 0.00145	Per Sample DNN Time 0.07216	Train Loss 0.3196	
start validation
mAP: 0.243538
AUC: 0.491753
Avg Precision: 0.241919
Avg Recall: 0.616113
d_prime: -0.029237
train_loss: 0.319452
valid_loss: 0.749097
S_p: 54.528182393916744, S_e: 17.33220050976913, Score: 35.93019145184294
validation finished
normal learning rate scheduler step
Epoch-43 lr: 3.90625e-07
Epoch-43 lr: 3.90625e-07
epoch 43 training time: 373.362
---------------
2023-08-07 03:34:39.575873
current #epochs=44, #steps=22231
Epoch: [44][69/517]	Per Sample Total Time 0.07934	Per Sample Data Time 0.00736	Per Sample DNN Time 0.07198	Train Loss 0.3200	
Epoch: [44][169/517]	Per Sample Total Time 0.07541	Per Sample Data Time 0.00335	Per Sample DNN Time 0.07206	Train Loss 0.3249	
Epoch: [44][269/517]	Per Sample Total Time 0.07441	Per Sample Data Time 0.00230	Per Sample DNN Time 0.07211	Train Loss 0.3200	
Epoch: [44][369/517]	Per Sample Total Time 0.07395	Per Sample Data Time 0.00182	Per Sample DNN Time 0.07213	Train Loss 0.3245	
Epoch: [44][469/517]	Per Sample Total Time 0.07369	Per Sample Data Time 0.00154	Per Sample DNN Time 0.07215	Train Loss 0.3249	
start validation
mAP: 0.242903
AUC: 0.491021
Avg Precision: 0.240798
Avg Recall: 0.608028
d_prime: -0.031831
train_loss: 0.323136
valid_loss: 0.749146
S_p: 54.97150094996485, S_e: 16.99235344095013, Score: 35.98192719545749
validation finished
normal learning rate scheduler step
Epoch-44 lr: 3.90625e-07
Epoch-44 lr: 3.90625e-07
epoch 44 training time: 373.413
---------------
2023-08-07 03:40:52.988976
current #epochs=45, #steps=22748
Epoch: [45][52/517]	Per Sample Total Time 0.08131	Per Sample Data Time 0.00943	Per Sample DNN Time 0.07189	Train Loss 0.3329	
Epoch: [45][152/517]	Per Sample Total Time 0.07554	Per Sample Data Time 0.00353	Per Sample DNN Time 0.07201	Train Loss 0.3313	
Epoch: [45][252/517]	Per Sample Total Time 0.07436	Per Sample Data Time 0.00230	Per Sample DNN Time 0.07206	Train Loss 0.3337	
Epoch: [45][352/517]	Per Sample Total Time 0.07385	Per Sample Data Time 0.00176	Per Sample DNN Time 0.07209	Train Loss 0.3280	
Epoch: [45][452/517]	Per Sample Total Time 0.07358	Per Sample Data Time 0.00147	Per Sample DNN Time 0.07210	Train Loss 0.3273	
start validation
mAP: 0.242689
AUC: 0.490737
Avg Precision: 0.240834
Avg Recall: 0.607099
d_prime: -0.032840
train_loss: 0.327934
valid_loss: 0.749018
S_p: 54.528182393916744, S_e: 17.33220050976913, Score: 35.93019145184294
validation finished
normal learning rate scheduler step
Epoch-45 lr: 1.953125e-07
Epoch-45 lr: 1.953125e-07
epoch 45 training time: 371.328
---------------
2023-08-07 03:47:04.316733
current #epochs=46, #steps=23265
Epoch: [46][35/517]	Per Sample Total Time 0.08073	Per Sample Data Time 0.00874	Per Sample DNN Time 0.07199	Train Loss 0.3231	
Epoch: [46][135/517]	Per Sample Total Time 0.07480	Per Sample Data Time 0.00273	Per Sample DNN Time 0.07207	Train Loss 0.3104	
Epoch: [46][235/517]	Per Sample Total Time 0.07393	Per Sample Data Time 0.00182	Per Sample DNN Time 0.07211	Train Loss 0.3161	
Epoch: [46][335/517]	Per Sample Total Time 0.07358	Per Sample Data Time 0.00145	Per Sample DNN Time 0.07213	Train Loss 0.3203	
Epoch: [46][435/517]	Per Sample Total Time 0.07338	Per Sample Data Time 0.00125	Per Sample DNN Time 0.07213	Train Loss 0.3214	
start validation
mAP: 0.242597
AUC: 0.490012
Avg Precision: 0.241069
Avg Recall: 0.608741
d_prime: -0.035409
train_loss: 0.320438
valid_loss: 0.749360
S_p: 54.14819506016123, S_e: 17.162276975359628, Score: 35.65523601776043
validation finished
normal learning rate scheduler step
Epoch-46 lr: 1.953125e-07
Epoch-46 lr: 1.953125e-07
epoch 46 training time: 371.916
---------------
2023-08-07 03:53:16.233126
current #epochs=47, #steps=23782
Epoch: [47][18/517]	Per Sample Total Time 0.09670	Per Sample Data Time 0.02486	Per Sample DNN Time 0.07184	Train Loss 0.3653	
Epoch: [47][118/517]	Per Sample Total Time 0.07631	Per Sample Data Time 0.00432	Per Sample DNN Time 0.07199	Train Loss 0.3237	
Epoch: [47][218/517]	Per Sample Total Time 0.07459	Per Sample Data Time 0.00254	Per Sample DNN Time 0.07205	Train Loss 0.3230	
Epoch: [47][318/517]	Per Sample Total Time 0.07397	Per Sample Data Time 0.00188	Per Sample DNN Time 0.07209	Train Loss 0.3253	
Epoch: [47][418/517]	Per Sample Total Time 0.07365	Per Sample Data Time 0.00153	Per Sample DNN Time 0.07212	Train Loss 0.3191	
start validation
mAP: 0.242747
AUC: 0.490090
Avg Precision: 0.241884
Avg Recall: 0.612068
d_prime: -0.035133
train_loss: 0.320178
valid_loss: 0.749245
S_p: 54.528182393916744, S_e: 17.162276975359628, Score: 35.845229684638184
validation finished
normal learning rate scheduler step
Epoch-47 lr: 1.953125e-07
Epoch-47 lr: 1.953125e-07
epoch 47 training time: 372.898
---------------
2023-08-07 03:59:29.130550
current #epochs=48, #steps=24299
Epoch: [48][1/517]	Per Sample Total Time 0.35761	Per Sample Data Time 0.28599	Per Sample DNN Time 0.07162	Train Loss 0.2665	
Epoch: [48][101/517]	Per Sample Total Time 0.07805	Per Sample Data Time 0.00611	Per Sample DNN Time 0.07194	Train Loss 0.3218	
Epoch: [48][201/517]	Per Sample Total Time 0.07537	Per Sample Data Time 0.00334	Per Sample DNN Time 0.07203	Train Loss 0.3232	
Epoch: [48][301/517]	Per Sample Total Time 0.07451	Per Sample Data Time 0.00242	Per Sample DNN Time 0.07209	Train Loss 0.3170	
Epoch: [48][401/517]	Per Sample Total Time 0.07407	Per Sample Data Time 0.00195	Per Sample DNN Time 0.07211	Train Loss 0.3180	
Epoch: [48][501/517]	Per Sample Total Time 0.07380	Per Sample Data Time 0.00167	Per Sample DNN Time 0.07213	Train Loss 0.3221	
start validation
mAP: 0.242797
AUC: 0.489989
Avg Precision: 0.241734
Avg Recall: 0.610093
d_prime: -0.035491
train_loss: 0.321390
valid_loss: 0.749574
S_p: 54.084863837868646, S_e: 17.33220050976913, Score: 35.70853217381889
validation finished
normal learning rate scheduler step
Epoch-48 lr: 1.953125e-07
Epoch-48 lr: 1.953125e-07
epoch 48 training time: 374.136
---------------
2023-08-07 04:05:43.266512
current #epochs=49, #steps=24816
Epoch: [49][84/517]	Per Sample Total Time 0.07879	Per Sample Data Time 0.00684	Per Sample DNN Time 0.07194	Train Loss 0.3149	
Epoch: [49][184/517]	Per Sample Total Time 0.07548	Per Sample Data Time 0.00346	Per Sample DNN Time 0.07202	Train Loss 0.3228	
Epoch: [49][284/517]	Per Sample Total Time 0.07449	Per Sample Data Time 0.00244	Per Sample DNN Time 0.07205	Train Loss 0.3240	
Epoch: [49][384/517]	Per Sample Total Time 0.07403	Per Sample Data Time 0.00195	Per Sample DNN Time 0.07208	Train Loss 0.3227	
Epoch: [49][484/517]	Per Sample Total Time 0.07376	Per Sample Data Time 0.00167	Per Sample DNN Time 0.07209	Train Loss 0.3229	
start validation
mAP: 0.242726
AUC: 0.489787
Avg Precision: 0.242274
Avg Recall: 0.613102
d_prime: -0.036208
train_loss: 0.324153
valid_loss: 0.749411
S_p: 54.46485117162416, S_e: 17.07731520815488, Score: 35.771083189889524
validation finished
normal learning rate scheduler step
Epoch-49 lr: 1.953125e-07
Epoch-49 lr: 1.953125e-07
epoch 49 training time: 374.085
---------------
2023-08-07 04:11:57.351275
current #epochs=50, #steps=25333
Epoch: [50][67/517]	Per Sample Total Time 0.07988	Per Sample Data Time 0.00798	Per Sample DNN Time 0.07189	Train Loss 0.3249	
Epoch: [50][167/517]	Per Sample Total Time 0.07557	Per Sample Data Time 0.00356	Per Sample DNN Time 0.07200	Train Loss 0.3249	
Epoch: [50][267/517]	Per Sample Total Time 0.07447	Per Sample Data Time 0.00243	Per Sample DNN Time 0.07204	Train Loss 0.3184	
Epoch: [50][367/517]	Per Sample Total Time 0.07398	Per Sample Data Time 0.00192	Per Sample DNN Time 0.07206	Train Loss 0.3204	
Epoch: [50][467/517]	Per Sample Total Time 0.07370	Per Sample Data Time 0.00162	Per Sample DNN Time 0.07208	Train Loss 0.3173	
start validation
mAP: 0.242618
AUC: 0.489482
Avg Precision: 0.241707
Avg Recall: 0.610799
d_prime: -0.037288
train_loss: 0.316437
valid_loss: 0.748932
S_p: 55.03483217225744, S_e: 16.907391673745376, Score: 35.97111192300141
validation finished
normal learning rate scheduler step
Epoch-50 lr: 9.765625e-08
Epoch-50 lr: 9.765625e-08
epoch 50 training time: 373.753
---------------Training Finished---------------
weighted averaged models results
mAP: 0.236329
AUC: 0.480502
Avg Precision: 0.238821
Avg Recall: 0.629092
d_prime: -0.069147
train_loss: 0.000000
valid_loss: 0.748932
S_p: 77.64407853071073, S_e: 7.391673746813305, Score: 42.51787613876202
